{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "D57PMLHEVlOm"
   },
   "source": [
    "# Set Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "frVOpCRsQFEX"
   },
   "outputs": [],
   "source": [
    "PAT_NOW = \"S12\"\n",
    "\n",
    "OUTPATIENT_MOOD_SHEET_PATH = '/home/klab/NAS/Analysis/AudioFacialEEG/Behavioral Labeling/OutpatientMoodScores_new.xlsx'\n",
    "\n",
    "OPENFACE_OUTPUT_DIRECTORY = f'/home/klab/NAS/Analysis/outputs_OpenFace/{PAT_NOW}/'\n",
    "COMBINED_OUTPUT_DIRECTORY = f'/home/klab/NAS/Analysis/outputs_Combined_Outpt/{PAT_NOW}/'\n",
    "\n",
    "RUNTIME_VAR_PATH = '/home/klab/NAS/Analysis/AudioFacialEEG/Runtime_Vars/'\n",
    "RESULTS_PATH_BASE = f'/home/klab/NAS/Analysis/AudioFacialEEG/Results/{PAT_NOW}/'\n",
    "FEATURE_VIS_PATH = f'/home/klab/NAS/Analysis/AudioFacialEEG/Feature_Visualization/{PAT_NOW}/'\n",
    "FEATURE_LABEL_PATH = '/home/klab/NAS/Analysis/AudioFacialEEG/Feature_Labels/'\n",
    "QC_PATH = '/home/klab/NAS/Analysis/AudioFacialEEG/Quality_Control/'\n",
    "\n",
    "EMO_FEATURE_SETTING = 2\n",
    "\n",
    "STATS_FEATURE_SETTING = 0\n",
    "\n",
    "NORMALIZE_DATA = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SU72QcAcVyLy"
   },
   "source": [
    "# Installs & Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LRX3feHKIR1z"
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# Ignore all warnings\n",
    "pd.options.mode.chained_assignment = None\n",
    "pd.set_option('mode.chained_assignment', None)\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "\n",
    "# SAVE VARIABLES\n",
    "import pickle\n",
    "\n",
    "def get_var_name(our_variable):\n",
    "    namespace = globals()\n",
    "    for name, obj in namespace.items():\n",
    "        if obj is our_variable:\n",
    "            return name\n",
    "    return None\n",
    "\n",
    "# Save the dictionary to a file using pickle\n",
    "def save_var(our_variable, RUNTIME_VAR_PATH=RUNTIME_VAR_PATH, forced_name=None):\n",
    "  if forced_name is None:\n",
    "    name_now = get_var_name(our_variable)\n",
    "  else:\n",
    "    name_now = forced_name\n",
    "\n",
    "  with open(RUNTIME_VAR_PATH + f'{name_now}.pkl', 'wb') as file:\n",
    "      pickle.dump(our_variable, file)\n",
    "\n",
    "def load_var(variable_name, RUNTIME_VAR_PATH=RUNTIME_VAR_PATH):\n",
    "  # Load from the file\n",
    "  with open(RUNTIME_VAR_PATH + f'{variable_name}.pkl', 'rb') as file:\n",
    "      return pickle.load(file)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_r22R0VLV4Gl"
   },
   "source": [
    "# Outpatient Mood Tracking Sheet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "W_bCqQTwV0cr"
   },
   "outputs": [],
   "source": [
    "## read data and put it in a dataframe\n",
    "spreadsheet = pd.read_excel(OUTPATIENT_MOOD_SHEET_PATH, sheet_name=None)\n",
    "\n",
    "wks = spreadsheet[f'{PAT_NOW}']\n",
    "\n",
    "data = wks\n",
    "\n",
    "df = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1IyDMQz7PvrR"
   },
   "outputs": [],
   "source": [
    "## Preprocess the mood tracking sheet\n",
    "\n",
    "# Replace the P_number mood headers with just the mood\n",
    "# df.columns = df.columns.str.replace('P[0-9]+ ', '')\n",
    "\n",
    "# Properly deal with the missing values\n",
    "df = df.replace('', np.nan).replace(' ', np.nan).fillna(value=np.nan)\n",
    "\n",
    "df_moodTracking = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "20LO991XzNAR"
   },
   "outputs": [],
   "source": [
    "df_moodTracking.loc[df_moodTracking['Follow-up Time'] == 'Screening', 'MADRS'] = df_moodTracking.apply(\n",
    "    lambda row: df_moodTracking[(df_moodTracking['Follow-up Time'] == 'Baseline')]['MADRS'].values[0]\n",
    "    if pd.isna(row['MADRS']) and row['Follow-up Time'] == 'Screening' else row['MADRS'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "12v2satGzkoI"
   },
   "outputs": [],
   "source": [
    "# Remove rows where we don't have a video file\n",
    "df_moodTracking = df_moodTracking.dropna(subset=['Filename']).reset_index(drop=True)\n",
    "\n",
    "# Remove rows where we have a video file, but no MADRS score\n",
    "df_moodTracking = df_moodTracking.dropna(subset=['MADRS']).reset_index(drop=True)\n",
    "\n",
    "# Remove duplicate Filenames\n",
    "df_moodTracking = df_moodTracking.drop_duplicates(subset=['Filename']).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_moodTracking['Filename'] = df_moodTracking['Filename'].str.replace(':', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XLMWo6cmiiE1"
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "import numpy as np\n",
    "\n",
    "def normalize_columns(df, method=1):\n",
    "    # Create a copy of the DataFrame\n",
    "    normalized_df = df.copy()\n",
    "\n",
    "    # Get the column names excluding 'Datetime'\n",
    "    columns_to_normalize = [col for col in normalized_df.columns if col != 'Filename' and col != 'Follow-up Time']\n",
    "\n",
    "    if method == 1:\n",
    "        # No scaling or normalization\n",
    "        pass\n",
    "\n",
    "    elif method == 2:\n",
    "        # MinMax scaling to range 0 to 10\n",
    "        scaler = MinMaxScaler(feature_range=(0, 10))\n",
    "        normalized_df[columns_to_normalize] = scaler.fit_transform(normalized_df[columns_to_normalize])\n",
    "\n",
    "    elif method == 3:\n",
    "        # MinMax scaling to range 0 to 1\n",
    "        scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "        normalized_df[columns_to_normalize] = scaler.fit_transform(normalized_df[columns_to_normalize])\n",
    "\n",
    "    elif method == 4:\n",
    "        # Log scaling\n",
    "        normalized_df[columns_to_normalize] = normalized_df[columns_to_normalize].astype(float)\n",
    "        normalized_df[columns_to_normalize] = np.log1p(normalized_df[columns_to_normalize])\n",
    "\n",
    "    elif method == 5:\n",
    "        # Standard normalization (Z-score normalization)\n",
    "        scaler = StandardScaler()\n",
    "        normalized_df[columns_to_normalize] = scaler.fit_transform(normalized_df[columns_to_normalize])\n",
    "\n",
    "    else:\n",
    "        raise ValueError(\"Invalid method. Choose a value between 1 and 5.\")\n",
    "\n",
    "    return normalized_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# No normalization or scaling\n",
    "df_moodTracking_orig = normalize_columns(df_moodTracking, method=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4pkPsvQxixAJ"
   },
   "outputs": [],
   "source": [
    "# With scaling (0 to 1)\n",
    "df_moodTracking = normalize_columns(df_moodTracking, method=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SHUFFLE MADRS\n",
    "# df_moodTracking_orig['MADRS'] = np.random.permutation(df_moodTracking_orig['MADRS'])\n",
    "# df_moodTracking['MADRS'] = np.random.permutation(df_moodTracking['MADRS'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dOrT1X_9WU5X"
   },
   "source": [
    "# OpenFace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YV8_wmALY-hV"
   },
   "outputs": [],
   "source": [
    "# DICTIONARY OF SEPARATE DFS\n",
    "\n",
    "def get_dict_openface(output_dir):\n",
    "  # Create an empty dictionary to hold the DataFrames\n",
    "  dfs_openface = {}\n",
    "\n",
    "  # Get a list of all the CSV files in the directory\n",
    "  csv_files = sorted([f for f in os.listdir(output_dir) if f.endswith('.csv')])\n",
    "\n",
    "  # list of columns to keep\n",
    "  columns_to_keep = ['frame', ' timestamp', ' success',\n",
    "                    ' AU01_r',\n",
    "                    ' AU02_r',\n",
    "                    ' AU04_r',\n",
    "                    ' AU05_r',\n",
    "                    ' AU06_r',\n",
    "                    ' AU07_r',\n",
    "                    ' AU09_r',\n",
    "                    ' AU10_r',\n",
    "                    ' AU12_r',\n",
    "                    ' AU14_r',\n",
    "                    ' AU15_r',\n",
    "                    ' AU17_r',\n",
    "                    ' AU20_r',\n",
    "                    ' AU23_r',\n",
    "                    ' AU25_r',\n",
    "                    ' AU26_r',\n",
    "                    ' AU45_r',\n",
    "                    ' AU01_c',\n",
    "                    ' AU02_c',\n",
    "                    ' AU04_c',\n",
    "                    ' AU05_c',\n",
    "                    ' AU06_c',\n",
    "                    ' AU07_c',\n",
    "                    ' AU09_c',\n",
    "                    ' AU10_c',\n",
    "                    ' AU12_c',\n",
    "                    ' AU14_c',\n",
    "                    ' AU15_c',\n",
    "                    ' AU17_c',\n",
    "                    ' AU20_c',\n",
    "                    ' AU23_c',\n",
    "                    ' AU25_c',\n",
    "                    ' AU26_c',\n",
    "                    ' AU45_c']\n",
    "    \n",
    "  # remove special character \n",
    "  columns_to_keep = [one_str.replace(' ', '') for one_str in columns_to_keep]\n",
    "\n",
    "  # Loop through the CSV files\n",
    "  for csv_file in csv_files:\n",
    "      # Load data into a pandas df\n",
    "      csv_file_path = os.path.join(output_dir, csv_file)\n",
    "      df_temp = pd.read_csv(csv_file_path)\n",
    "\n",
    "      # keep every 6th row such that it's 5 fps!\n",
    "      X = 6\n",
    "      df_temp = df_temp[df_temp.index % X == 0]\n",
    "\n",
    "      # filter DataFrame to keep only columns in list\n",
    "      # remove special character \n",
    "      df.columns = df.columns.str.replace(' ', '') \n",
    "      df_temp = df_temp.loc[:, columns_to_keep]\n",
    "\n",
    "      # fix column names to not have leading or trailing spaces!\n",
    "      df_temp = df_temp.rename(columns=lambda x: x.strip())\n",
    "\n",
    "      # Store the DataFrame in the dictionary with the csv file name as the key\n",
    "      # remove the '.csv' by doing csv_file[:-4]\n",
    "      dfs_openface[csv_file[:-4]] = df_temp\n",
    "      del df_temp\n",
    "\n",
    "  return dfs_openface\n",
    "\n",
    "\n",
    "def get_dict_openface_extras(output_dir):\n",
    "  # Create an empty dictionary to hold the DataFrames\n",
    "  dfs_openface = {}\n",
    "\n",
    "  # Get a list of all the CSV files in the directory\n",
    "  csv_files = sorted([f for f in os.listdir(output_dir) if f.endswith('.csv')])\n",
    "\n",
    "  # list of columns to keep\n",
    "  columns_to_keep = ['frame', ' timestamp', ' success',\n",
    "                     'gaze_0_x',\n",
    "                     'gaze_0_y',\n",
    "                     'gaze_0_z',\n",
    "                     'gaze_1_x',\n",
    "                     'gaze_1_y',\n",
    "                     'gaze_1_z',\n",
    "                     'pose_Tx',\n",
    "                     'pose_Ty',\n",
    "                     'pose_Tz',\n",
    "                     'pose_Rx',\n",
    "                     'pose_Ry',\n",
    "                     'pose_Rz']\n",
    "\n",
    "  columns_to_keep = columns_to_keep + [f\"eye_lmk_X_{i}\" for i in range(56)] + [f\"eye_lmk_Y_{i}\" for i in range(56)] + [f\"eye_lmk_Z_{i}\" for i in range(56)] \n",
    "  columns_to_keep = columns_to_keep + [f\"X_{i}\" for i in range(68)] + [f\"Y_{i}\" for i in range(68)] + [f\"Z_{i}\" for i in range(68)]\n",
    "    \n",
    "  # remove special character \n",
    "  columns_to_keep = [one_str.replace(' ', '') for one_str in columns_to_keep]\n",
    "\n",
    "  # Loop through the CSV files\n",
    "  for csv_file in csv_files:\n",
    "      # Load data into a pandas df\n",
    "      csv_file_path = os.path.join(output_dir, csv_file)\n",
    "      df_temp = pd.read_csv(csv_file_path)\n",
    "\n",
    "      # keep every 6th row such that it's 5 fps!\n",
    "      X = 6\n",
    "      df_temp = df_temp[df_temp.index % X == 0]\n",
    "\n",
    "      # filter DataFrame to keep only columns in list\n",
    "      # remove special character \n",
    "      df.columns = df.columns.str.replace(' ', '') \n",
    "      df_temp = df_temp.loc[:, columns_to_keep]\n",
    "\n",
    "      # fix column names to not have leading or trailing spaces!\n",
    "      df_temp = df_temp.rename(columns=lambda x: x.strip())\n",
    "\n",
    "      # Store the DataFrame in the dictionary with the csv file name as the key\n",
    "      # remove the '.csv' by doing csv_file[:-4]\n",
    "      dfs_openface[csv_file[:-4]] = df_temp\n",
    "      del df_temp\n",
    "\n",
    "  return dfs_openface\n",
    "\n",
    "\n",
    "\n",
    "def only_successful_frames(df):\n",
    "    # get frames where AU/emotion detection was successful!\n",
    "    return df[df['success'] == 1]\n",
    "\n",
    "def apply_function_to_dict(dictionary, func, **kwargs):\n",
    "    \"\"\"\n",
    "    Apply a function to each DataFrame in a dictionary and return a modified copy of the dictionary.\n",
    "\n",
    "    Args:\n",
    "        dictionary (dict): The dictionary containing DataFrames.\n",
    "        func (function): The function to apply to each DataFrame.\n",
    "        **kwargs: Additional keyword arguments to pass to the function.\n",
    "\n",
    "    Returns:\n",
    "        dict: A modified copy of the dictionary with the function applied to each DataFrame.\n",
    "    \"\"\"\n",
    "    return {key: func(df, **kwargs) for key, df in dictionary.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eTOXk7be8YSH"
   },
   "outputs": [],
   "source": [
    "dfs_openface = get_dict_openface(OPENFACE_OUTPUT_DIRECTORY)\n",
    "dfs_openface = apply_function_to_dict(dfs_openface, only_successful_frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wkiuU4NVeACU"
   },
   "outputs": [],
   "source": [
    "# SAVE THE OPENFACE DICTIONARY\n",
    "\n",
    "save_var(dfs_openface, forced_name=f'dfs_openface_{PAT_NOW}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Py2RgmTAekZS"
   },
   "outputs": [],
   "source": [
    "# LOAD THE OPENFACE DICTIONARY\n",
    "\n",
    "dfs_openface = load_var(f'dfs_openface_{PAT_NOW}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs_openface_extras = get_dict_openface_extras(OPENFACE_OUTPUT_DIRECTORY)\n",
    "dfs_openface_extras = apply_function_to_dict(dfs_openface_extras, only_successful_frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SAVE THE OPENFACE EXTRAS DICTIONARY\n",
    "\n",
    "save_var(dfs_openface_extras, forced_name=f'dfs_openface_extras_{PAT_NOW}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LOAD THE OPENFACE EXTRAS DICTIONARY\n",
    "\n",
    "dfs_openface_extras = load_var(f'dfs_openface_extras_{PAT_NOW}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "t52_30WQzYeh"
   },
   "source": [
    "# HSEmotion & OpenGraphAU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aUg5iqkRtIJX"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "def get_dict(output_dir, file_now='outputs_hse.csv', filterOutLR=True):\n",
    "\n",
    "  # Initialize an empty dictionary to store the dataframes\n",
    "  df_dict = {}\n",
    "\n",
    "  # Loop through the subfolders in alphabetical order\n",
    "  for subfolder_name in sorted(os.listdir(output_dir)):\n",
    "\n",
    "    # Check if the subfolder contains CSV files\n",
    "    subfolder_path = os.path.join(output_dir, subfolder_name)\n",
    "    if not os.path.isdir(subfolder_path):\n",
    "      continue\n",
    "\n",
    "    # Load the first CSV file in the subfolder into a dataframe\n",
    "    csv_file_path = os.path.join(subfolder_path, file_now)\n",
    "    if not os.path.isfile(csv_file_path):\n",
    "      continue\n",
    "\n",
    "    try:\n",
    "      df_temp = pd.read_csv(csv_file_path)\n",
    "    except:\n",
    "      df_temp = pd.DataFrame(columns=['frame', 'timestamp', 'success', 'AU1', 'AU2', 'AU4', 'AU5', 'AU6', 'AU7', 'AU9',\n",
    "       'AU10', 'AU11', 'AU12', 'AU13', 'AU14', 'AU15', 'AU16', 'AU17', 'AU18',\n",
    "       'AU19', 'AU20', 'AU22', 'AU23', 'AU24', 'AU25', 'AU26', 'AU27', 'AU32',\n",
    "       'AU38', 'AU39'])\n",
    "\n",
    "\n",
    "    # OpenGraphAU - we are filtering out L and R!\n",
    "    if filterOutLR:\n",
    "      df_temp = df_temp.filter(regex='^(?!AUL|AUR)')\n",
    "\n",
    "    # Add the dataframe to the dictionary with the subfolder name as the key\n",
    "    df_dict[subfolder_name[:-4]] = df_temp\n",
    "\n",
    "  return df_dict\n",
    "\n",
    "def create_binary_columns(df, threshold):\n",
    "    # adds classification columns to opengraphAU\n",
    "    for col in df.columns:\n",
    "        if col.startswith('AU'):\n",
    "            # Add _c to the column name for the new column\n",
    "            new_col_name = col + '_c'\n",
    "            # Apply the binary classification to the new column\n",
    "            df[new_col_name] = df[col].apply(lambda x: 1 if x >= threshold else 0)\n",
    "            # Add _r to the original column name\n",
    "            df.rename(columns={col: col + '_r'}, inplace=True)\n",
    "    return df\n",
    "\n",
    "def remove_columns_ending_with_r(df):\n",
    "    columns_to_drop = [col for col in df.columns if col.endswith('_r')]\n",
    "    df_new = df.drop(columns=columns_to_drop, inplace=False)\n",
    "    return df_new\n",
    "\n",
    "def only_successful_frames(df):\n",
    "    # get frames where AU/emotion detection was successful!\n",
    "    return df[df['success'] == 1]\n",
    "\n",
    "\n",
    "def take_time_subset(df, num_mins=10, frames_per_second=5):\n",
    "    # Takes the first num_mins minutes of data we have from a dataframe\n",
    "    df = df.reset_index(drop=True)\n",
    "    num_wanted_frames = num_mins * 60 * frames_per_second\n",
    "    df = df[:num_wanted_frames]\n",
    "    return df\n",
    "\n",
    "def take_time_subsets(df, num_mins=10, frames_per_second=5):\n",
    "    # Reset the index of the dataframe\n",
    "    df = df.reset_index(drop=True)\n",
    "\n",
    "    # Calculate the number of frames for each interval\n",
    "    interval_frame_count = num_mins * 60 * frames_per_second\n",
    "\n",
    "    # Calculate the total number of intervals\n",
    "    total_frames = len(df)\n",
    "    total_intervals = (total_frames + interval_frame_count - 1) // interval_frame_count\n",
    "\n",
    "    # Create a list to store each interval DataFrame\n",
    "    intervals = []\n",
    "\n",
    "    # Slice the DataFrame into intervals and append to the list\n",
    "    for i in range(total_intervals):\n",
    "        start = i * interval_frame_count\n",
    "        end = min((i + 1) * interval_frame_count, total_frames)\n",
    "        interval_df = df[start:end]\n",
    "        intervals.append(interval_df)\n",
    "\n",
    "    return intervals\n",
    "\n",
    "\n",
    "def apply_function_to_dict(dictionary, func, **kwargs):\n",
    "    \"\"\"\n",
    "    Apply a function to each DataFrame in a dictionary and return a modified copy of the dictionary.\n",
    "\n",
    "    Args:\n",
    "        dictionary (dict): The dictionary containing DataFrames.\n",
    "        func (function): The function to apply to each DataFrame.\n",
    "        **kwargs: Additional keyword arguments to pass to the function.\n",
    "\n",
    "    Returns:\n",
    "        dict: A modified copy of the dictionary with the function applied to each DataFrame.\n",
    "    \"\"\"\n",
    "    return {key: func(df, **kwargs) for key, df in dictionary.items()}\n",
    "\n",
    "def apply_function_to_dict_list(dictionary, func, **kwargs):\n",
    "    \"\"\"\n",
    "    Apply a function to each DataFrame in a dictionary where values are LISTS of dfs and return a modified copy of the dictionary.\n",
    "\n",
    "    Args:\n",
    "        dictionary (dict): The dictionary containing DataFrames.\n",
    "        func (function): The function to apply to each DataFrame.\n",
    "        **kwargs: Additional keyword arguments to pass to the function.\n",
    "\n",
    "    Returns:\n",
    "        dict: A modified copy of the dictionary with the function applied to each DataFrame.\n",
    "    \"\"\"\n",
    "    return {key: [func(df, **kwargs) for df in df_list] for key, df_list in dictionary.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mEea0RmkACqS"
   },
   "outputs": [],
   "source": [
    "dfs_hsemotion = get_dict(COMBINED_OUTPUT_DIRECTORY, file_now='outputs_hse.csv')\n",
    "dfs_hsemotion = apply_function_to_dict(dfs_hsemotion, only_successful_frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MQjRLc6E7st0"
   },
   "outputs": [],
   "source": [
    "dfs_opengraphau = get_dict(COMBINED_OUTPUT_DIRECTORY, file_now='outputs_ogau.csv')\n",
    "dfs_opengraphau = apply_function_to_dict(dfs_opengraphau, only_successful_frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EA_FYs-8e12m"
   },
   "outputs": [],
   "source": [
    "# SAVE THE HSEMOTION AND OPENGRAPHAU DICTIONARIES\n",
    "\n",
    "save_var(dfs_hsemotion, forced_name=f'dfs_hsemotion_outpatient_raw_{PAT_NOW}')\n",
    "\n",
    "save_var(dfs_opengraphau, forced_name=f'dfs_opengraphau_outpatient_raw_{PAT_NOW}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0c_gdTS1fAoE"
   },
   "outputs": [],
   "source": [
    "# LOAD THE HSEMOTION AND OPENGRAPHAU DICTIONARIES\n",
    "\n",
    "dfs_hsemotion = load_var(f'dfs_hsemotion_outpatient_raw_{PAT_NOW}')\n",
    "\n",
    "dfs_opengraphau = load_var(f'dfs_opengraphau_outpatient_raw_{PAT_NOW}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Filtering OpenFace via FaceDx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_by_timestamp_optimized(facedx_df, openface_df):\n",
    "    # Reset index of the DataFrames at the beginning\n",
    "    facedx_df.reset_index(drop=True, inplace=True)\n",
    "    openface_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    # Convert timestamp columns to float\n",
    "    facedx_df['timestamp'] = pd.to_numeric(facedx_df['timestamp'], errors='coerce')\n",
    "    openface_df['timestamp'] = pd.to_numeric(openface_df['timestamp'], errors='coerce')\n",
    "\n",
    "    # Initialize an empty list to store indices of rows in openface_df to keep\n",
    "    indices_to_keep = []\n",
    "\n",
    "    # Use broadcasting to find the absolute differences between each openface timestamp and all facedx timestamps\n",
    "    for timestamp in openface_df['timestamp']:\n",
    "        # Calculate the absolute difference between the current openface timestamp and all facedx timestamps\n",
    "        abs_diff = np.abs(facedx_df['timestamp'] - timestamp)\n",
    "        \n",
    "        # Check if the minimum difference is within 0.2\n",
    "        if (abs_diff.min() <= 0.2):\n",
    "            indices_to_keep.append(True)\n",
    "        else:\n",
    "            indices_to_keep.append(False)\n",
    "\n",
    "    # Filter openface_df using the indices_to_keep\n",
    "    filtered_openface_df = openface_df[indices_to_keep].reset_index(drop=True)\n",
    "    \n",
    "    return filtered_openface_df\n",
    "\n",
    "def filter_dictionaries(facedx_dict, openface_dict):\n",
    "    filtered_openface_dict = {}\n",
    "    for key in facedx_dict.keys():\n",
    "        # Assuming both dictionaries have the same keys\n",
    "        facedx_df = facedx_dict[key]\n",
    "        openface_df = openface_dict[key]\n",
    "        # Apply the optimized filtering function to each pair of DataFrames\n",
    "        filtered_openface_df = filter_by_timestamp_optimized(facedx_df, openface_df)\n",
    "        # Store the filtered DataFrame in the new dictionary with the same key\n",
    "        filtered_openface_dict[key] = filtered_openface_df\n",
    "    return filtered_openface_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs_openface_filtered = filter_dictionaries(dfs_opengraphau, dfs_openface)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs_openface_extras_filtered = filter_dictionaries(dfs_opengraphau, dfs_openface_extras)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EXPERIMENT - REMOVE FILTERING\n",
    "# dfs_openface_filtered = dfs_openface\n",
    "# dfs_openface_extras_filtered = dfs_openface_extras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yI5NrEUT6Kh6"
   },
   "source": [
    "# Select Specific Times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VRo0X-I78RnV"
   },
   "outputs": [],
   "source": [
    "# We will need these later (during feature extraction)\n",
    "\n",
    "\n",
    "def average_dfs(dfs):\n",
    "    if not dfs:\n",
    "        raise ValueError(\"The list of DataFrames is empty\")\n",
    "\n",
    "    # Ensure all DataFrames have the same shape and columns\n",
    "    shape = dfs[0].shape\n",
    "    columns = dfs[0].columns\n",
    "    for df in dfs:\n",
    "        if df.shape != shape or not df.columns.equals(columns):\n",
    "            raise ValueError(\"All DataFrames must have the same shape and columns\")\n",
    "    \n",
    "    # Initialize a DataFrame to store the result\n",
    "    avg_df = pd.DataFrame(index=dfs[0].index, columns=columns)\n",
    "    \n",
    "    # Iterate over each column to handle strings and numbers separately\n",
    "    for column in columns:\n",
    "        if pd.api.types.is_string_dtype(dfs[0][column]):\n",
    "            # If column is of string type, use the column from the first DataFrame\n",
    "            avg_df[column] = dfs[0][column]\n",
    "        else:\n",
    "            # Calculate the average for numeric columns\n",
    "            column_data = np.mean([df[column] for df in dfs], axis=0)\n",
    "            avg_df[column] = column_data\n",
    "\n",
    "    return avg_df\n",
    "\n",
    "\n",
    "def first_dfs(dfs):\n",
    "    # Take the first X-minute window's features!\n",
    "    return dfs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6mOSFkHtFvXg"
   },
   "outputs": [],
   "source": [
    "# Make them into lists of X minutes of valid data from each video\n",
    "\n",
    "TIME_INTERVALS = [5, 10]\n",
    "\n",
    "ENABLE_GRAPH_AND_HSE = False\n",
    "\n",
    "openface_radius_dict = {}\n",
    "openface_extras_radius_dict = {}\n",
    "if ENABLE_GRAPH_AND_HSE:\n",
    "    dfs_opengraphau_times = {}\n",
    "    dfs_hsemotion_times = {}\n",
    "\n",
    "for interval_now in TIME_INTERVALS:\n",
    "  dfs_openface_now = apply_function_to_dict(dfs_openface_filtered, take_time_subsets, num_mins=interval_now)\n",
    "  openface_radius_dict[interval_now] = dfs_openface_now\n",
    "  dfs_openface_extras_now = apply_function_to_dict(dfs_openface_extras_filtered, take_time_subsets, num_mins=interval_now)\n",
    "  openface_extras_radius_dict[interval_now] = dfs_openface_extras_now\n",
    "  if ENABLE_GRAPH_AND_HSE:\n",
    "      dfs_opengraphau_now = apply_function_to_dict(dfs_opengraphau, take_time_subsets, num_mins=interval_now)\n",
    "      dfs_opengraphau_times[interval_now] = dfs_opengraphau_now\n",
    "      dfs_hsemotion_now = apply_function_to_dict(dfs_hsemotion, take_time_subsets, num_mins=interval_now)\n",
    "      dfs_hsemotion_times[interval_now] = dfs_hsemotion_now"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DB4tQ4p-8y5h"
   },
   "source": [
    "# Feature Extraction 1.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b-FYeiEe8y5u"
   },
   "source": [
    "## AU --> Emotion & Lower/Upper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Xlf0hhZU8y5v"
   },
   "outputs": [],
   "source": [
    "# Define emotion to AU mapping\n",
    "\n",
    "# OpenDBM:\n",
    "emo_AUs = {'Happiness': [6, 12],\n",
    "           'Sadness': [1, 4, 15],\n",
    "           'Surprise': [1, 2, 5, 26],\n",
    "           'Fear': [1, 2, 4, 5, 7, 20, 26],\n",
    "           'Anger': [4, 5, 7, 23],\n",
    "           'Disgust': [9, 15, 16],\n",
    "           'Contempt': [12, 14]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "65HQiu4i8y5v"
   },
   "outputs": [],
   "source": [
    "# Define AU to lower/upper\n",
    "\n",
    "# OpenDBM:\n",
    "AU_lower = [12, 15, 26, 20, 23, 14]\n",
    "AU_upper = [6, 1, 4, 2, 5, 7, 9]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-uJ-q2cE8y5v"
   },
   "source": [
    "## Emotion Processing - HSEmotion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fqQtSBRY8y5v"
   },
   "outputs": [],
   "source": [
    "def only_successful_frames(df):\n",
    "    # get frames where AU/emotion detection was successful!\n",
    "    return df[df['success'] == 1]\n",
    "\n",
    "from scipy.stats import skew, kurtosis\n",
    "from statsmodels.tsa.stattools import acf\n",
    "\n",
    "def binarize_cols(df, threshold=0.5):\n",
    "  new_df = df.copy()\n",
    "  emotions = [col for col in new_df.columns if col not in ['frame', 'success', 'timestamp']]\n",
    "\n",
    "  for emotion in emotions:\n",
    "      new_df[f'{emotion}_Raw'] = new_df[emotion]\n",
    "      new_df[f'{emotion}_Binary'] = (new_df[f'{emotion}_Raw'] >= threshold).astype(int)\n",
    "\n",
    "  new_df = new_df.drop(columns=emotions, inplace=False)\n",
    "\n",
    "  return new_df\n",
    "\n",
    "\n",
    "def fill_empty_dfs_lists(dictionary):\n",
    "  # when we do emotion processing, some dfs will have ZERO successful frames,\n",
    "  # leading to ZERO events, and an empty df.\n",
    "  # we need to fill the empty dfs with a df with all 0s\n",
    "\n",
    "  non_empty_dfs = [[df for df in df_list if not df.empty] for df_list in dictionary.values()]\n",
    "\n",
    "  if not non_empty_dfs:\n",
    "      return dictionary  # Return the original dictionary if all DataFrames are empty\n",
    "\n",
    "  non_empty_df = non_empty_dfs[0][0]  # Choose the first non-empty DataFrame as replacement\n",
    "\n",
    "  modified_dictionary = {}\n",
    "  for key, df_list in dictionary.items():\n",
    "      modified_df_list = []\n",
    "      for df in df_list:\n",
    "        if df.empty:\n",
    "            modified_df = pd.DataFrame(0, index=non_empty_df.index, columns=non_empty_df.columns)\n",
    "            # Preserve string columns from non-empty DataFrame\n",
    "            for column in non_empty_df.columns:\n",
    "                if non_empty_df[column].dtype == object:\n",
    "                    modified_df[column] = non_empty_df[column]\n",
    "        else:\n",
    "            modified_df = df.copy()\n",
    "\n",
    "        modified_df_list.append(modified_df)\n",
    "\n",
    "      modified_dictionary[key] = modified_df_list\n",
    "\n",
    "  return modified_dictionary\n",
    "\n",
    "def analyze_emotion_events_v2(df, max_frame_gap=10, event_minimum_num_frames=1, method='HSE'):\n",
    "    df = df.reset_index(drop=True)\n",
    "\n",
    "    # Emotions to analyze\n",
    "    emotions_raw = [col for col in df.columns if col not in ['frame', 'success', 'timestamp']]\n",
    "    # Removing \"_Raw\" or \"_Binary\" from each string\n",
    "    processed_strings = [s.replace(\"_Raw\", \"\").replace(\"_Binary\", \"\") for s in emotions_raw]\n",
    "    # Eliminating duplicates\n",
    "    emotions = list(set(processed_strings))\n",
    "\n",
    "    # Create DataFrame for results\n",
    "    if STATS_FEATURE_SETTING == 0:\n",
    "        results_df = pd.DataFrame(index=['avg_event_length', 'avg_event_duration', 'total_num_events', 'avg_probability', 'std', 'skewness', 'kurtosis', 'autocorrelation', 'pres_pct'])\n",
    "    elif STATS_FEATURE_SETTING == 1 or (STATS_FEATURE_SETTING == 3 and method == 'HSE'):\n",
    "        results_df = pd.DataFrame(index=['avg_event_length', 'total_num_events', 'avg_probability', 'std', 'pres_pct'])\n",
    "    elif STATS_FEATURE_SETTING == 2:\n",
    "        results_df = pd.DataFrame(index=['pres_pct'])\n",
    "    elif STATS_FEATURE_SETTING == 3 and (method == 'OGAU' or method=='OF'):\n",
    "        results_df = pd.DataFrame(index=['pres_pct', 'total_num_events'])\n",
    "\n",
    "\n",
    "    def detect_events(emotion_binary_col):\n",
    "        probThreshold = 0.5 # irrelevant because it's a binary column\n",
    "        minInterval = max_frame_gap\n",
    "        minDuration = event_minimum_num_frames\n",
    "\n",
    "        probBinary = emotion_binary_col > probThreshold\n",
    "\n",
    "        # Using np.diff to find changes in the binary array\n",
    "        changes = np.diff(probBinary.astype(int))\n",
    "\n",
    "        # Identify start (1) and stop (-1) points\n",
    "        starts = np.where(changes == 1)[0] + 1  # +1 to correct the index shift caused by diff\n",
    "        stops = np.where(changes == -1)[0] + 1\n",
    "\n",
    "        # Adjust for edge cases\n",
    "        if probBinary.iloc[0]:\n",
    "            starts = np.insert(starts, 0, 0)\n",
    "        if probBinary.iloc[-1]:\n",
    "            stops = np.append(stops, len(probBinary))\n",
    "\n",
    "        # Merge close events and filter by duration\n",
    "        events = []\n",
    "        for start, stop in zip(starts, stops):\n",
    "\n",
    "            # Construct the event considering only indices where probBinary is 1\n",
    "            event = np.arange(start, stop)[probBinary[start:stop].values]\n",
    "\n",
    "            # Check if there is a previous event to potentially merge with\n",
    "            if events and event.size > 0 and events[-1][-1] >= start - minInterval:\n",
    "                # Merge with the previous event\n",
    "                events[-1] = np.unique(np.concatenate([events[-1], event]))\n",
    "            elif event.size >= event_minimum_num_frames:\n",
    "                events.append(event)\n",
    "\n",
    "        # Filter events by minimum duration\n",
    "        valid_events = [event for event in events if len(event) >= minDuration]\n",
    "\n",
    "        return valid_events\n",
    "\n",
    "    for emotion in emotions:\n",
    "        # Identify events\n",
    "        emotion_binary_col = df[f'{emotion}_Binary']\n",
    "        emotion_presence = df[f'{emotion}_Binary'].sum()\n",
    "        pres_pct = emotion_presence / len(df) * 100  # Percentage of frames where emotion is present\n",
    "        events = detect_events(emotion_binary_col)\n",
    "\n",
    "        if not(STATS_FEATURE_SETTING == 2):\n",
    "            # Calculate features for each event\n",
    "            if events:\n",
    "                event_lengths = [len(event) for event in events]\n",
    "                event_durations = [event[-1] - event[0] + 1 for event in events]\n",
    "                probabilities = [df.loc[event, f'{emotion}_Raw'].values for event in events]\n",
    "                probabilities_flattened = np.concatenate(probabilities)\n",
    "\n",
    "                avg_event_length = np.mean(event_lengths)\n",
    "                avg_event_duration = np.mean(event_durations)\n",
    "\n",
    "                total_num_events = len(events)\n",
    "\n",
    "                # NORMALIZE TOTAL NUM EVENTS BASED ON DF SIZE\n",
    "                # total_num_events = len(events) * 1000 / df.shape[0]\n",
    "\n",
    "                avg_probability = np.mean(probabilities_flattened)\n",
    "                std_dev = np.std(probabilities_flattened)\n",
    "                skewness_val = skew(probabilities_flattened)\n",
    "                kurtosis_val = kurtosis(probabilities_flattened)\n",
    "                autocorr = acf(probabilities_flattened, fft=True, nlags=1)[1] if len(probabilities_flattened) > 1 else 0\n",
    "            else:\n",
    "                avg_event_length = 0\n",
    "                avg_event_duration = 0\n",
    "                total_num_events = 0\n",
    "                avg_probability = 0\n",
    "                std_dev = 0\n",
    "                skewness_val = 0\n",
    "                kurtosis_val = 0\n",
    "                autocorr = 0\n",
    "\n",
    "        # Add results to the DataFrame\n",
    "        if STATS_FEATURE_SETTING == 0:\n",
    "            results_df[emotion] = [avg_event_length, avg_event_duration, total_num_events, avg_probability, std_dev, skewness_val, kurtosis_val, autocorr, pres_pct]\n",
    "        elif STATS_FEATURE_SETTING == 1 or (STATS_FEATURE_SETTING == 3 and method == 'HSE'):\n",
    "            results_df[emotion] = [avg_event_length, total_num_events, avg_probability, std_dev, pres_pct]\n",
    "        elif STATS_FEATURE_SETTING == 2:\n",
    "            results_df[emotion] = [pres_pct]\n",
    "        elif STATS_FEATURE_SETTING == 3 and (method == 'OGAU' or method=='OF'):\n",
    "            results_df[emotion] = [pres_pct, total_num_events]\n",
    "\n",
    "    # Replace NaN values with 0\n",
    "    results_df.fillna(0, inplace=True)\n",
    "\n",
    "    return results_df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qhVRg8xV8y5x"
   },
   "outputs": [],
   "source": [
    "import scipy.stats as stats\n",
    "\n",
    "def detect_emotions(df, method, emo_AUs, additional_filter=None):\n",
    "    # INPUT:\n",
    "    # df -- dataframe with AUs for each frame\n",
    "    # method -- must be 'OpenFace'\n",
    "    # emo_AUs -- the hash table\n",
    "    # additional_filter -- are we just doing lower half? upper half? This is None or a list of ints (which AUs to keep)\n",
    "\n",
    "    # OUTPUT:\n",
    "    # 3 datafrmes. Each has emotion values for each frame\n",
    "    # emo_hard, emo_soft, emo_binary (see OpenDBM docs for details)\n",
    "\n",
    "\n",
    "    if df.empty:\n",
    "      return (df, df, df)\n",
    "    # We start by mapping AUs to emotions for each of our two methods\n",
    "    # Using this mapping: https://aicure.github.io/open_dbm/docs/emotional-expressivity\n",
    "    if method == 'OpenFace':\n",
    "        columns = ['AU01_r','AU02_r', 'AU04_r', 'AU05_r', 'AU06_r', 'AU07_r', 'AU09_r', 'AU10_r',\n",
    "                    'AU12_r', 'AU14_r', 'AU15_r', 'AU17_r', 'AU20_r', 'AU23_r', 'AU25_r',\n",
    "                    'AU26_r', 'AU45_r',\n",
    "                    'AU01_c',\n",
    "                    'AU02_c',\n",
    "                    'AU04_c',\n",
    "                    'AU05_c',\n",
    "                    'AU06_c',\n",
    "                    'AU07_c',\n",
    "                    'AU09_c',\n",
    "                    'AU10_c',\n",
    "                    'AU12_c',\n",
    "                    'AU14_c',\n",
    "                    'AU15_c',\n",
    "                    'AU17_c',\n",
    "                    'AU20_c',\n",
    "                    'AU23_c',\n",
    "                    'AU25_c',\n",
    "                    'AU26_c',\n",
    "                    'AU45_c']\n",
    "\n",
    "        # hash tables for presence and intensity\n",
    "        emo_AUs_presence = {}\n",
    "        emo_AUs_intensity = {}\n",
    "        for key in emo_AUs.keys(): # loop through emotion strings\n",
    "            new_values_r = [] # regression\n",
    "            new_values_c = [] # classification\n",
    "\n",
    "            for value in emo_AUs[key]:\n",
    "                if isinstance(value, int):\n",
    "                    AU_key_r = \"AU{:02d}_r\".format(value)\n",
    "                    AU_key_c = \"AU{:02d}_c\".format(value)\n",
    "                    if AU_key_r in columns:\n",
    "                        if additional_filter is not None:\n",
    "                          if value in additional_filter:\n",
    "                            new_values_r.append(AU_key_r)\n",
    "                        else:\n",
    "                          new_values_r.append(AU_key_r)\n",
    "                    if AU_key_c in columns:\n",
    "                        if additional_filter is not None:\n",
    "                          if value in additional_filter:\n",
    "                            new_values_c.append(AU_key_c)\n",
    "                        else:\n",
    "                          new_values_c.append(AU_key_c)\n",
    "            if new_values_r:\n",
    "                emo_AUs_intensity[key] = new_values_r\n",
    "            if new_values_c:\n",
    "                emo_AUs_presence[key] = new_values_c\n",
    "\n",
    "    # elif method == 'OpenGraphAU':\n",
    "    #     raise ValueError(\"Invalid method parameter. Method must be 'OpenFace'.\")\n",
    "        # columns = ['AU1', 'AU2', 'AU4', 'AU5', 'AU6', 'AU7', 'AU9',\n",
    "        #            'AU10', 'AU11', 'AU12', 'AU13', 'AU14', 'AU15', 'AU16', 'AU17',\n",
    "        #            'AU18', 'AU19', 'AU20', 'AU22', 'AU23', 'AU24', 'AU25', 'AU26', 'AU27', 'AU32',\n",
    "        #            'AU38', 'AU39']\n",
    "\n",
    "        # # add the classification columns!\n",
    "        # columns = [item for sublist in [[col+'_r', col+'_c'] for col in columns] for item in sublist]\n",
    "\n",
    "        # # hash tables for presence and intensity\n",
    "        # emo_AUs_presence = {}\n",
    "        # emo_AUs_intensity = {}\n",
    "        # for key in emo_AUs.keys():\n",
    "        #     new_values_r = []\n",
    "        #     new_values_c = []\n",
    "        #     for value in emo_AUs[key]:\n",
    "        #         if isinstance(value, int):\n",
    "        #             AU_key_r = f\"AU{value}_r\"\n",
    "        #             AU_key_c = f\"AU{value}_c\"\n",
    "        #             if AU_key_r in columns:\n",
    "        #                 if additional_filter is not None:\n",
    "        #                   if value in additional_filter:\n",
    "        #                     new_values_r.append(AU_key_r)\n",
    "        #                 else:\n",
    "        #                   new_values_r.append(AU_key_r)\n",
    "        #             if AU_key_c in columns:\n",
    "        #                 if additional_filter is not None:\n",
    "        #                   if value in additional_filter:\n",
    "        #                     new_values_c.append(AU_key_c)\n",
    "        #                 else:\n",
    "        #                   new_values_c.append(AU_key_c)\n",
    "        #     if new_values_r:\n",
    "        #         emo_AUs_intensity[key] = new_values_r\n",
    "        #     if new_values_c:\n",
    "        #         emo_AUs_presence[key] = new_values_c\n",
    "\n",
    "    else:\n",
    "        # if the method specified is not OpenFace or OpenGraphAU, raise an error (pipeline doesn't support others yet)\n",
    "        raise ValueError(\"Invalid method parameter. Method must be 'OpenFace'.\")\n",
    "\n",
    "    # Create an empty dictionary to store the emotion scores\n",
    "    emotion_scores_hard = {} # only non-zero if all AUs present\n",
    "    emotion_scores_soft = {} # average of AU intensities even if all not present\n",
    "    emotion_scores_binary = {} # 1 or 0: are all AUs present?\n",
    "\n",
    "    # Compute emotion scores for each emotion\n",
    "    for emotion in emo_AUs_presence.keys():\n",
    "        # Get the relevant columns for presence and intensity\n",
    "        presence_cols = emo_AUs_presence[emotion]\n",
    "        intensity_cols = emo_AUs_intensity[emotion]\n",
    "\n",
    "        # Compute the emotion score for each row in the dataframe\n",
    "        emotion_scores_hard[emotion] = df[intensity_cols].mean(axis=1) * df[presence_cols].all(axis=1)\n",
    "        emotion_scores_hard[emotion] = emotion_scores_hard[emotion].fillna(0)\n",
    "\n",
    "        emotion_scores_soft[emotion] = df[intensity_cols].mean(axis=1)\n",
    "        emotion_scores_soft[emotion] = emotion_scores_soft[emotion].fillna(0)\n",
    "\n",
    "        emotion_scores_binary[emotion] = df[presence_cols].all(axis=1)\n",
    "        emotion_scores_binary[emotion] = emotion_scores_binary[emotion].fillna(0)\n",
    "\n",
    "    # Create a new dataframe with the emotion scores\n",
    "    emotion_df_hard = pd.DataFrame(emotion_scores_hard)\n",
    "    emotion_df_soft = pd.DataFrame(emotion_scores_soft)\n",
    "    emotion_df_binary = pd.DataFrame(emotion_scores_binary)\n",
    "    emotion_df_binary = emotion_df_binary.replace({False: 0, True: 1})\n",
    "\n",
    "    # Let's add timestamp and success on\n",
    "    columns_of_interest = ['timestamp', 'success']\n",
    "    df_temp = df[columns_of_interest]\n",
    "\n",
    "    # Concatenate the columns from df2 with df1\n",
    "    emotion_df_hard = pd.concat([df_temp, emotion_df_hard], axis=1)\n",
    "    emotion_df_soft = pd.concat([df_temp, emotion_df_soft], axis=1)\n",
    "    emotion_df_binary = pd.concat([df_temp, emotion_df_binary], axis=1)\n",
    "\n",
    "    return emotion_df_hard, emotion_df_soft, emotion_df_binary\n",
    "\n",
    "\n",
    "\n",
    "def detect_emotions_og(df, method, emo_AUs, additional_filter=None):\n",
    "    # INPUT:\n",
    "    # df -- dataframe with AUs for each frame\n",
    "    # method -- must be 'OpenGraphAU'\n",
    "    # emo_AUs -- the hash table\n",
    "    # additional_filter -- are we just doing lower half? upper half? This is None or a list of ints (which AUs to keep)\n",
    "\n",
    "    # OUTPUT:\n",
    "    # 1 datafrme with emotion values for each frame\n",
    "    # emo_binary (see OpenDBM docs for details)\n",
    "\n",
    "\n",
    "    if df.empty:\n",
    "      return df\n",
    "    # We start by mapping AUs to emotions for each of our two methods\n",
    "    # Using this mapping: https://aicure.github.io/open_dbm/docs/emotional-expressivity\n",
    "\n",
    "\n",
    "    if method == 'OpenGraphAU':\n",
    "        columns = ['AU1', 'AU2', 'AU4', 'AU5', 'AU6', 'AU7', 'AU9',\n",
    "                   'AU10', 'AU11', 'AU12', 'AU13', 'AU14', 'AU15', 'AU16', 'AU17',\n",
    "                   'AU18', 'AU19', 'AU20', 'AU22', 'AU23', 'AU24', 'AU25', 'AU26', 'AU27', 'AU32',\n",
    "                   'AU38', 'AU39']\n",
    "\n",
    "        # add the classification columns!\n",
    "        columns = [item for sublist in [[col+'_r', col+'_c'] for col in columns] for item in sublist]\n",
    "\n",
    "        # hash tables for presence and intensity\n",
    "        emo_AUs_presence = {}\n",
    "        for key in emo_AUs.keys():\n",
    "            new_values_c = []\n",
    "            for value in emo_AUs[key]:\n",
    "                if isinstance(value, int):\n",
    "                    AU_key_c = f\"AU{value}_c\"\n",
    "\n",
    "                    if AU_key_c in columns:\n",
    "                        if additional_filter is not None:\n",
    "                          if value in additional_filter:\n",
    "                            new_values_c.append(AU_key_c)\n",
    "                        else:\n",
    "                          new_values_c.append(AU_key_c)\n",
    "            if new_values_c:\n",
    "                emo_AUs_presence[key] = new_values_c\n",
    "\n",
    "    else:\n",
    "        # if the method specified is not OpenFace or OpenGraphAU, raise an error (pipeline doesn't support others yet)\n",
    "        raise ValueError(\"Invalid method parameter. Method must be 'OpenGraphAU'.\")\n",
    "\n",
    "    # Create an empty dictionary to store the emotion scores\n",
    "    emotion_scores_binary = {} # 1 or 0: are all AUs present?\n",
    "\n",
    "    # Compute emotion scores for each emotion\n",
    "    for emotion in emo_AUs_presence.keys():\n",
    "        # Get the relevant columns for presence\n",
    "        presence_cols = emo_AUs_presence[emotion]\n",
    "\n",
    "        # Compute the emotion score for each row in the dataframe\n",
    "        emotion_scores_binary[emotion] = df[presence_cols].all(axis=1)\n",
    "        emotion_scores_binary[emotion] = emotion_scores_binary[emotion].fillna(0)\n",
    "\n",
    "    # Create a new dataframe with the emotion scores\n",
    "    emotion_df_binary = pd.DataFrame(emotion_scores_binary)\n",
    "    emotion_df_binary = emotion_df_binary.replace({False: 0, True: 1})\n",
    "\n",
    "    # Let's add timestamp and success on\n",
    "    columns_of_interest = ['timestamp', 'success']\n",
    "    df_temp = df[columns_of_interest]\n",
    "\n",
    "    # Concatenate the columns from df2 with df1\n",
    "    emotion_df_binary = pd.concat([df_temp, emotion_df_binary], axis=1)\n",
    "\n",
    "    return emotion_df_binary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rD79SgOk8y5x"
   },
   "outputs": [],
   "source": [
    "# Raw Variables for Emotional Expressivity!\n",
    "\n",
    "openface_emoHardSoftPres_dict = {}\n",
    "\n",
    "# key: (df_emohard, df_emosoft, df_emopres)\n",
    "\n",
    "for time_radius, openface_radius_now in openface_radius_dict.items():\n",
    "  print('Time Radius: ', time_radius)\n",
    "  openface_emoHardSoftPres_dict[time_radius] = apply_function_to_dict_list(openface_radius_now, detect_emotions, method='OpenFace', emo_AUs=emo_AUs)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3aTyYbY_8y5y"
   },
   "outputs": [],
   "source": [
    "# This will help us get Raw Variables for Overall Expressivity!\n",
    "\n",
    "# key: (df_emohard, df_emosoft, df_emopres)\n",
    "\n",
    "\n",
    "\n",
    "openface_lowerHardSoftPres_dict = {}\n",
    "openface_upperHardSoftPres_dict = {}\n",
    "\n",
    "for time_radius, openface_radius_now in openface_radius_dict.items():\n",
    "  openface_lowerHardSoftPres_dict[time_radius] = apply_function_to_dict_list(openface_radius_now, detect_emotions, method='OpenFace', emo_AUs=emo_AUs, additional_filter=AU_lower)\n",
    "  openface_upperHardSoftPres_dict[time_radius] = apply_function_to_dict_list(openface_radius_now, detect_emotions, method='OpenFace', emo_AUs=emo_AUs, additional_filter=AU_upper)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NOxpw79n8y5y"
   },
   "source": [
    "### Apply Our HSEmotion Analysis to AU Detectors!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XMD_OvC8DMQT"
   },
   "outputs": [],
   "source": [
    "def openface_combine_and_binarize(soft_hard):\n",
    "    \"\"\"\n",
    "    Combine the middle and last dataframes from detect_emotions output,\n",
    "    with columns for AU raw and binary values renamed appropriately.\n",
    "\n",
    "    Parameters:\n",
    "    - soft_hard: a list of two DataFrames:\n",
    "      - emo_soft: DataFrame, the second output of detect_emotions, with AU raw values\n",
    "      - emo_binary: DataFrame, the third output of detect_emotions, with AU binary values\n",
    "\n",
    "    Returns:\n",
    "    - combined_df: DataFrame, combined dataframe with emotion raw and binary values.\n",
    "    \"\"\"\n",
    "    emo_soft, emo_binary = soft_hard\n",
    "\n",
    "    # Drop 'timestamp' and 'success' columns from emo_binary to prevent duplication\n",
    "    emo_binary = emo_binary.drop(['timestamp', 'success'], axis=1, errors='ignore')\n",
    "\n",
    "    # Rename columns in emo_soft and emo_binary for clarity\n",
    "    emo_soft_columns = {col: f\"{col}_Raw\" for col in emo_soft.columns if col not in ['success', 'timestamp', 'frame']}\n",
    "    emo_binary_columns = {col: f\"{col}_Binary\" for col in emo_binary.columns if col not in ['success', 'timestamp', 'frame']}\n",
    "\n",
    "    emo_soft_renamed = emo_soft.rename(columns=emo_soft_columns)\n",
    "    emo_binary_renamed = emo_binary.rename(columns=emo_binary_columns)\n",
    "\n",
    "    # Combine the dataframes\n",
    "    combined_df = pd.concat([emo_soft_renamed, emo_binary_renamed], axis=1)\n",
    "\n",
    "    return combined_df\n",
    "\n",
    "\n",
    "def take_second_from_tuple(input):\n",
    "    return input[1]\n",
    "\n",
    "\n",
    "def take_second_third_from_tuple(input):\n",
    "    return [input[1], input[2]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7E3yI5Px8y5y"
   },
   "outputs": [],
   "source": [
    "# Dictionary of dictionary of just soft values\n",
    "openface_emoSoft_dict = {}\n",
    "\n",
    "for time_radius, openface_emoHardSoftPres_now in openface_emoHardSoftPres_dict.items():\n",
    "  openface_emoSoft_dict[time_radius] = apply_function_to_dict_list(openface_emoHardSoftPres_now, take_second_from_tuple)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "x7F3VzdVEANl"
   },
   "outputs": [],
   "source": [
    "# Dictionary of list of two dictionaries: soft, presence (binary)\n",
    "openface_emoSoftPres_dict = {}\n",
    "\n",
    "for time_radius, openface_emoHardSoftPres_now in openface_emoHardSoftPres_dict.items():\n",
    "  openface_emoSoftPres_dict[time_radius] = apply_function_to_dict_list(openface_emoHardSoftPres_now, take_second_third_from_tuple)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3yjlJirn8y5z"
   },
   "outputs": [],
   "source": [
    "# OPENFACE - affect/emotions (longer term)\n",
    "openface_emo_stats_dict_list = {}\n",
    "\n",
    "for time_radius, openface_radius_list_now in openface_emoSoftPres_dict.items():\n",
    "  print('Time Radius: ', time_radius)\n",
    "  openface_binarized = apply_function_to_dict_list(openface_radius_list_now, openface_combine_and_binarize)\n",
    "  openface_emo_stats = apply_function_to_dict_list(openface_binarized, analyze_emotion_events_v2, max_frame_gap=10, event_minimum_num_frames=12, method='OF')\n",
    "  openface_emo_stats_fixed = fill_empty_dfs_lists(openface_emo_stats)\n",
    "  openface_emo_stats_dict_list[time_radius] = openface_emo_stats_fixed\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rCOKVIlcD1Br"
   },
   "outputs": [],
   "source": [
    "# OPENFACE - Averaging across time windows!\n",
    "\n",
    "openface_emo_stats_dict = {}\n",
    "\n",
    "\n",
    "for time_window, openface_radius_now in openface_emo_stats_dict_list.items():\n",
    "  print('Time Window: ', time_window)\n",
    "\n",
    "  openface_emo_stats_fixed = apply_function_to_dict(openface_radius_now, average_dfs)\n",
    "  openface_emo_stats_dict[time_window] = openface_emo_stats_fixed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gOCiRy5zyy8S"
   },
   "outputs": [],
   "source": [
    "# SAVE openface_emo_stats_dict\n",
    "save_var(openface_emo_stats_dict, forced_name=f'openface_emo_stats_dict_{PAT_NOW}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_W7Hypmc8y50"
   },
   "source": [
    "### Action Units"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "G5SMjpN_8y50"
   },
   "outputs": [],
   "source": [
    "def rename_columns(df):\n",
    "    \"\"\"\n",
    "    Renames the columns in a DataFrame according to specified pattern.\n",
    "\n",
    "    Args:\n",
    "        df (pandas DataFrame): The DataFrame to rename columns.\n",
    "\n",
    "    Returns:\n",
    "        pandas DataFrame: The DataFrame with renamed columns.\n",
    "    \"\"\"\n",
    "\n",
    "    # Copy the DataFrame\n",
    "    df_copy = df.copy()\n",
    "\n",
    "    # Define the mapping for renaming columns\n",
    "    column_mapping = {\n",
    "        '_r': 'int',\n",
    "        '_c': 'pres'\n",
    "    }\n",
    "\n",
    "    # Function to rename the columns\n",
    "    def rename_column(column_name):\n",
    "        au_number = column_name[2:4]\n",
    "        if au_number.endswith('_'):\n",
    "          au_number = '0' + au_number[0:1]\n",
    "        suffix = column_name[-2:]\n",
    "        if suffix in column_mapping:\n",
    "            return f'fac_au{au_number}{column_mapping[suffix]}'\n",
    "        else:\n",
    "            return column_name\n",
    "\n",
    "    # Rename the columns in the copied DataFrame\n",
    "    df_copy = df_copy.rename(columns=rename_column)\n",
    "\n",
    "    return df_copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nky4Wmx78y50"
   },
   "outputs": [],
   "source": [
    "def calculate_AU_statistics(df):\n",
    "    # Initialize an empty dictionary to store the computed statistics\n",
    "    stats = {'AU': [], 'pres_pct': [], 'int_mean': [], 'int_std': []}\n",
    "\n",
    "    # Iterate over the AU columns\n",
    "    for col in df.columns:\n",
    "        if col.startswith('fac_au') and ('pres' in col):\n",
    "            # Calculate the percentage of frames where AU is present\n",
    "            pres_pct = df[col].mean() * 100\n",
    "            # Extract the AU number\n",
    "            AU = col.split('au')[1][0:2]\n",
    "            # Calculate the mean and standard deviation of intensity for the AU\n",
    "            int_mean = df[f'fac_au{AU}int'].mean()\n",
    "            int_std = df[f'fac_au{AU}int'].std()\n",
    "\n",
    "            # Add the statistics to the dictionary\n",
    "            stats['AU'].append(AU)\n",
    "            stats['pres_pct'].append(pres_pct)\n",
    "            stats['int_mean'].append(int_mean)\n",
    "            stats['int_std'].append(int_std)\n",
    "\n",
    "    # Create a DataFrame from the dictionary of statistics\n",
    "    stats_df = pd.DataFrame(stats)\n",
    "\n",
    "    return stats_df\n",
    "\n",
    "def calculate_AU_statistics_og(df):\n",
    "    # Stats for ONLY binary columns!\n",
    "    # Initialize an empty dictionary to store the computed statistics\n",
    "    stats = {'AU': [], 'pres_pct': []}\n",
    "\n",
    "    # Iterate over the AU columns\n",
    "    for col in df.columns:\n",
    "        if col.startswith('fac_au') and ('pres' in col):\n",
    "            # Calculate the percentage of frames where AU is present\n",
    "            pres_pct = df[col].mean() * 100\n",
    "            # Extract the AU number\n",
    "            AU = col.split('au')[1][0:2]\n",
    "\n",
    "            # Add the statistics to the dictionary\n",
    "            stats['AU'].append(AU)\n",
    "            stats['pres_pct'].append(pres_pct)\n",
    "\n",
    "    # Create a DataFrame from the dictionary of statistics\n",
    "    stats_df = pd.DataFrame(stats)\n",
    "\n",
    "    return stats_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FVs4H8V88y50"
   },
   "outputs": [],
   "source": [
    "# Raw Variables!\n",
    "openface_radius_renamed_dict = {}\n",
    "\n",
    "for time_radius, openface_radius_now in openface_radius_dict.items():\n",
    "  openface_radius_renamed_dict[time_radius] = apply_function_to_dict_list(openface_radius_now, rename_columns)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sF_1vBU08y50"
   },
   "outputs": [],
   "source": [
    "# Derived Variables!\n",
    "openface_au_derived_dict_list = {}\n",
    "\n",
    "for time_radius, openface_radius_renamed_now in openface_radius_renamed_dict.items():\n",
    "  openface_au_derived_dict_list[time_radius] = apply_function_to_dict_list(openface_radius_renamed_now, calculate_AU_statistics)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yZpqM5_DFfLN"
   },
   "outputs": [],
   "source": [
    "# OPENFACE - Averaging across time windows!\n",
    "\n",
    "openface_au_derived_dict = {}\n",
    "\n",
    "\n",
    "for time_window, openface_radius_now in openface_au_derived_dict_list.items():\n",
    "  print('Time Window: ', time_window)\n",
    "\n",
    "  openface_au_derived_fixed = apply_function_to_dict(openface_radius_now, average_dfs)\n",
    "  openface_au_derived_dict[time_window] = openface_au_derived_fixed\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Vp3yVpbD8y51"
   },
   "source": [
    "### Emotional Expressivity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TLp3I5py8y51"
   },
   "outputs": [],
   "source": [
    "def calculate_emotion_express_statistics(tuple_to_unpack):\n",
    "    \"\"\"\n",
    "    Calculates statistics for each emotion in the given DataFrames.\n",
    "\n",
    "    Args:\n",
    "        tuple_to_unpack: 3-membered tuple that has:\n",
    "          df_emo_inthard (pandas DataFrame): DataFrame with emotion intensity (hard) values.\n",
    "          df_emo_intsoft (pandas DataFrame): DataFrame with emotion intensity (soft) values.\n",
    "          df_emo_pres (pandas DataFrame): DataFrame with emotion presence values.\n",
    "\n",
    "    Returns:\n",
    "        pandas DataFrame: A DataFrame with statistics for each emotion.\n",
    "    \"\"\"\n",
    "    df_emo_inthard, df_emo_intsoft, df_emo_pres = tuple_to_unpack\n",
    "    stats = {'emotion': [], 'pres_pct': [], 'intsoft_mean': [], 'intsoft_std': [], 'inthard_mean': []}\n",
    "\n",
    "    emotions = [col for col in df_emo_inthard.columns if col not in ['timestamp', 'success']]\n",
    "\n",
    "    for emotion in emotions:\n",
    "        pres_pct = (df_emo_pres[emotion] == 1).mean() * 100\n",
    "        intsoft_mean = df_emo_intsoft[emotion].mean()\n",
    "        intsoft_std = df_emo_intsoft[emotion].std()\n",
    "        inthard_mean = df_emo_inthard[emotion].mean()\n",
    "\n",
    "        stats['emotion'].append(emotion)\n",
    "        stats['pres_pct'].append(pres_pct)\n",
    "        stats['intsoft_mean'].append(intsoft_mean)\n",
    "        stats['intsoft_std'].append(intsoft_std)\n",
    "        stats['inthard_mean'].append(inthard_mean)\n",
    "\n",
    "    stats_df = pd.DataFrame(stats)\n",
    "    return stats_df\n",
    "\n",
    "def calculate_ee_stats_og(df_emo_pres):\n",
    "    \"\"\"\n",
    "    Calculates statistics for each emotion in the given DataFrame.\n",
    "\n",
    "    Args:\n",
    "        df_emo_pres (pandas DataFrame): DataFrame with emotion presence values.\n",
    "\n",
    "    Returns:\n",
    "        pandas DataFrame: A DataFrame with statistics for each emotion.\n",
    "    \"\"\"\n",
    "    stats = {'emotion': [], 'pres_pct': []}\n",
    "\n",
    "    emotions = [col for col in df_emo_pres.columns if col not in ['timestamp', 'success']]\n",
    "\n",
    "    for emotion in emotions:\n",
    "        pres_pct = (df_emo_pres[emotion] == 1).mean() * 100\n",
    "\n",
    "\n",
    "        stats['emotion'].append(emotion)\n",
    "        stats['pres_pct'].append(pres_pct)\n",
    "\n",
    "    stats_df = pd.DataFrame(stats)\n",
    "    return stats_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7FXhU4Iz8y51"
   },
   "outputs": [],
   "source": [
    "def calculate_ee_stats_hse(df, threshold):\n",
    "    \"\"\"\n",
    "    Calculates statistics for each emotion in the given DataFrame.\n",
    "\n",
    "    Args:\n",
    "    df with emotion intensities for every video frame\n",
    "    threshold for presence of emotion (i.e. 0.5)\n",
    "\n",
    "    Returns:\n",
    "        pandas DataFrame: A DataFrame with statistics for each emotion.\n",
    "    \"\"\"\n",
    "    df_emo_intsoft = df\n",
    "    stats = {'emotion': [], 'pres_pct': [], 'intsoft_mean': [], 'intsoft_std': []}\n",
    "\n",
    "    emotions = [col for col in df_emo_intsoft.columns if col not in ['timestamp', 'success']]\n",
    "\n",
    "    for emotion in emotions:\n",
    "        pres_pct = (df_emo_intsoft[emotion] >= threshold).mean() * 100\n",
    "        intsoft_mean = df_emo_intsoft[emotion].mean()\n",
    "        intsoft_std = df_emo_intsoft[emotion].std()\n",
    "\n",
    "        stats['emotion'].append(emotion)\n",
    "        stats['pres_pct'].append(pres_pct)\n",
    "        stats['intsoft_mean'].append(intsoft_mean)\n",
    "        stats['intsoft_std'].append(intsoft_std)\n",
    "\n",
    "    stats_df = pd.DataFrame(stats)\n",
    "    return stats_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rAzD1DiS8y51"
   },
   "outputs": [],
   "source": [
    "# Raw Variables for Emotional Expressivity were calculated above:\n",
    "# openface_emoHardSoftPres\n",
    "# opengraphau_emoHardSoftPres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NyqXL1I48y51"
   },
   "outputs": [],
   "source": [
    "# Derived Variables for Emotional Expressivity\n",
    "openface_ee_derived_dict_list = {}\n",
    "\n",
    "for time_radius, openface_emoHardSoftPres_now in openface_emoHardSoftPres_dict.items():\n",
    "  openface_ee_derived_dict_list[time_radius] = apply_function_to_dict_list(openface_emoHardSoftPres_now, calculate_emotion_express_statistics)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BElderrnGcai"
   },
   "outputs": [],
   "source": [
    "# OPENFACE - Averaging across time windows!\n",
    "\n",
    "openface_ee_derived_dict = {}\n",
    "\n",
    "\n",
    "for time_window, openface_radius_now in openface_ee_derived_dict_list.items():\n",
    "  print('Time Window: ', time_window)\n",
    "\n",
    "  openface_ee_stats_fixed = apply_function_to_dict(openface_radius_now, average_dfs)\n",
    "  openface_ee_derived_dict[time_window] = openface_ee_stats_fixed\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0k1l_WRt8y52"
   },
   "source": [
    "### Overall Expressivity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hpnTVApQ8y53"
   },
   "outputs": [],
   "source": [
    "def compute_oe_raw_vars(regular_tuple, lower_tuple, upper_tuple):\n",
    "    # Takes in 3 3-membered tuples, each of which should be hardSoftPres\n",
    "    # regular, lower, upper\n",
    "\n",
    "    # Outputs one df with the raw variables for overall expressivity\n",
    "\n",
    "    df_emo_inthard, df_emo_intsoft, df_emo_pres = regular_tuple\n",
    "    df_emo_inthard_lower, df_emo_intsoft_lower, df_emo_pres_lower = lower_tuple\n",
    "    df_emo_inthard_upper, df_emo_intsoft_upper, df_emo_pres_upper = upper_tuple\n",
    "\n",
    "    # Calculate the average values for emo_intsoft and emo_inthard across all frames\n",
    "    avg_emo_intsoft = df_emo_intsoft.mean(axis=1)\n",
    "    avg_emo_inthard = df_emo_inthard.mean(axis=1)\n",
    "\n",
    "    # Calculate lower and upper averages across all frames\n",
    "    avg_emo_intsoft_lower = df_emo_intsoft_lower.mean(axis=1)\n",
    "    avg_emo_inthard_lower = df_emo_inthard_lower.mean(axis=1)\n",
    "    avg_emo_intsoft_upper = df_emo_intsoft_upper.mean(axis=1)\n",
    "    avg_emo_inthard_upper = df_emo_inthard_upper.mean(axis=1)\n",
    "\n",
    "    # Create a new dataframe with the computed statistics\n",
    "    stats_df = pd.DataFrame({'comintsoft': avg_emo_intsoft, 'cominthard': avg_emo_inthard,\n",
    "                             'comlowintsoft': avg_emo_intsoft_lower, 'comlowinthard': avg_emo_inthard_lower,\n",
    "                             'comuppintsoft': avg_emo_intsoft_upper, 'comuppinthard': avg_emo_inthard_upper,})\n",
    "\n",
    "    return stats_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "95mBcMYz8y53"
   },
   "outputs": [],
   "source": [
    "def apply_function_to_dict_three(d1, d2, d3, func, **kwargs):\n",
    "    \"\"\"\n",
    "    Apply a function that takes in 3 dfs and return a modified dictionary\n",
    "\n",
    "    Args:\n",
    "        d1, d2, d3: The dictionaries containing DataFrames.\n",
    "        func (function): The function to apply to each DataFrame.\n",
    "        **kwargs: Additional keyword arguments to pass to the function.\n",
    "\n",
    "    Returns:\n",
    "        dict_final: A modified copy of the dictionary with the function applied to each DataFrame.\n",
    "    \"\"\"\n",
    "    dict_final = {}\n",
    "    for key in d1.keys():\n",
    "      dict_final[key] = func(d1[key], d2[key], d3[key], **kwargs)\n",
    "\n",
    "    return dict_final\n",
    "\n",
    "def apply_function_to_dict_three_list(d1, d2, d3, func, **kwargs):\n",
    "    \"\"\"\n",
    "    Apply a function that takes in 3 dfs and return a modified dictionary\n",
    "\n",
    "    Args:\n",
    "        d1, d2, d3: The dictionaries containing LISTS of DataFrames.\n",
    "        func (function): The function to apply to each DataFrame.\n",
    "        **kwargs: Additional keyword arguments to pass to the function.\n",
    "\n",
    "    Returns:\n",
    "        dict_final: A modified copy of the dictionary with the function applied to each DataFrame in each list!\n",
    "    \"\"\"\n",
    "    dict_final = {}\n",
    "    for key in d1.keys():\n",
    "      num_in_list = len(d1[key])\n",
    "      list_building = []\n",
    "      for i in range(num_in_list):\n",
    "        list_building.append(func(d1[key][i], d2[key][i], d3[key][i], **kwargs))\n",
    "      \n",
    "      dict_final[key] = list_building\n",
    "        \n",
    "\n",
    "    return dict_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "I8xa0YU68y53"
   },
   "outputs": [],
   "source": [
    "# Raw Variables for Overall Expressivity!\n",
    "\n",
    "#openface_oe_raw = apply_function_to_dict_three(openface_emoHardSoftPres, openface_lowerHardSoftPres, openface_upperHardSoftPres, compute_oe_raw_vars)\n",
    "#opengraphau_oe_raw = apply_function_to_dict_three(opengraphau_emoHardSoftPres, opengraphau_lowerHardSoftPres, opengraphau_upperHardSoftPres, compute_oe_raw_vars)\n",
    "\n",
    "\n",
    "openface_oe_raw_dict_list = {}\n",
    "\n",
    "\n",
    "# Loop through the dictionaries and sample one item from each with the same key\n",
    "for key in openface_emoHardSoftPres_dict.keys():\n",
    "    openface_emo = openface_emoHardSoftPres_dict[key]\n",
    "    openface_lower = openface_lowerHardSoftPres_dict[key]\n",
    "    openface_upper = openface_upperHardSoftPres_dict[key]\n",
    "\n",
    "    # Call the compute_oe_raw_vars function with the sampled items\n",
    "    openface_oe_raw_dict_list[key] = apply_function_to_dict_three_list(openface_emo, openface_lower, openface_upper, compute_oe_raw_vars)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "f30AmaOz8y53"
   },
   "outputs": [],
   "source": [
    "def calculate_oe_summary_statistics(df):\n",
    "    # Compute comintsoft_pct\n",
    "    comintsoft_pct = (df['comintsoft'] > 0).mean() * 100\n",
    "\n",
    "    # Compute comintsoft_mean and comintsoft_std\n",
    "    comintsoft_mean = df['comintsoft'].mean()\n",
    "    comintsoft_std = df['comintsoft'].std()\n",
    "\n",
    "    # Compute cominthard_mean and cominthard_std\n",
    "    cominthard_mean = df['cominthard'].mean()\n",
    "    cominthard_std = df['cominthard'].std()\n",
    "\n",
    "    # Compute comlowintsoft_pct\n",
    "    comlowintsoft_pct = (df['comlowintsoft'] > 0).mean() * 100\n",
    "\n",
    "    # Compute comlowintsoft_mean and comlowintsoft_std\n",
    "    comlowintsoft_mean = df['comlowintsoft'].mean()\n",
    "    comlowintsoft_std = df['comlowintsoft'].std()\n",
    "\n",
    "    # Compute comuppinthard_mean and comuppinthard_std\n",
    "    comuppinthard_mean = df['comuppinthard'].mean()\n",
    "    comuppinthard_std = df['comuppinthard'].std()\n",
    "\n",
    "    # Create a new DataFrame with the summary statistics\n",
    "    summary_df = pd.DataFrame({\n",
    "        'comintsoft_pct': [comintsoft_pct],\n",
    "        'comintsoft_mean': [comintsoft_mean],\n",
    "        'comintsoft_std': [comintsoft_std],\n",
    "        'cominthard_mean': [cominthard_mean],\n",
    "        'cominthard_std': [cominthard_std],\n",
    "        'comlowintsoft_pct': [comlowintsoft_pct],\n",
    "        'comlowintsoft_mean': [comlowintsoft_mean],\n",
    "        'comlowintsoft_std': [comlowintsoft_std],\n",
    "        'comuppinthard_mean': [comuppinthard_mean],\n",
    "        'comuppinthard_std': [comuppinthard_std]\n",
    "    })\n",
    "\n",
    "    return summary_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "18AjXrL48y53"
   },
   "outputs": [],
   "source": [
    "# Derived Variables for Overall Expressivity!\n",
    "\n",
    "openface_oe_derived_dict_list = {}\n",
    "\n",
    "for time_radius, openface_oe_raw_now in openface_oe_raw_dict_list.items():\n",
    "  openface_oe_derived_dict_list[time_radius] = apply_function_to_dict_list(openface_oe_raw_now, calculate_oe_summary_statistics)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "s7hT3bf9GsFc"
   },
   "outputs": [],
   "source": [
    "# OPENFACE - Averaging across time windows!\n",
    "\n",
    "openface_oe_derived_dict = {}\n",
    "\n",
    "\n",
    "for time_window, openface_radius_now in openface_oe_derived_dict_list.items():\n",
    "  print('Time Window: ', time_window)\n",
    "\n",
    "  openface_oe_stats_fixed = apply_function_to_dict(openface_radius_now, average_dfs)\n",
    "  openface_oe_derived_dict[time_window] = openface_oe_stats_fixed\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Head Movement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_head_movement(df):\n",
    "    # Ensure the pose columns are floats\n",
    "    pose_cols = ['pose_Tx', 'pose_Ty', 'pose_Tz', 'pose_Rx', 'pose_Ry', 'pose_Rz']\n",
    "    df[pose_cols] = df[pose_cols].astype(float)\n",
    "    \n",
    "    # Calculate Euclidean head movement (displacement)\n",
    "    df['mov_headvel'] = np.sqrt(df[['pose_Tx', 'pose_Ty', 'pose_Tz']].diff().fillna(0).pow(2).sum(axis=1))\n",
    "    \n",
    "    # Assign frame-wise pitch, yaw, and roll directly from pose_Rx, pose_Ry, pose_Rz\n",
    "    df['mov_hposepitch'] = df['pose_Rx']\n",
    "    df['mov_hposeyaw'] = df['pose_Ry']\n",
    "    df['mov_hposeroll'] = df['pose_Rz']\n",
    "    \n",
    "    # Calculate angular head movement using diff for pose_Rx, pose_Ry, pose_Rz, then take Euclidean norm\n",
    "    df['mov_hposedist'] = np.sqrt(df[['pose_Rx', 'pose_Ry', 'pose_Rz']].diff().fillna(0).pow(2).sum(axis=1))\n",
    "    \n",
    "    # Calculate mean and std for the new variables\n",
    "    output_dict = {}\n",
    "    variables = ['mov_headvel', 'mov_hposepitch', 'mov_hposeyaw', 'mov_hposeroll', 'mov_hposedist']\n",
    "    for var in variables:\n",
    "        output_dict[f\"{var}_mean\"] = df[var].mean()\n",
    "        output_dict[f\"{var}_std\"] = df[var].std()\n",
    "    \n",
    "    # Create output DataFrame from the output_dict\n",
    "    output_df = pd.DataFrame([output_dict])\n",
    "    \n",
    "    return output_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Derived Variables for Head Movement!\n",
    "\n",
    "openface_hm_derived_dict_list = {}\n",
    "\n",
    "for time_radius, openface_radius_now in openface_extras_radius_dict.items():\n",
    "  openface_hm_derived_dict_list[time_radius] = apply_function_to_dict_list(openface_radius_now, process_head_movement)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OPENFACE - Averaging across time windows!\n",
    "\n",
    "openface_hm_derived_dict = {}\n",
    "\n",
    "\n",
    "for time_window, openface_radius_now in openface_hm_derived_dict_list.items():\n",
    "  print('Time Window: ', time_window)\n",
    "\n",
    "  openface_hm_stats_fixed = apply_function_to_dict(openface_radius_now, average_dfs)\n",
    "  openface_hm_derived_dict[time_window] = openface_hm_stats_fixed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Eye Gaze Directionality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_gaze_data(df):\n",
    "    # Ensure all gaze-related columns are floats\n",
    "    gaze_cols = ['gaze_0_x', 'gaze_0_y', 'gaze_0_z', 'gaze_1_x', 'gaze_1_y', 'gaze_1_z']\n",
    "    df[gaze_cols] = df[gaze_cols].astype(float)\n",
    "    \n",
    "    # Initialize output dictionary\n",
    "    output_dict = {}\n",
    "    \n",
    "    # Mapping for renaming\n",
    "    rename_map = {\n",
    "        'gaze_0_x': 'righteyex', 'gaze_0_y': 'righteyey', 'gaze_0_z': 'righteyez',\n",
    "        'gaze_1_x': 'lefteyex', 'gaze_1_y': 'lefteyey', 'gaze_1_z': 'lefteyez'\n",
    "    }\n",
    "    \n",
    "    # Calculate mean and std for each gaze direction component and rename\n",
    "    for col in gaze_cols:\n",
    "        new_base_name = rename_map[col]\n",
    "        output_dict[f\"mov_{new_base_name}_mean\"] = df[col].mean()\n",
    "        output_dict[f\"mov_{new_base_name}_std\"] = df[col].std()\n",
    "    \n",
    "    # Calculate Euclidean displacement for each eye in each frame\n",
    "    df['mov_leyedisp'] = np.sqrt((df['gaze_1_x'].diff()**2 + df['gaze_1_y'].diff()**2 + df['gaze_1_z'].diff()**2).fillna(0))\n",
    "    df['mov_reyedisp'] = np.sqrt((df['gaze_0_x'].diff()**2 + df['gaze_0_y'].diff()**2 + df['gaze_0_z'].diff()**2).fillna(0))\n",
    "    \n",
    "    # Add mean and std for the Euclidean displacements to output dict\n",
    "    output_dict['mov_leyedisp_mean'] = df['mov_leyedisp'].mean()\n",
    "    output_dict['mov_leyedisp_std'] = df['mov_leyedisp'].std()\n",
    "    output_dict['mov_reyedisp_mean'] = df['mov_reyedisp'].mean()\n",
    "    output_dict['mov_reyedisp_std'] = df['mov_reyedisp'].std()\n",
    "    \n",
    "    # Create output DataFrame from the output_dict\n",
    "    output_df = pd.DataFrame([output_dict])\n",
    "    \n",
    "    return output_df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Derived Variables for Head Movement!\n",
    "\n",
    "openface_eg_derived_dict_list = {}\n",
    "\n",
    "for time_radius, openface_radius_now in openface_extras_radius_dict.items():\n",
    "  openface_eg_derived_dict_list[time_radius] = apply_function_to_dict_list(openface_radius_now, process_gaze_data)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OPENFACE - Averaging across time windows!\n",
    "\n",
    "openface_eg_derived_dict = {}\n",
    "\n",
    "\n",
    "for time_window, openface_radius_now in openface_eg_derived_dict_list.items():\n",
    "  print('Time Window: ', time_window)\n",
    "\n",
    "  openface_eg_stats_fixed = apply_function_to_dict(openface_radius_now, average_dfs)\n",
    "  openface_eg_derived_dict[time_window] = openface_eg_stats_fixed\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Eye Blink Behavior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial.distance import euclidean\n",
    "\n",
    "def compute_ear(row):\n",
    "    # Right eye\n",
    "    d1 = euclidean((row['eye_lmk_X_10'], row['eye_lmk_Y_10'], row['eye_lmk_Z_10']), (row['eye_lmk_X_18'], row['eye_lmk_Y_18'], row['eye_lmk_Z_18']))\n",
    "    d2 = euclidean((row['eye_lmk_X_12'], row['eye_lmk_Y_12'], row['eye_lmk_Z_12']), (row['eye_lmk_X_16'], row['eye_lmk_Y_16'], row['eye_lmk_Z_16']))\n",
    "    d3 = euclidean((row['eye_lmk_X_8'], row['eye_lmk_Y_8'], row['eye_lmk_Z_8']), (row['eye_lmk_X_14'], row['eye_lmk_Y_14'], row['eye_lmk_Z_14']))\n",
    "    right_ear = (d1 + d2) / (2.0 * d3)\n",
    "    \n",
    "    # Left eye\n",
    "    d4 = euclidean((row['eye_lmk_X_38'], row['eye_lmk_Y_38'], row['eye_lmk_Z_38']), (row['eye_lmk_X_46'], row['eye_lmk_Y_46'], row['eye_lmk_Z_46']))\n",
    "    d5 = euclidean((row['eye_lmk_X_40'], row['eye_lmk_Y_40'], row['eye_lmk_Z_40']), (row['eye_lmk_X_44'], row['eye_lmk_Y_44'], row['eye_lmk_Z_44']))\n",
    "    d6 = euclidean((row['eye_lmk_X_36'], row['eye_lmk_Y_36'], row['eye_lmk_Z_36']), (row['eye_lmk_X_42'], row['eye_lmk_Y_42'], row['eye_lmk_Z_42']))\n",
    "    left_ear = (d4 + d5) / (2.0 * d6)\n",
    "    \n",
    "    # Overall EAR\n",
    "    return (right_ear + left_ear) / 2.0\n",
    "\n",
    "def ebb_process_video_df(df):\n",
    "    \n",
    "    # Calculate EAR for each frame\n",
    "    df['EAR'] = df.apply(compute_ear, axis=1)\n",
    "    \n",
    "    # Identify frames where a blink occurs\n",
    "    df['is_blink'] = (df['EAR'] < 0.2) & (df['EAR'].shift(1) >= 0.2)\n",
    "    \n",
    "    # For each blink, find the timestamp difference to the previous blink\n",
    "    blink_timestamps = df[df['is_blink']]['timestamp']\n",
    "    mov_blinkdur = blink_timestamps.diff().fillna(0)  # This calculates the time between blinks\n",
    "\n",
    "    # Initialize all values at zero\n",
    "    features = {\n",
    "        'mov_blink_ear_mean': 0,\n",
    "        'mov_blink_ear_std': 0,\n",
    "        'mov_blink_count': 0,\n",
    "        'mov_blinkdur_mean': 0,\n",
    "        'mov_blinkdur_std': 0\n",
    "    }\n",
    "\n",
    "    \n",
    "    if df['is_blink'].sum() > 0:\n",
    "        # Calculate requested features\n",
    "        blink_ear_values = df[df['is_blink']]['EAR']\n",
    "        features = {\n",
    "            'mov_blink_ear_mean': blink_ear_values.mean(),\n",
    "            'mov_blink_ear_std': 0 if np.isnan(blink_ear_values.std()) else blink_ear_values.std(),\n",
    "            'mov_blink_count': df['is_blink'].sum(),\n",
    "            'mov_blinkdur_mean': mov_blinkdur.mean(),\n",
    "            'mov_blinkdur_std': 0 if np.isnan(mov_blinkdur.std()) else mov_blinkdur.std(),\n",
    "        }\n",
    "    \n",
    "    return pd.DataFrame([features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Derived Variables for Eye Blink Behavior!\n",
    "\n",
    "openface_ebb_derived_dict_list = {}\n",
    "\n",
    "for time_radius, openface_radius_now in openface_extras_radius_dict.items():\n",
    "  openface_ebb_derived_dict_list[time_radius] = apply_function_to_dict_list(openface_radius_now, ebb_process_video_df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OPENFACE - Averaging across time windows!\n",
    "\n",
    "openface_ebb_derived_dict = {}\n",
    "\n",
    "\n",
    "for time_window, openface_radius_now in openface_ebb_derived_dict_list.items():\n",
    "  print('Time Window: ', time_window)\n",
    "\n",
    "  openface_ebb_stats_fixed = apply_function_to_dict(openface_radius_now, average_dfs)\n",
    "  openface_ebb_derived_dict[time_window] = openface_ebb_stats_fixed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Facial Landmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fl_process_video_df(df):\n",
    "    # Preparing the column names for X, Y, Z coordinates\n",
    "    x_cols = [f'X_{i}' for i in range(68)]\n",
    "    y_cols = [f'Y_{i}' for i in range(68)]\n",
    "    z_cols = [f'Z_{i}' for i in range(68)]\n",
    "    \n",
    "    # Calculating the displacement for each landmark across frames\n",
    "    disp_cols = []\n",
    "    for x_col, y_col, z_col in zip(x_cols, y_cols, z_cols):\n",
    "        disp_col = f'{x_col}_disp'\n",
    "        df[disp_col] = np.sqrt((df[x_col].diff() ** 2) + (df[y_col].diff() ** 2) + (df[z_col].diff() ** 2))\n",
    "        disp_cols.append(disp_col)\n",
    "    \n",
    "    # Calculating the mean and standard deviation of displacements for each landmark\n",
    "    output_df = pd.DataFrame()\n",
    "    for col in disp_cols:\n",
    "        landmark_num = col.split('_')[1]\n",
    "        output_df[f'fac_lmk{landmark_num}disp_mean'] = [df[col].mean()]\n",
    "        output_df[f'fac_lmk{landmark_num}disp_std'] = [df[col].std()]\n",
    "    \n",
    "    # Return a DataFrame with calculated mean and standard deviation for each landmark displacement\n",
    "    return output_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Derived Variables for Facial Landmark!\n",
    "\n",
    "openface_fl_derived_dict_list = {}\n",
    "\n",
    "for time_radius, openface_radius_now in openface_extras_radius_dict.items():\n",
    "  openface_fl_derived_dict_list[time_radius] = apply_function_to_dict_list(openface_radius_now, fl_process_video_df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OPENFACE - Averaging across time windows!\n",
    "\n",
    "openface_fl_derived_dict = {}\n",
    "\n",
    "\n",
    "for time_window, openface_radius_now in openface_fl_derived_dict_list.items():\n",
    "  print('Time Window: ', time_window)\n",
    "\n",
    "  openface_fl_stats_fixed = apply_function_to_dict(openface_radius_now, average_dfs)\n",
    "  openface_fl_derived_dict[time_window] = openface_fl_stats_fixed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Facial Tremor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_fac_tremor(df, window_size=5):\n",
    "    # Pad the DataFrame at the beginning and end to handle edge cases\n",
    "    df_padded = pd.concat([df.iloc[:window_size-1].copy(), df, df.iloc[-window_size+1:].copy()]).reset_index(drop=True)\n",
    "    \n",
    "    # Initialize a DataFrame to hold the median tremor values for each landmark\n",
    "    tremor_medians = pd.DataFrame()\n",
    "    \n",
    "    for i in range(68):  # For each landmark\n",
    "        # Prepare column names\n",
    "        x_col = f'X_{i}'\n",
    "        y_col = f'Y_{i}'\n",
    "        z_col = f'Z_{i}'\n",
    "        \n",
    "        # Calculate rolling mean positions\n",
    "        rolling_means = df_padded[[x_col, y_col, z_col]].rolling(window=window_size, center=True).mean()\n",
    "        \n",
    "        # Calculate Euclidean distance from each frame's position to the rolling mean position\n",
    "        distances = np.sqrt((df_padded[x_col] - rolling_means[x_col])**2 + \n",
    "                            (df_padded[y_col] - rolling_means[y_col])**2 + \n",
    "                            (df_padded[z_col] - rolling_means[z_col])**2)\n",
    "        \n",
    "        # Calculate median of distances for each window\n",
    "        tremor_median = distances.rolling(window=window_size, center=True).median()\n",
    "        \n",
    "        # Append the median tremor value for the landmark to the tremor_medians DataFrame\n",
    "        tremor_medians[f'fac_tremor_median_{i+1:02d}'] = tremor_median\n",
    "        \n",
    "    # Calculate the mean of median tremors across all frames for each landmark\n",
    "    output_df = tremor_medians.mean().rename(lambda x: f'{x}_mean').to_frame().transpose()\n",
    "    \n",
    "    # Adjust the DataFrame to start from the original index\n",
    "    output_df.index = [0]\n",
    "    \n",
    "    return output_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Derived Variables for Facial Tremor!\n",
    "\n",
    "openface_ft_derived_dict_list = {}\n",
    "\n",
    "for time_radius, openface_radius_now in openface_extras_radius_dict.items():\n",
    "  openface_ft_derived_dict_list[time_radius] = apply_function_to_dict_list(openface_radius_now, calculate_fac_tremor)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OPENFACE - Averaging across time windows!\n",
    "\n",
    "openface_ft_derived_dict = {}\n",
    "\n",
    "\n",
    "for time_window, openface_radius_now in openface_ft_derived_dict_list.items():\n",
    "  print('Time Window: ', time_window)\n",
    "\n",
    "  openface_ft_stats_fixed = apply_function_to_dict(openface_radius_now, average_dfs)\n",
    "  openface_ft_derived_dict[time_window] = openface_ft_stats_fixed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pain Expressivity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_pain_expressivity(df):\n",
    "    # Calculate fac_paiintsoft for each frame\n",
    "    soft_columns = [\"AU04_r\", \"AU06_r\", \"AU07_r\", \"AU09_r\", \"AU10_r\", \"AU12_r\", \"AU20_r\", \"AU26_r\"]\n",
    "    df['fac_paiintsoft'] = df[soft_columns].mean(axis=1) / 5\n",
    "    \n",
    "    # Calculate fac_paiinthard for each frame\n",
    "    hard_columns = [\"AU04_c\", \"AU06_c\", \"AU07_c\", \"AU09_c\", \"AU10_c\", \"AU12_c\", \"AU20_c\", \"AU26_c\"]\n",
    "    df['fac_paiinthard'] = np.where(df[hard_columns].min(axis=1) > 0, df['fac_paiintsoft'], 0)\n",
    "    \n",
    "    # Calculate overall features\n",
    "    results = {\n",
    "        'fac_paiintsoft_pct': (df[hard_columns] > 0).any(axis=1).mean(),\n",
    "        'fac_paiintsoft_mean': df['fac_paiintsoft'].mean(),\n",
    "        'fac_paiintsoft_std': df['fac_paiintsoft'].std(),\n",
    "        'fac_paiinthard_mean': df['fac_paiinthard'].mean(),\n",
    "        'fac_paiinthard_std': df['fac_paiinthard'].std()\n",
    "    }\n",
    "\n",
    "    # Ensure no NaNs - replace NaNs with 0 for aggregation metrics\n",
    "    results = {k: 0 if pd.isna(v) else v for k, v in results.items()}\n",
    "\n",
    "    # Return results as a DataFrame\n",
    "    return pd.DataFrame([results])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Derived Variables for Pain Expressivity!\n",
    "\n",
    "openface_pe_derived_dict_list = {}\n",
    "\n",
    "for time_radius, openface_radius_now in openface_radius_dict.items():\n",
    "  openface_pe_derived_dict_list[time_radius] = apply_function_to_dict_list(openface_radius_now, calculate_pain_expressivity)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OPENFACE - Averaging across time windows!\n",
    "\n",
    "openface_pe_derived_dict = {}\n",
    "\n",
    "\n",
    "for time_window, openface_radius_now in openface_pe_derived_dict_list.items():\n",
    "  print('Time Window: ', time_window)\n",
    "\n",
    "  openface_pe_stats_fixed = apply_function_to_dict(openface_radius_now, average_dfs)\n",
    "  openface_pe_derived_dict[time_window] = openface_pe_stats_fixed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pkcRVBK7CZaJ"
   },
   "source": [
    "# Make Vectors for Each Timestamp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SFkY8uARYsGL"
   },
   "source": [
    "## Vectors for AU and emotion classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1afeC95tCzgK"
   },
   "outputs": [],
   "source": [
    "## Dictionary of list of relevant dictionaries\n",
    "openface_dict_list_dict = {}\n",
    "\n",
    "for key in openface_au_derived_dict.keys():\n",
    "  openface_dict_list_dict[key] = [ openface_au_derived_dict[key], openface_emo_stats_dict[key], openface_ee_derived_dict[key], \n",
    "                                  openface_oe_derived_dict[key], openface_hm_derived_dict[key], openface_eg_derived_dict[key],\n",
    "                                  openface_ebb_derived_dict[key], openface_fl_derived_dict[key], openface_ft_derived_dict[key],\n",
    "                                 openface_pe_derived_dict[key] ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZRuy_1Y9JAqd"
   },
   "outputs": [],
   "source": [
    "# SAVE VARIABLES - EMOTION & AFFECT\n",
    "\n",
    "save_var(openface_dict_list_dict, forced_name=f'openface_dict_list_dict_outpatient_{PAT_NOW}')\n",
    "\n",
    "#save_var(opengraphau_dict_list_dict, forced_name=f'opengraphau_dict_list_dict_outpatient_{PAT_NOW}')\n",
    "\n",
    "#save_var(hsemotion_dict_list_dict, forced_name=f'hsemotion_dict_list_dict_outpatient_{PAT_NOW}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rcZea69MJ9Lw"
   },
   "outputs": [],
   "source": [
    "def flatten_dataframes_dict(dataframes_list):\n",
    "    # Initialize an empty dictionary to store the flattened data for each key\n",
    "    flattened_data_dict = {}\n",
    "\n",
    "    # Define the columns to ignore\n",
    "    ignore_columns = ['success', 'frame', 'timestamp', 'AU', 'emotion']\n",
    "\n",
    "    for dataframes_dict in dataframes_list:\n",
    "       for key, df in dataframes_dict.items():\n",
    "          # Filter out the columns to be ignored\n",
    "          filtered_df = df.drop(columns=[col for col in ignore_columns if col in df.columns])\n",
    "\n",
    "          # Flatten the data by converting each DataFrame into a 1D array\n",
    "          flattened_array = filtered_df.select_dtypes(include=[np.number, int, float, complex, \\\n",
    "                                                                pd.Int64Dtype(), pd.Float64Dtype(), pd.Int32Dtype(), \\\n",
    "                                                                pd.Float32Dtype()]).values.flatten()\n",
    "\n",
    "          # Convert the flattened array to NumPy array and store it in the dictionary\n",
    "          if key in flattened_data_dict:\n",
    "              flattened_data_dict[key] = np.concatenate((flattened_data_dict[key], flattened_array))\n",
    "          else:\n",
    "              flattened_data_dict[key] = np.array(flattened_array)\n",
    "\n",
    "    return flattened_data_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1_kZiz0dKDcm"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "openface_vectors_dict = {}\n",
    "\n",
    "for key, openface_dict_list_now in openface_dict_list_dict.items():\n",
    "  openface_vectors_dict[key] = flatten_dataframes_dict(openface_dict_list_now)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gx6_bCNQV6uD"
   },
   "source": [
    "## Labels - datetime conversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5hRicOaOQVtq"
   },
   "outputs": [],
   "source": [
    "def ts_to_str(timestamp):\n",
    "    return timestamp.strftime('%-m/%-d/%Y %H:%M:%S')\n",
    "\n",
    "def str_to_ts(string_now):\n",
    "  temp_var = pd.to_datetime(pd.to_datetime(string_now).strftime('%d-%b-%Y %H:%M:%S'))\n",
    "  return pd.Timestamp(temp_var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3lwF8VpTv-oC"
   },
   "outputs": [],
   "source": [
    "## Save our vectors to excel sheets!\n",
    "\n",
    "def get_dict_name(dictionary):\n",
    "    namespace = globals()\n",
    "    for name, obj in namespace.items():\n",
    "        if isinstance(obj, dict) and obj is dictionary:\n",
    "            return name\n",
    "    return None\n",
    "\n",
    "def save_dicts_to_excel(dict_list, output_path):\n",
    "  # Create an Excel writer object\n",
    "  writer = pd.ExcelWriter(output_path, engine='xlsxwriter')\n",
    "\n",
    "  # Iterate over the keys in the dictionaries\n",
    "  for key in dict_list[0].keys():\n",
    "      # Write each dataframe to a separate sheet with the corresponding key as the sheet name\n",
    "      for enum, dict_now in enumerate(dict_list):\n",
    "        name_var = f'Matrix_{enum}'\n",
    "        sheet_name_starter = f'{key[10:]}_{name_var}'\n",
    "        if key in dict_now:\n",
    "            dict_now[key].to_excel(writer, sheet_name=sheet_name_starter[:31])\n",
    "\n",
    "  # Save the Excel file\n",
    "  writer.close()\n",
    "  return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "os.makedirs(FEATURE_VIS_PATH, exist_ok=True)\n",
    "\n",
    "#for i in opengraphau_dict_list_dict.keys():\n",
    "for i in openface_dict_list_dict.keys():\n",
    "  save_dicts_to_excel(openface_dict_list_dict[i], FEATURE_VIS_PATH + f'openface_{PAT_NOW}_{int(i)}_minutes.xlsx')\n",
    "  #save_dicts_to_excel(opengraphau_dict_list_dict[i], FEATURE_VIS_PATH + f'opengraphau_{PAT_NOW}_{int(i) / 60}_hours.xlsx')\n",
    "  #save_dicts_to_excel(hsemotion_dict_list_dict[i], FEATURE_VIS_PATH + f'hsemotion_{PAT_NOW}_{int(i) / 60}_hours.xlsx')\n",
    "  #save_dicts_to_excel(ogauhsemotion_dict_list_dict[i], FEATURE_VIS_PATH + f'ogauhse_{PAT_NOW}_{int(i) / 60}_hours.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bYi6EjHkWTTZ"
   },
   "source": [
    "# Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8t1JM3aZYVaF"
   },
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "r4_0pdm5WRw0"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "\n",
    "def set_seed(x=5):\n",
    "  np.random.seed(x)\n",
    "  random.seed(x)\n",
    "\n",
    "\n",
    "set_seed()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bUEpxgLPWRw0"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "from scipy.stats import pearsonr\n",
    "import seaborn as sns\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.linear_model import Lasso\n",
    "from ControlBurn.ControlBurnModel import ControlBurnClassifier\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "USING_CONTROLBURN = False\n",
    "\n",
    "\n",
    "def linRegOneMetric(vectors_dict, y, randShuffle=False, do_lasso=False, do_ridge=False, alpha=1.0):\n",
    "    # runs simple linear regression via one-left-out\n",
    "    # vectors_dict -- dictionary mapping time radius (in minutes) to features\n",
    "    # y -- a numpy array with labels (self-reported metrics)\n",
    "    # randShuffle -- do we shuffle the self-report labels?\n",
    "    # if do_lasso, does lasso regression\n",
    "    # if do_ridge, does ridge regression. Overrides do_lasso\n",
    "    # alpha - this is the weighting of either lasso or ridge\n",
    "\n",
    "    # returns a dictionary with several results:\n",
    "    # scores -- dictionary mapping each time radius to list of MSEs from each one-left-out\n",
    "    # preds -- dictionary mapping each time radius to a list of each one-left-out model's prediction\n",
    "    # y -- returns y again for convenience\n",
    "    # models -- dictionary mapping each time radius to a list of each one-left-out trained model (simple linear regression)\n",
    "\n",
    "\n",
    "\n",
    "    # Custom implementation without cross_val_score\n",
    "    scores = {}\n",
    "    preds = {}\n",
    "    models = {}\n",
    "\n",
    "    if randShuffle:\n",
    "        y_using = np.random.permutation(y)\n",
    "    else:\n",
    "        y_using = y\n",
    "\n",
    "    for i in vectors_dict.keys():\n",
    "        # Initialize appropriate model based on input flags\n",
    "        model = LinearRegression()\n",
    "        if do_lasso:\n",
    "            if USING_CONTROLBURN:\n",
    "                model = ControlBurnClassifier(alpha=alpha)\n",
    "            else:\n",
    "                model = Lasso(alpha=alpha)\n",
    "        if do_ridge:\n",
    "            model = Ridge(alpha=alpha)\n",
    "\n",
    "        scores[i] = []\n",
    "        preds[i] = np.zeros(y_using.shape)\n",
    "        models_i_building = []\n",
    "\n",
    "        # Manual leave-one-out cross-validation\n",
    "        for test_index in range(vectors_dict[i].shape[0]):\n",
    "            # Split the data into training and testing sets\n",
    "            X_train = np.delete(vectors_dict[i], test_index, axis=0)\n",
    "            y_train = np.delete(y_using, test_index, axis=0)\n",
    "            X_test = vectors_dict[i][test_index:test_index+1]  # Keep the test sample in 2D\n",
    "            y_test = y_using[test_index]\n",
    "\n",
    "            # Fit the model and make predictions\n",
    "            if USING_CONTROLBURN:\n",
    "                X_train = pd.DataFrame(X_train)\n",
    "            model.fit(X_train, y_train)\n",
    "            y_pred = model.predict(X_test)\n",
    "            preds[i][test_index] = y_pred\n",
    "\n",
    "            # Compute and store the MSE for this fold\n",
    "            mse = mean_squared_error([y_test], [y_pred])\n",
    "            scores[i].append(mse)\n",
    "\n",
    "            models_i_building.append(model)  # Save the trained model for this fold\n",
    "\n",
    "        models[i] = models_i_building\n",
    "\n",
    "    return scores, preds, y_using, models\n",
    "\n",
    "\n",
    "def plot_predictions(y, y_pred, randShuffleR=None, ax=None, time_rad=None, metric=None):\n",
    "    # Makes one scatterplot with Pearson's R and p value on it\n",
    "    # give it the randShuffle Pearson's R\n",
    "    # if you want to display that on the plot\n",
    "\n",
    "    # Compute Pearson's R\n",
    "    pearson_corr, p_val = pearsonr(y, y_pred)\n",
    "\n",
    "    # Create the scatter plot on the specified axes\n",
    "    if ax is None:\n",
    "        ax_original = None\n",
    "        fig, ax = plt.subplots()\n",
    "        # adjust fonts!\n",
    "        text_font = 16\n",
    "    else:\n",
    "        ax_original = ax\n",
    "        text_font = 16\n",
    "\n",
    "\n",
    "    ax.scatter(y, y_pred, label='Predicted vs. True', s=24)\n",
    "\n",
    "\n",
    "\n",
    "    # Add the correlation coefficient and p-value on the plot\n",
    "    ax.text(0.05, 0.90, f'Pearson\\'s R: {pearson_corr:.2f}', transform=ax.transAxes, fontsize=text_font)\n",
    "    ax.text(0.05, 0.80, f'P Value: {p_val:.2f}', transform=ax.transAxes, fontsize=text_font)\n",
    "    if not(randShuffleR is None):\n",
    "      ax.text(0.05, 0.70, f'Random Shuffle R: {randShuffleR:.2f}', transform=ax.transAxes, fontsize=text_font)\n",
    "\n",
    "    # Set labels and title\n",
    "    ax.set_xlabel('Self-Reported Scores', fontsize=17)\n",
    "    ax.set_ylabel('Predicted Scores', fontsize=17)\n",
    "\n",
    "    if metric is None:\n",
    "      title_starter = 'Predicted vs. True'\n",
    "    else:\n",
    "      title_starter = metric\n",
    "\n",
    "    if time_rad is None:\n",
    "      ax.set_title(f'{title_starter} Scores', fontsize=17)\n",
    "    else:\n",
    "      num_mins = int(time_rad)\n",
    "      if num_mins > 1:\n",
    "        ax.set_title(f'{title_starter}, Time Window = {num_mins} Minutes', fontsize=15)\n",
    "      else:\n",
    "        ax.set_title(f'{title_starter}, Time Window = {num_mins} Minute', fontsize=15)\n",
    "\n",
    "\n",
    "    # Add the line of best fit\n",
    "    sns.regplot(x=y, y=y_pred, ax=ax, line_kws={'color': 'red', 'linestyle': '--'}, label='Line of Best Fit')\n",
    "\n",
    "    # Add the shaded region for the 95% confidence interval\n",
    "    #sns.regplot(x=y, y=y_pred, ax=ax, scatter=False, ci=95, color='gray', label='95% Confidence Interval')\n",
    "\n",
    "    # Adjust the font size of the tick labels on the axes\n",
    "    ax.tick_params(axis='both', labelsize=18)\n",
    "\n",
    "    ax.set_adjustable('box')\n",
    "\n",
    "    #set aspect ratio to 1\n",
    "    ratio = 1.0\n",
    "    x_left, x_right = ax.get_xlim()\n",
    "    y_low, y_high = ax.get_ylim()\n",
    "    ax.set_aspect(abs((x_right-x_left)/(y_low-y_high))*ratio)\n",
    "\n",
    "    if ax_original is None:\n",
    "        plt.show()\n",
    "        return pearson_corr, p_val, fig\n",
    "    else:\n",
    "        return pearson_corr, p_val\n",
    "\n",
    "\n",
    "\n",
    "def plot_scatterplots(preds_dict, y, overall_title, savepath, randShuffleR=None):\n",
    "\n",
    "    plt.rcParams['lines.markersize'] = 6\n",
    "    subplot_title_font = 16\n",
    "    full_title_font = 24\n",
    "\n",
    "    num_plots = len(list(preds_dict.keys()))\n",
    "    num_cols = 4\n",
    "    num_rows = (num_plots + num_cols - 1) // num_cols\n",
    "\n",
    "    r_list = []\n",
    "    p_list = []\n",
    "\n",
    "    # Calculate the desired figure size for larger plot\n",
    "    figsize = (28, 12)\n",
    "\n",
    "    # Create subplots with auto aspect ratio\n",
    "    fig, axes = plt.subplots(num_rows, num_cols, figsize=figsize)\n",
    "\n",
    "    #axes.set_adjustable('box')\n",
    "\n",
    "    if num_rows == 1:\n",
    "      axes = axes.reshape((1, num_cols))\n",
    "\n",
    "    # Flatten the axes array if necessary\n",
    "    if num_plots == 1:\n",
    "        fig, axes = plt.subplots(1, 1, figsize=figsize)\n",
    "        axes = np.array([axes]).reshape(1, 1)\n",
    "\n",
    "\n",
    "    # Loop through the dictionaries\n",
    "    for i, (key, y_preds) in enumerate(preds_dict.items()):\n",
    "        y_list = np.array(y).astype(float)\n",
    "        y_pred = np.array(y_preds).astype(float)\n",
    "        #y_pred = np.array([i[0] for i in y_pred])\n",
    "\n",
    "        # Get the subplot coordinates\n",
    "        row = i // num_cols\n",
    "        col = i % num_cols\n",
    "\n",
    "        # Plot predictions on the subplot\n",
    "        if randShuffleR is None:\n",
    "          pearson_corr, p_val = plot_predictions(y_list, y_pred, randShuffleR=randShuffleR, ax=axes[row, col])\n",
    "        else:\n",
    "          pearson_corr, p_val = plot_predictions(y_list, y_pred, randShuffleR=randShuffleR[i], ax=axes[row, col])\n",
    "        r_list.append(pearson_corr)\n",
    "        p_list.append(p_val)\n",
    "\n",
    "        num_mins = int(key)\n",
    "        if num_mins > 1:\n",
    "          axes[row, col].set_title(f'Time Window = {num_mins} Minutes', fontsize=subplot_title_font)\n",
    "        else:\n",
    "          axes[row, col].set_title(f'Time Window = {num_mins} Minute', fontsize=subplot_title_font)\n",
    "        #axes[row, col].set_aspect('equal')\n",
    "\n",
    "        # Remove x-axis and y-axis labels from subplots\n",
    "        axes[row, col].set_xlabel('')\n",
    "        axes[row, col].set_ylabel('')\n",
    "\n",
    "        #axes[row, col].set_adjustable('box')\n",
    "\n",
    "    # Add overall title\n",
    "    fig.suptitle(overall_title, fontsize=30, y=1)\n",
    "\n",
    "    # Set shared x-axis and y-axis labels\n",
    "    fig.text(0.5, 0.00, 'Self-Reported Scores', ha='center', fontsize=full_title_font)\n",
    "    fig.text(-0.01, 0.5, 'Predicted Scores', va='center', rotation='vertical', fontsize=full_title_font)\n",
    "\n",
    "    # Adjust spacing and layout\n",
    "    fig.tight_layout()\n",
    "\n",
    "    plt.savefig(savepath, bbox_inches='tight')\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "    return r_list, p_list, fig\n",
    "\n",
    "\n",
    "def make_mse_boxplot(scores, metric, savepath, ax=None, method_now='OpenFace'):\n",
    "    # scores -- dictionary that maps time radius (mins) to list of MSEs from one-left-out\n",
    "    # metric - e.g. Mood or Anxiety\n",
    "\n",
    "    # Combine the data into a single array\n",
    "    data = [MSE_list for MSE_list in list(scores.values())]\n",
    "\n",
    "    # Set the font sizes\n",
    "    plt.rcParams.update({'font.size': 15})\n",
    "\n",
    "    if ax is None:\n",
    "        fig, ax = plt.subplots()\n",
    "    else:\n",
    "        fig = None\n",
    "\n",
    "    # Create a box plot of the data\n",
    "    labels_now = [f'{int(key) / 60}' for key in scores.keys()]\n",
    "\n",
    "    ax.boxplot(data, labels=labels_now, showmeans=True, meanprops={'marker': 'o', 'markerfacecolor': 'red', 'markersize': 10})\n",
    "\n",
    "    # Determine the highest 75th percentile value among the four entries\n",
    "    max_value = np.max([np.percentile(entry, 75) for entry in data])\n",
    "\n",
    "    # Set the y-axis range conditionally\n",
    "    if max_value > 100:\n",
    "        ax.set_ylim(0, 100)\n",
    "    else:\n",
    "        ax.set_ylim(0, max_value)\n",
    "\n",
    "    # Set the labels and title\n",
    "    ax.set_xlabel('Time Window (Hours)')\n",
    "    ax.set_ylabel('Mean Squared Error')\n",
    "    ax.set_title(f'{metric} Prediction via {method_now}', y=1.1)\n",
    "\n",
    "    plt.xticks(rotation=45)\n",
    "\n",
    "    plt.savefig(savepath, bbox_inches='tight')\n",
    "\n",
    "    # Show the plot if fig is None\n",
    "    if fig is None:\n",
    "        plt.show()\n",
    "    else:\n",
    "        return fig\n",
    "\n",
    "def make_r_barplot(r_list, time_radius_list, metric, savepath, ax=None, method_now='OpenFace'):\n",
    "    plt.rcParams.update({'font.size': 15})\n",
    "\n",
    "    x_labels = [f'{int(i) / 60}' for i in time_radius_list]\n",
    "\n",
    "    if ax is None:\n",
    "        original_ax = None\n",
    "        fig, ax = plt.subplots()\n",
    "    else:\n",
    "        original_ax = ax\n",
    "\n",
    "    ax.bar(x_labels, r_list)\n",
    "\n",
    "    # Set the y-axis range\n",
    "    ax.set_ylim(-0.5, 1)\n",
    "\n",
    "    # Set the labels and title\n",
    "    ax.set_xlabel('Time Window (Hours)')\n",
    "    ax.set_ylabel(\"Pearson's R\")\n",
    "    ax.set_title(f'{metric} Prediction via {method_now}', y=1.1)\n",
    "\n",
    "    plt.xticks(rotation=45)\n",
    "\n",
    "    plt.savefig(savepath, bbox_inches='tight')\n",
    "\n",
    "    # Show the plot if ax is None\n",
    "    if original_ax is None:\n",
    "        plt.show()\n",
    "        return fig\n",
    "\n",
    "\n",
    "def getTopFeaturesfromWeights(model_list, spreadsheet_path=FEATURE_LABEL_PATH+'openface_2.0_hours.xlsx'):\n",
    "  # given a list of linear regression models,\n",
    "  # returns their top 5 features (on average) from just weights!\n",
    "\n",
    "  coef_array = [model_now.coef_ for model_now in model_list]\n",
    "  coef_avg = np.mean(coef_array, axis=0)\n",
    "\n",
    "  top_5_features = np.argsort(np.abs(coef_avg))[::-1][:5]\n",
    "\n",
    "  top_5_english = [get_label_from_index(feat_ind, spreadsheet_path=spreadsheet_path) for feat_ind in top_5_features]\n",
    "\n",
    "  return top_5_english\n",
    "\n",
    "\n",
    "def featureAblate(vectors_array, y, do_lasso=False, do_ridge=False):\n",
    "  # runs one-left-out linear regression,\n",
    "  # deleting one feature at a time to determine most important features\n",
    "\n",
    "\n",
    "  num_features = vectors_array.shape[1]\n",
    "  num_timestamps = vectors_array.shape[0]\n",
    "\n",
    "  scores = np.zeros((num_features, num_timestamps))\n",
    "  prs = np.zeros((num_features,))\n",
    "\n",
    "  # loop through each feature (for openface, 0 through 144) and delete just that\n",
    "  for deleteNow in range(num_features):\n",
    "    data = np.delete(vectors_array, deleteNow, axis=1)\n",
    "\n",
    "    # make into dictionary to feed into our lin reg function\n",
    "    data = {'placeholder': data}\n",
    "\n",
    "    scores_temp, preds, y, _ = linRegOneMetric(data, y, do_lasso=do_lasso, do_ridge=do_ridge)\n",
    "    scores_temp = scores_temp['placeholder']\n",
    "    preds = preds['placeholder']\n",
    "\n",
    "    # save MSEs\n",
    "    scores[deleteNow, :] =  scores_temp\n",
    "\n",
    "    # compute and save Pearson's R\n",
    "    pearson_corr, _ = pearsonr(y, preds)\n",
    "    prs[deleteNow] = pearson_corr\n",
    "\n",
    "  return scores, prs\n",
    "\n",
    "def featureAblate2D(vectors_array, y):\n",
    "  # runs one-left-out linear regression,\n",
    "  # deleting TWO features at a time to determine most important features\n",
    "\n",
    "\n",
    "  num_features = vectors_array.shape[1]\n",
    "\n",
    "  prs = np.zeros((num_features,num_features))\n",
    "\n",
    "  # loop through each feature (for openface, 0 through 144) and delete just that\n",
    "  for deleteNow in range(num_features):\n",
    "    # delete a second one!\n",
    "    for secondDelete in range(deleteNow+1, num_features):\n",
    "      data = np.delete(vectors_array, [deleteNow, secondDelete], axis=1)\n",
    "\n",
    "      # make into dictionary to feed into our lin reg function\n",
    "      data = {'placeholder': data}\n",
    "\n",
    "      _, preds, _, _ = linRegOneMetric(data, y)\n",
    "      preds = preds['placeholder']\n",
    "\n",
    "      # compute and save Pearson's R\n",
    "      pearson_corr, _ = pearsonr(y, preds)\n",
    "      prs[deleteNow, secondDelete] = pearson_corr\n",
    "\n",
    "  return prs\n",
    "\n",
    "def featureAblate3D(vectors_array, y):\n",
    "  # runs one-left-out linear regression,\n",
    "  # deleting THREE features at a time to determine most important features\n",
    "\n",
    "  num_features = vectors_array.shape[1]\n",
    "\n",
    "  prs = np.zeros((num_features, num_features, num_features))\n",
    "\n",
    "  # loop through each feature (for openface, 0 through 144) and delete just that\n",
    "  for deleteNow in range(num_features):\n",
    "    # delete a second one!\n",
    "    for secondDelete in range(deleteNow+1, num_features):\n",
    "      # delete a third one!\n",
    "      for thirdDelete in range(secondDelete+1, num_features):\n",
    "        data = np.delete(vectors_array, [deleteNow, secondDelete, thirdDelete], axis=1)\n",
    "\n",
    "        # make into dictionary to feed into our lin reg function\n",
    "        data = {'placeholder': data}\n",
    "\n",
    "        _, preds, _, _ = linRegOneMetric(data, y)\n",
    "        preds = preds['placeholder']\n",
    "\n",
    "        # compute and save Pearson's R\n",
    "        pearson_corr, _ = pearsonr(y, preds)\n",
    "        prs[deleteNow, secondDelete, thirdDelete] = pearson_corr\n",
    "\n",
    "  return prs\n",
    "\n",
    "def plotFeatAbMSEs(feat_ab_scores, original_mse_list, metric, time_radius, savepath, top_n=5, ax=None, spreadsheet_path=FEATURE_LABEL_PATH+'openface_2.0_hours.xlsx'):\n",
    "  # takes feat_ab_scores, a numpy array (n_features, n_timestamps) of MSEs\n",
    "  # outputs box and whisker plot of top_n features for the model\n",
    "\n",
    "  # procedure: get the top_n features with lowest mse averaged across timestamps\n",
    "  # make a box and whisker plot with each feature on x axis and MSEs on y axis\n",
    "  # for x axis labels, convert the index of each feature to english label\n",
    "  # by calling get_label_from_index(feat_ind)\n",
    "\n",
    "\n",
    "  # Get the average MSE across timestamps for each feature\n",
    "  avg_mses = np.mean(feat_ab_scores, axis=1)\n",
    "\n",
    "  # avg MSEs minus original_avg_MSE (make it difference!)\n",
    "  avg_mses = avg_mses - np.mean(original_mse_list)\n",
    "\n",
    "  # Get the indices of the top_n features with the highest difference in MSEs from original\n",
    "  top_indices = np.argsort(avg_mses)[-top_n:]\n",
    "  top_indices = top_indices[::-1]\n",
    "\n",
    "  # Get the English labels for the top_n features\n",
    "  top_labels = [get_label_from_index(ind, spreadsheet_path=spreadsheet_path) for ind in top_indices]\n",
    "\n",
    "  # Get the MSE values for the top_n features\n",
    "  top_mses = feat_ab_scores[top_indices]\n",
    "\n",
    "  # Adjust so it's top mses minus original\n",
    "  original_list_repeated = np.repeat(np.array(original_mse_list).reshape(1, -1), top_n, axis=0)\n",
    "  top_mses = top_mses - original_list_repeated\n",
    "\n",
    "  # Create a box and whisker plot\n",
    "  if ax is None:\n",
    "      original_ax = None\n",
    "      fig, ax = plt.subplots()\n",
    "  else:\n",
    "      original_ax = ax\n",
    "  ax.boxplot(top_mses.T, labels=top_labels, showmeans=True, meanprops={'marker': 'o', 'markerfacecolor': 'red', 'markersize': 10})\n",
    "\n",
    "  # Rotate x-axis labels by 45 degrees\n",
    "  ax.set_xticklabels(top_labels, rotation=45)\n",
    "\n",
    "  # Set the axis labels\n",
    "  ax.set_xlabel('Features')\n",
    "  ax.set_ylabel('Ablated - Original MSEs')\n",
    "\n",
    "  # Set the title\n",
    "  num_hrs = int(time_radius) / 60\n",
    "  if num_hrs > 1:\n",
    "      ax.set_title(f'Top {top_n} Features: {metric}, Time Window = {num_hrs} Hours')\n",
    "  else:\n",
    "      ax.set_title(f'Top {top_n} Features: {metric}, Time Window = {num_hrs} Hour')\n",
    "\n",
    "  plt.savefig(savepath, bbox_inches='tight')\n",
    "\n",
    "  # Show the plot if ax is None\n",
    "  if original_ax is None:\n",
    "      plt.show()\n",
    "\n",
    "\n",
    "  return top_indices, fig\n",
    "\n",
    "def plotFeatAbPRs(feat_ab_prs, original_r_val, metric, time_radius, savepath, top_n=5, ax=None, spreadsheet_path=FEATURE_LABEL_PATH+'openface_2.0_hours.xlsx'):\n",
    "  # takes feat_ab_prs, a numpy array (n_features, ) of Pearson's R vals post-ablation\n",
    "  # outputs bar plot of top_n features TO REMOVE for the model\n",
    "\n",
    "  # procedure: get the top_n features with highest pearson's R\n",
    "  # make a bar plot with each feature on x axis and pearson's R from feat_ab_prs on y axis\n",
    "  # for x axis labels, convert the index of each feature to english label\n",
    "  # by calling get_label_from_index(feat_ind)\n",
    "\n",
    "  # if ax is given, plot on ax. If ax=None, make new fig, ax\n",
    "\n",
    "\n",
    "  # Get the top_n features with highest Pearson's R values\n",
    "  top_features_indices = np.argsort(feat_ab_prs)[-top_n:]\n",
    "  top_features_indices = top_features_indices[::-1]\n",
    "\n",
    "  # Get the labels for the top_n features\n",
    "  top_features_labels = [get_label_from_index(index, spreadsheet_path=spreadsheet_path) for index in top_features_indices]\n",
    "\n",
    "  # Get the corresponding Pearson's R values for the top_n features\n",
    "  top_features_prs = feat_ab_prs[top_features_indices]\n",
    "\n",
    "  # Plot the bar plot\n",
    "  if ax is None:\n",
    "      fig, ax = plt.subplots()\n",
    "  ax.bar(top_features_labels, top_features_prs)\n",
    "\n",
    "  # Rotate x-axis labels by 45 degrees\n",
    "  ax.set_xticklabels(top_features_labels, rotation=45)\n",
    "\n",
    "  # Set plot title and axis labels\n",
    "  # Set the title\n",
    "  num_hrs = int(time_radius) / 60\n",
    "  if num_hrs > 1:\n",
    "      ax.set_title(f'Top {top_n} Features to Remove: {metric}, Time Window = {num_hrs} Hours')\n",
    "  else:\n",
    "      ax.set_title(f'Top {top_n} Features to Remove: {metric}, Time Window = {num_hrs} Hour')\n",
    "\n",
    "  ax.set_xlabel(\"Features\")\n",
    "  ax.set_ylabel(f\"Pearson's R (Original={round(original_r_val, 2)})\")\n",
    "\n",
    "  # Save the plot\n",
    "  plt.savefig(savepath, bbox_inches='tight')\n",
    "\n",
    "  # Show the plot if ax=None\n",
    "  if ax is None:\n",
    "      plt.show()\n",
    "\n",
    "def find_max_indices(array, top_n):\n",
    "    # Flatten the 2D array into a 1D array\n",
    "    flattened_array = array.flatten()\n",
    "\n",
    "    # Find the indices of the top n maximum values in the flattened array\n",
    "    max_indices = np.argsort(flattened_array)[-top_n:][::-1]\n",
    "\n",
    "    # Convert the flattened indices to the corresponding row and column indices in the original array\n",
    "    row_indices, col_indices = np.unravel_index(max_indices, array.shape)\n",
    "\n",
    "    # Combine the row and column indices into pairs\n",
    "    index_combinations = list(zip(row_indices, col_indices))\n",
    "\n",
    "    return index_combinations\n",
    "\n",
    "def plot_feat_scatterplots(vectors_array, y, feat_ind_list, metric, savepath, spreadsheet_path=FEATURE_LABEL_PATH+'openface_2.0_hours.xlsx'):\n",
    "    # for each feature, plot feature on x axis and self-report score on y axis\n",
    "    # vectors_array is the array of feature vectors for ONE time radius\n",
    "    # y - self-reports\n",
    "    # feat_ind_list - list of the indices of the top features\n",
    "    # metric -- e.g. Mood or Anxiety\n",
    "    # savepath - where to save the figure\n",
    "\n",
    "    plt.rcParams['lines.markersize'] = 15\n",
    "\n",
    "    num_plots = len(feat_ind_list)\n",
    "    num_cols = min([len(feat_ind_list), 4])\n",
    "    num_rows = (num_plots + num_cols - 1) // num_cols\n",
    "\n",
    "    r_list = []\n",
    "    p_list = []\n",
    "\n",
    "    # Calculate the desired figure size for larger plot\n",
    "    figsize = (28, 12)\n",
    "\n",
    "    # Create subplots with auto aspect ratio\n",
    "    fig, axes = plt.subplots(num_rows, num_cols, figsize=figsize)\n",
    "\n",
    "    #axes.set_adjustable('box')\n",
    "\n",
    "    if num_rows == 1:\n",
    "      axes = axes.reshape((1, num_cols))\n",
    "\n",
    "    # Flatten the axes array if necessary\n",
    "    if num_plots == 1:\n",
    "        fig, axes = plt.subplots(1, 1, figsize=figsize)\n",
    "        axes = np.array([axes]).reshape(1, 1)\n",
    "\n",
    "\n",
    "    # Loop through the dictionaries\n",
    "    for enum, i in enumerate(feat_ind_list):\n",
    "        x_list = vectors_array[:, i].astype(float)\n",
    "        y_list = np.array(y).astype(float)\n",
    "\n",
    "        #y_pred = np.array([i[0] for i in y_pred])\n",
    "\n",
    "        # Get the subplot coordinates\n",
    "        row = enum // num_cols\n",
    "        col = enum % num_cols\n",
    "\n",
    "        # Plot predictions on the subplot\n",
    "        pearson_corr, p_val = plot_predictions(x_list, y_list, randShuffleR=None, ax=axes[row, col])\n",
    "\n",
    "\n",
    "        axes[row, col].set_title(f'{metric} vs. {get_label_from_index(i, spreadsheet_path=spreadsheet_path)}', fontsize=24)\n",
    "\n",
    "\n",
    "        # Redo x-axis and y-axis labels for subplot\n",
    "        axes[row, col].set_xlabel(get_label_from_index(i, spreadsheet_path=spreadsheet_path), fontsize=24)\n",
    "        axes[row, col].set_ylabel('')\n",
    "\n",
    "        #axes[row, col].set_adjustable('box')\n",
    "\n",
    "    # Add overall title\n",
    "    fig.suptitle(f'Top {num_plots} Features for {metric}', fontsize=30, y=1.05)\n",
    "\n",
    "    # Set shared y-axis label\n",
    "    #fig.text(0.5, 0, f'Self-Reported {metric} Scores', ha='center', fontsize=24)\n",
    "    fig.text(-0.01, 0.5, f'Self-Reported {metric} Scores', va='center', rotation='vertical', fontsize=24)\n",
    "\n",
    "    # Adjust spacing and layout\n",
    "    fig.tight_layout()\n",
    "\n",
    "    plt.savefig(savepath, bbox_inches='tight')\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "    return r_list, p_list, fig\n",
    "\n",
    "\n",
    "\n",
    "def extractOneMetric(metric, vectors_now, df_moodTracking=df_moodTracking, remove_outliers=False):\n",
    "  # extracts the vectors needed for linear regression\n",
    "  # e.g. Mood only, for all time windows\n",
    "  # metric -- a string that is a self-report metric (ex. 'MADRS')\n",
    "  # vectors_now -- our feature vectors (all)\n",
    "  # df_moodTracking -- load in and pre-process self-report google sheet\n",
    "\n",
    "  # returns vectors_return and y\n",
    "  # vectors_return -- a dictionary mapping time radius (in minutes) to features\n",
    "  # y -- a numpy array with labels (self-reported metrics)\n",
    "\n",
    "\n",
    "  y = df_moodTracking[metric].values.astype(float)\n",
    "  y = np.array([float(y_now) for y_now in y])\n",
    "\n",
    "  # # just valid indices (remove nan self-reports!)\n",
    "  # valid_indices = ~pd.isna(y)\n",
    "  # y = y[valid_indices]\n",
    "\n",
    "  # Initially, set valid_indices to include all indices\n",
    "  valid_indices = np.arange(len(y))\n",
    "\n",
    "  # Step 1: Remove NaN values\n",
    "  nan_mask = ~pd.isna(y)\n",
    "  y = y[nan_mask]\n",
    "  valid_indices = valid_indices[nan_mask]\n",
    "\n",
    "\n",
    "  if remove_outliers:\n",
    "    # Step 2: Remove outliers\n",
    "    mean_y = np.mean(y)\n",
    "    std_y = np.std(y)\n",
    "    outlier_mask = (y >= mean_y - 2 * std_y) & (y <= mean_y + 2 * std_y)\n",
    "    y = y[outlier_mask]\n",
    "    valid_indices = valid_indices[outlier_mask]\n",
    "\n",
    "\n",
    "\n",
    "  vectors_return = {}\n",
    "\n",
    "  # Temp debug: outpatient dataset spreadsheet seems to be inserting spaces\n",
    "  #replace_underscore_space = lambda s: s.replace(\"_ \", \"_\").replace(':', '')\n",
    "  def modify_keys(dictionary):\n",
    "    # Using dictionary comprehension to create a new dictionary\n",
    "    # with keys that have spaces removed\n",
    "    return {key.replace(' ', '').replace(':', ''): value for key, value in dictionary.items()}\n",
    "\n",
    "  # loop through the outpatient videos at each time truncation we're considering (e.g. 10 mins)\n",
    "  for i in vectors_now.keys():\n",
    "    vectors_now_dict = vectors_now[i]\n",
    "    vectors_now_dict_fixed = modify_keys(vectors_now_dict)\n",
    "    \n",
    "    vectors_one_timestamp = np.array([vectors_now_dict_fixed[fn.replace(' ', '').replace(':', '')[:-4]] for fn in df_moodTracking['Filename']])\n",
    "\n",
    "    # we want just the valid features (where self-report is not nan)\n",
    "    vectors_one_timestamp = vectors_one_timestamp[valid_indices]\n",
    "\n",
    "    vectors_return[i] = vectors_one_timestamp\n",
    "\n",
    "  return vectors_return, y\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def plot_pearsons_r_vs_alpha(pearson_r_list, ALPHAS_FOR_SEARCH, method, save_path):\n",
    "    \"\"\"\n",
    "    Plots Pearson's R values against Alphas and saves the plot to the specified path.\n",
    "\n",
    "    :param pearson_r_list: List of Pearson's R values.\n",
    "    :param ALPHAS_FOR_SEARCH: List of Alpha values.\n",
    "    :param method: The method used (string).\n",
    "    :param save_path: File path to save the plot.\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.plot(ALPHAS_FOR_SEARCH, pearson_r_list, marker='o')\n",
    "    plt.title(f'LASSO: Alpha Search {method}')\n",
    "    plt.xlabel('Alpha')\n",
    "    plt.ylabel(\"Pearson's R\")\n",
    "    plt.grid(True)\n",
    "    plt.savefig(save_path, bbox_inches='tight')\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "def get_label_from_index(index, spreadsheet_path=FEATURE_LABEL_PATH+'openface_0.5_hours.xlsx'):\n",
    "    if 'experimental' in spreadsheet_path:\n",
    "      matrices = [\"Matrix_0\", \"Matrix_1\", \"Matrix_2\", \"Matrix_3\", \"Matrix_4\", \"Matrix_5\", \"Matrix_6\", \"Matrix_7\", \"Matrix_8\", \"Matrix_9\"]\n",
    "      row_label_cols = [\"AU\", \"emotion\", \"emotion\", None, None, None, None, None, None, None]\n",
    "    elif 'hsemotion' in spreadsheet_path:\n",
    "      matrices = [\"Matrix_0\"]\n",
    "      row_label_cols = [\"emotion\"]\n",
    "    elif 'opengraphau' in spreadsheet_path:\n",
    "      matrices = [\"Matrix_0\"]\n",
    "      row_label_cols = [\"AU\"]\n",
    "    elif 'openface' in spreadsheet_path:\n",
    "      matrices = [\"Matrix_0\", \"Matrix_1\", \"Matrix_2\", \"Matrix_3\"]\n",
    "      row_label_cols = [\"AU\", \"emotion\", \"emotion\", None]\n",
    "    elif 'ofauhse' in spreadsheet_path:\n",
    "      matrices = [\"Matrix_0\", \"Matrix_1\"]\n",
    "      row_label_cols = [\"AU\", \"emotion\"]\n",
    "    elif 'ogauhse' in spreadsheet_path:\n",
    "      matrices = [\"Matrix_0\", \"Matrix_1\"]\n",
    "      row_label_cols = [\"AU\", \"emotion\"]\n",
    "    elif 'all' in spreadsheet_path:\n",
    "      matrices = [\"Matrix_0\", \"Matrix_1\", \"Matrix_2\", \"Matrix_3\", \"Matrix_4\", \"Matrix_5\"]\n",
    "      row_label_cols = [\"AU\", \"emotion\", \"emotion\", None, \"AU\", \"emotion\"]\n",
    "    else:\n",
    "      print('BUG IN THE CODE! CHECK get_label_from_index')\n",
    "      print('spreadsheet path is ', spreadsheet_path)\n",
    "\n",
    "\n",
    "    xls = pd.ExcelFile(spreadsheet_path)\n",
    "\n",
    "    for i, matrix in enumerate(matrices):\n",
    "        # Find the sheet ending with the current matrix name\n",
    "        sheet_name = next((s for s in xls.sheet_names if s.endswith(matrix)), None)\n",
    "        if sheet_name is not None:\n",
    "            # Load the sheet into a DataFrame, with the first row as column names\n",
    "            df = pd.read_excel(spreadsheet_path, sheet_name=sheet_name, header=0)\n",
    "\n",
    "            # Get the column labels from the DataFrame\n",
    "            col_labels = df.columns.tolist()[1:]\n",
    "\n",
    "            row_labels = df['Unnamed: 0'].tolist()\n",
    "\n",
    "            # Get the numerical entries in the sheet excluding columns \"AU\" and \"emotion\" and \"Unnamed: 0\"\n",
    "            numerical_entries = df.loc[:, ~df.columns.isin([\"AU\", \"emotion\", \"Unnamed: 0\"])].values.flatten()\n",
    "            numerical_entries = numerical_entries[~pd.isnull(numerical_entries)]\n",
    "\n",
    "            # Check if the index is within the range of numerical entries\n",
    "            if index < len(numerical_entries):\n",
    "                # Find the label corresponding to the index\n",
    "                row_index, col_index = divmod(index, len(col_labels))\n",
    "\n",
    "                return f\"{col_labels[col_index]} {row_labels[row_index]}\"\n",
    "\n",
    "            else:\n",
    "                index -= len(numerical_entries)\n",
    "\n",
    "    # Return None if the index is out of range or no suitable sheets found\n",
    "    print('BUG IN THE CODE! INDEX TOO LARGE! CHECK get_label_from_index')\n",
    "    print('spreadsheet path is ', spreadsheet_path)\n",
    "    return None\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sanity Check: Correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def calculate_pearsons_r(features_dict, y):\n",
    "    \"\"\"\n",
    "    Calculate Pearson's R correlation coefficient for each feature in each time window with the answers.\n",
    "\n",
    "    Parameters:\n",
    "    - features_dict: Dictionary with numerical keys for time_windows, each mapping to a (num_answers, num_features) array.\n",
    "    - y: Numpy array of answers with shape (num_answers,).\n",
    "\n",
    "    Returns:\n",
    "    - A dictionary with the same time_window keys, where each key maps to a (num_features,) numpy array of Pearson's R values.\n",
    "    \"\"\"\n",
    "    correlations = {}\n",
    "\n",
    "    for time_window, features in features_dict.items():\n",
    "        # Check if the dimensions match between features and answers\n",
    "        if features.shape[0] != y.shape[0]:\n",
    "            raise ValueError(f\"Number of answers ({y.shape[0]}) does not match number of samples ({features.shape[0]}) in time window {time_window}.\")\n",
    "\n",
    "        # Initialize an array to store Pearson's R values for each feature\n",
    "        pearsons_r_values = np.zeros(features.shape[1])\n",
    "\n",
    "        # Calculate Pearson's R for each feature\n",
    "        for feature_idx in range(features.shape[1]):\n",
    "            feature_data = features[:, feature_idx]\n",
    "            r, _ = pearsonr(feature_data, y)\n",
    "            pearsons_r_values[feature_idx] = r\n",
    "\n",
    "        # Get rid of nans (usually from all features being 0)\n",
    "        pearsons_r_values = np.nan_to_num(pearsons_r_values)\n",
    "        \n",
    "        correlations[time_window] = pearsons_r_values\n",
    "\n",
    "    return correlations\n",
    "\n",
    "\n",
    "\n",
    "def filter_features_by_correlation_and_get_labels(features_dict, correlations, threshold, spreadsheet_path):\n",
    "    \"\"\"\n",
    "    Filter features based on Pearson's R correlation threshold and return selected feature labels.\n",
    "\n",
    "    Parameters:\n",
    "    - features_dict: Dictionary with numerical keys for time_windows, each mapping to a (num_answers, num_features) array.\n",
    "    - correlations: Dictionary with the same time_window keys, mapping to (num_features,) numpy array of Pearson's R values.\n",
    "    - threshold: Minimum Pearson's R correlation required to keep a feature.\n",
    "\n",
    "    Returns:\n",
    "    - A modified features_dict that only includes features with Pearson's R correlation >= threshold.\n",
    "    - An array of strings indicating the names of the selected features across all time windows.\n",
    "    \"\"\"\n",
    "    filtered_features_dict = {}\n",
    "    selected_feature_indices = set()\n",
    "\n",
    "    for time_window, pearsons_r_values in correlations.items():\n",
    "        # Identify features that meet or exceed the correlation threshold\n",
    "        features_to_keep = np.where(pearsons_r_values >= threshold)[0]\n",
    "        selected_feature_indices.update(features_to_keep)\n",
    "\n",
    "        # Filter the original features based on the identified indices\n",
    "        filtered_features = features_dict[time_window][:, features_to_keep]\n",
    "\n",
    "        filtered_features_dict[time_window] = filtered_features\n",
    "\n",
    "    # Get the labels for the selected features\n",
    "    selected_feature_labels = [get_label_from_index(index, spreadsheet_path=spreadsheet_path) for index in sorted(selected_feature_indices)]\n",
    "\n",
    "    return filtered_features_dict, selected_feature_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Predict with just correlated features\n",
    "\n",
    "all_metrics = [col for col in df_moodTracking.columns if col != 'Datetime']\n",
    "\n",
    "FILE_ENDING = '.png'\n",
    "\n",
    "# We are just searching using lasso regression\n",
    "#RESULTS_PREFIX_LIST = ['OF_L_', 'OGAU_L_', 'OFAUHSE_L_', 'OGAUHSE_L_', 'HSE_L_', 'ALL_L_']\n",
    "#RESULTS_PREFIX_LIST = ['OGAU_L_', 'OGAUHSE_L_', 'HSE_L_']\n",
    "RESULTS_PREFIX_LIST = ['OF_L_']\n",
    "\n",
    "\n",
    "EMOTIONS_FOR_SEARCH = ['MADRS'] # We are just searching on Mood\n",
    "TIME_WINDOW_FOR_SEARCH = 5\n",
    "ALPHAS_FOR_SEARCH = np.arange(0, 10, 0.1)\n",
    "\n",
    "best_alphas = {}\n",
    "\n",
    "for RESULTS_PREFIX in RESULTS_PREFIX_LIST:\n",
    "  do_lasso = False\n",
    "  do_ridge = False\n",
    "\n",
    "  if '_L_' in RESULTS_PREFIX:\n",
    "    do_lasso = True\n",
    "\n",
    "  if '_R_' in RESULTS_PREFIX:\n",
    "    do_ridge = True\n",
    "\n",
    "\n",
    "  if 'OF_' in RESULTS_PREFIX:\n",
    "    spreadsheet_path = FEATURE_LABEL_PATH+f'experimental_openface_0.5_hours.xlsx'\n",
    "    vectors_now = openface_vectors_dict\n",
    "    method_now = 'OpenFace'\n",
    "\n",
    "  elif 'OGAU_' in RESULTS_PREFIX:\n",
    "    spreadsheet_path = FEATURE_LABEL_PATH+'opengraphau_0.5_hours.xlsx'\n",
    "    vectors_now = opengraphau_vectors_dict\n",
    "    method_now = 'OpenGraphAU'\n",
    "\n",
    "  elif 'OFAUHSE_' in RESULTS_PREFIX:\n",
    "    spreadsheet_path = FEATURE_LABEL_PATH+'ofauhse_0.5_hours.xlsx'\n",
    "    vectors_now = ofauhsemotion_vectors_dict\n",
    "    method_now = 'OFAU+HSE'\n",
    "\n",
    "  elif 'OGAUHSE_' in RESULTS_PREFIX:\n",
    "    spreadsheet_path = FEATURE_LABEL_PATH+'ogauhse_0.5_hours.xlsx'\n",
    "    vectors_now = ogauhsemotion_vectors_dict\n",
    "    method_now = 'OGAU+HSE'\n",
    "\n",
    "  elif 'HSE_' in RESULTS_PREFIX:\n",
    "    spreadsheet_path = FEATURE_LABEL_PATH+'hsemotion_0.5_hours.xlsx'\n",
    "    vectors_now = hsemotion_vectors_dict\n",
    "    method_now = 'HSEmotion'\n",
    "\n",
    "  elif 'ALL_' in RESULTS_PREFIX:\n",
    "    spreadsheet_path = FEATURE_LABEL_PATH+'all_0.5_hours.xlsx'\n",
    "    vectors_now = all_vectors_dict\n",
    "    method_now = 'ALL(OF+OG+HSE)'\n",
    "\n",
    "\n",
    "  # Let's put each setting in its own folder!\n",
    "  os.makedirs(RESULTS_PATH_BASE + 'SANITY_CHECK_Corr/' + RESULTS_PREFIX, exist_ok=True)\n",
    "  results_prefix_unmodified = RESULTS_PREFIX\n",
    "  RESULTS_PREFIX = 'SANITY_CHECK_Corr/' + RESULTS_PREFIX + '/' + RESULTS_PREFIX\n",
    "\n",
    "  best_alphas_across_metrics = []\n",
    "    \n",
    "  # Loop through EMOTIONS_FOR_SEARCH\n",
    "  for metric in EMOTIONS_FOR_SEARCH:\n",
    "    print('METRIC NOW: ', metric)\n",
    "    vectors_return, y = extractOneMetric(metric, vectors_now=vectors_now)\n",
    "\n",
    "    # Limit to just one time window for this sanity check\n",
    "    tmp_vectors = vectors_return\n",
    "    vectors_return = {}\n",
    "    vectors_return[TIME_WINDOW_FOR_SEARCH] = tmp_vectors[TIME_WINDOW_FOR_SEARCH]\n",
    "    del tmp_vectors\n",
    "\n",
    "    correlations = calculate_pearsons_r(vectors_return, y)\n",
    "\n",
    "    MIN_THRESHOLD = 0.4\n",
    "\n",
    "    vectors_return, feature_names = filter_features_by_correlation_and_get_labels(vectors_return, correlations, threshold=MIN_THRESHOLD, spreadsheet_path=spreadsheet_path)\n",
    "    \n",
    "    print(feature_names)\n",
    "\n",
    "    best_alpha = 0\n",
    "    best_r = -100\n",
    "    for alpha_now in ALPHAS_FOR_SEARCH:\n",
    "    \n",
    "        scores, preds, y, models = linRegOneMetric(vectors_return, y, do_lasso=do_lasso, do_ridge=do_ridge, alpha=alpha_now)\n",
    "        scores_r, preds_r, _, models_r = linRegOneMetric(vectors_return, y, randShuffle=True, alpha=alpha_now)\n",
    "    \n",
    "        # make scatterplots\n",
    "        randShuffleR, _, _ = plot_scatterplots(preds_r, y, f'{metric} Random Shuffle', RESULTS_PATH_BASE + f'{RESULTS_PREFIX}{metric}_linReg_scatterRand_{alpha_now}{FILE_ENDING}')\n",
    "        r_list, p_list, scatterFig = plot_scatterplots(preds, y, metric, RESULTS_PATH_BASE + f'{RESULTS_PREFIX}{metric}_linReg_scatterplots_{alpha_now}{FILE_ENDING}', randShuffleR=randShuffleR)\n",
    "        if r_list[0] > best_r:\n",
    "            best_alpha = alpha_now\n",
    "            best_r = r_list[0]\n",
    "    \n",
    "    best_alphas_across_metrics.append(best_alpha)\n",
    "    print(f'BEST PEARSON\\'S R FOR {metric}: {best_r}. Alpha = {best_alpha}')\n",
    "\n",
    "  best_alphas[RESULTS_PREFIX] = np.mean(best_alphas_across_metrics)\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'BEST PEARSON\\'S R FOR {metric}: {best_r}. Alpha = {best_alpha}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ECLHmN7qYYiy"
   },
   "source": [
    "## Alpha Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cz5HFPcNWRw1",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# ALPHA PARAMETER SEARCH FOR LASSO - RUN THIS FIRST!\n",
    "\n",
    "all_metrics = [col for col in df_moodTracking.columns if col != 'Datetime']\n",
    "\n",
    "FILE_ENDING = '.png'\n",
    "\n",
    "# We are just searching using lasso regression\n",
    "#RESULTS_PREFIX_LIST = ['OF_L_', 'OGAU_L_', 'OFAUHSE_L_', 'OGAUHSE_L_', 'HSE_L_', 'ALL_L_']\n",
    "#RESULTS_PREFIX_LIST = ['OGAU_L_', 'OGAUHSE_L_', 'HSE_L_']\n",
    "RESULTS_PREFIX_LIST = ['OF_L_']\n",
    "\n",
    "\n",
    "EMOTIONS_FOR_SEARCH = ['MADRS'] # We are just searching on Mood\n",
    "TIME_WINDOW_FOR_SEARCH = 10 # We are just searching 10 minutes\n",
    "\n",
    "# List of alpha values to search through\n",
    "ALPHAS_FOR_SEARCH = np.arange(0, 10, 0.1)\n",
    "#ALPHAS_FOR_SEARCH = np.arange(0.1, 1, 0.1)\n",
    "#ALPHAS_FOR_SEARCH = np.arange(0, 1.6, 0.1)\n",
    "#ALPHAS_FOR_SEARCH = np.arange(0, 3, 0.2)\n",
    "#ALPHAS_FOR_SEARCH = np.arange(0, 5, 0.2)\n",
    "\n",
    "\n",
    "# This will populate with the best alphas for each prefix in RESULTS_PREFIX_LIST\n",
    "best_alphas_lasso = {}\n",
    "\n",
    "for RESULTS_PREFIX in RESULTS_PREFIX_LIST:\n",
    "  do_lasso = False\n",
    "  do_ridge = False\n",
    "\n",
    "  if '_L_' in RESULTS_PREFIX:\n",
    "    do_lasso = True\n",
    "\n",
    "  if '_R_' in RESULTS_PREFIX:\n",
    "    do_ridge = True\n",
    "\n",
    "\n",
    "  if 'OF_' in RESULTS_PREFIX:\n",
    "    spreadsheet_path = FEATURE_LABEL_PATH+f'experimental_openface_0.5_hours.xlsx'\n",
    "    vectors_now = openface_vectors_dict\n",
    "    method_now = 'OpenFace'\n",
    "\n",
    "  elif 'OGAU_' in RESULTS_PREFIX:\n",
    "    spreadsheet_path = FEATURE_LABEL_PATH+'opengraphau_0.5_hours.xlsx'\n",
    "    vectors_now = opengraphau_vectors_dict\n",
    "    method_now = 'OpenGraphAU'\n",
    "\n",
    "  elif 'OFAUHSE_' in RESULTS_PREFIX:\n",
    "    spreadsheet_path = FEATURE_LABEL_PATH+'ofauhse_0.5_hours.xlsx'\n",
    "    vectors_now = ofauhsemotion_vectors_dict\n",
    "    method_now = 'OFAU+HSE'\n",
    "\n",
    "  elif 'OGAUHSE_' in RESULTS_PREFIX:\n",
    "    spreadsheet_path = FEATURE_LABEL_PATH+'ogauhse_0.5_hours.xlsx'\n",
    "    vectors_now = ogauhsemotion_vectors_dict\n",
    "    method_now = 'OGAU+HSE'\n",
    "\n",
    "  elif 'HSE_' in RESULTS_PREFIX:\n",
    "    spreadsheet_path = FEATURE_LABEL_PATH+'hsemotion_0.5_hours.xlsx'\n",
    "    vectors_now = hsemotion_vectors_dict\n",
    "    method_now = 'HSEmotion'\n",
    "\n",
    "  elif 'ALL_' in RESULTS_PREFIX:\n",
    "    spreadsheet_path = FEATURE_LABEL_PATH+'all_0.5_hours.xlsx'\n",
    "    vectors_now = all_vectors_dict\n",
    "    method_now = 'ALL(OF+OG+HSE)'\n",
    "\n",
    "\n",
    "  # Let's put each setting in its own folder!\n",
    "  os.makedirs(RESULTS_PATH_BASE + 'SEARCH_Alpha_Lasso/' + RESULTS_PREFIX, exist_ok=True)\n",
    "  results_prefix_unmodified = RESULTS_PREFIX\n",
    "  RESULTS_PREFIX = 'SEARCH_Alpha_Lasso/' + RESULTS_PREFIX + '/' + RESULTS_PREFIX\n",
    "\n",
    "  # This will store the best R, averaged across all metrics we're testing, for each alpha\n",
    "  pearson_r_list = []\n",
    "\n",
    "  for alpha_now in ALPHAS_FOR_SEARCH:\n",
    "\n",
    "    avg_best_R = 0\n",
    "\n",
    "    # Loop through EMOTIONS_FOR_SEARCH\n",
    "    for metric in EMOTIONS_FOR_SEARCH:\n",
    "      print('METRIC NOW: ', metric)\n",
    "      vectors_return, y = extractOneMetric(metric, vectors_now=vectors_now)\n",
    "\n",
    "      # Limit to just one time window for alpha search\n",
    "      tmp_vectors = vectors_return\n",
    "      vectors_return = {}\n",
    "      vectors_return[TIME_WINDOW_FOR_SEARCH] = tmp_vectors[TIME_WINDOW_FOR_SEARCH]\n",
    "      del tmp_vectors\n",
    "\n",
    "      scores, preds, y, models = linRegOneMetric(vectors_return, y, do_lasso=do_lasso, do_ridge=do_ridge, alpha=alpha_now)\n",
    "      scores_r, preds_r, _, models_r = linRegOneMetric(vectors_return, y, randShuffle=True, alpha=alpha_now)\n",
    "\n",
    "      # make scatterplots\n",
    "      randShuffleR, _, _ = plot_scatterplots(preds_r, y, f'{metric} Random Shuffle', RESULTS_PATH_BASE + f'{RESULTS_PREFIX}{metric}_linReg_scatterRand_{alpha_now}{FILE_ENDING}')\n",
    "      r_list, p_list, scatterFig = plot_scatterplots(preds, y, metric, RESULTS_PATH_BASE + f'{RESULTS_PREFIX}{metric}_linReg_scatterplots_{alpha_now}{FILE_ENDING}', randShuffleR=randShuffleR)\n",
    "\n",
    "      # Determine our best time radius for this metric based on Pearson's R\n",
    "      best_time_radius = list(scores.keys())[np.argmax(r_list)]\n",
    "      best_mse_list = scores[best_time_radius]\n",
    "      best_avg_mse = np.mean(scores[best_time_radius])\n",
    "      best_pearson_r = r_list[np.argmax(r_list)]\n",
    "\n",
    "      # Add to our avg best R\n",
    "      avg_best_R = avg_best_R + best_pearson_r\n",
    "\n",
    "      # bar plot for pearson r\n",
    "      rPlotFig = make_r_barplot(r_list, list(scores.keys()), metric, RESULTS_PATH_BASE + f'{RESULTS_PREFIX}{metric}_linReg_R_{alpha_now}{FILE_ENDING}', method_now=method_now)\n",
    "\n",
    "      # make MSE plot\n",
    "      MSEPlotFig = make_mse_boxplot(scores, metric, RESULTS_PATH_BASE + f'{RESULTS_PREFIX}{metric}_linReg_MSE_{alpha_now}{FILE_ENDING}', method_now=method_now)\n",
    "\n",
    "    # Add one R value for this alpha value to pearson_r_list\n",
    "    avg_best_R = avg_best_R / len(EMOTIONS_FOR_SEARCH)\n",
    "    pearson_r_list.append(avg_best_R)\n",
    "\n",
    "  # Plot R vs. alpha for this setting\n",
    "  plot_pearsons_r_vs_alpha(pearson_r_list=pearson_r_list, ALPHAS_FOR_SEARCH=ALPHAS_FOR_SEARCH, method=method_now, save_path=RESULTS_PATH_BASE + f'{RESULTS_PREFIX}{metric}_Alpha_Search{FILE_ENDING}')\n",
    "\n",
    "  # Find best alpha for this setting\n",
    "  best_index_of_alpha = np.argmax(pearson_r_list)\n",
    "  best_alpha_value = ALPHAS_FOR_SEARCH[best_index_of_alpha]\n",
    "  best_alphas_lasso[results_prefix_unmodified] = best_alpha_value\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eVpa4rFGWRw2"
   },
   "outputs": [],
   "source": [
    "# SAVE VARIABLES\n",
    "\n",
    "save_var(best_alphas_lasso, forced_name=f'best_alphas_lasso_{PAT_NOW}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_BRg7NCvWRw2"
   },
   "outputs": [],
   "source": [
    "# LOAD VARIABLES\n",
    "\n",
    "best_alphas_lasso = load_var(f'best_alphas_lasso_{PAT_NOW}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LbrmWuiEYghJ"
   },
   "source": [
    "## Core Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "43grLIvwWRw2"
   },
   "outputs": [],
   "source": [
    "# GENERATE ALL PLOTS! ONE CODE BLOCK\n",
    "\n",
    "if 'best_alphas_lasso' not in globals():\n",
    "    raise NameError(\"GO RUN THE LASSO ALPHA PARAMETER SEARCH BLOCK FIRST!\")\n",
    "\n",
    "#all_metrics = [col for col in df_moodTracking.columns if col != 'Datetime']\n",
    "#all_metrics = ['Mood', 'Anxiety', 'Hunger']\n",
    "all_metrics = ['MADRS']\n",
    "\n",
    "\n",
    "FILE_ENDING = '.png'\n",
    "# RESULTS_PREFIX_LIST = ['OF_', 'OGAU_', 'OFAUHSE_', 'OGAUHSE_', 'HSE_', 'ALL_',\n",
    "#                        'OF_L_', 'OGAU_L_', 'OFAUHSE_L_', 'OGAUHSE_L_', 'HSE_L_', 'ALL_L_',\n",
    "#                        'OF_R_', 'OGAU_R_', 'OFAUHSE_R_', 'OGAUHSE_R_', 'HSE_R_', 'ALL_R_']\n",
    "\n",
    "# RESULTS_PREFIX_LIST = ['OF_L_', 'OGAUHSE_L_', 'OGAU_L_', 'OFAUHSE_L_', 'HSE_L_', 'ALL_L_']\n",
    "\n",
    "#RESULTS_PREFIX_LIST = ['OGAU_L_', 'OGAUHSE_L_', 'HSE_L_']\n",
    "\n",
    "RESULTS_PREFIX_LIST = ['OF_L_']\n",
    "\n",
    "# Do we remove ground truth labels that are over 2 standard deviations from the mean?\n",
    "REMOVE_OUTLIERS = False\n",
    "\n",
    "\n",
    "for RESULTS_PREFIX in RESULTS_PREFIX_LIST:\n",
    "  do_lasso = False\n",
    "  do_ridge = False\n",
    "\n",
    "  if '_L_' in RESULTS_PREFIX:\n",
    "    do_lasso = True\n",
    "\n",
    "  if '_R_' in RESULTS_PREFIX:\n",
    "    do_ridge = True\n",
    "\n",
    "\n",
    "  if 'OF_' in RESULTS_PREFIX:\n",
    "    spreadsheet_path = FEATURE_LABEL_PATH+'experimental_openface_0.5_hours.xlsx'\n",
    "    vectors_now = openface_vectors_dict\n",
    "    method_now = 'OpenFace'\n",
    "\n",
    "  elif 'OGAU_' in RESULTS_PREFIX:\n",
    "    spreadsheet_path = FEATURE_LABEL_PATH+'opengraphau_0.5_hours.xlsx'\n",
    "    vectors_now = opengraphau_vectors_dict\n",
    "    method_now = 'OpenGraphAU'\n",
    "\n",
    "  elif 'OFAUHSE_' in RESULTS_PREFIX:\n",
    "    spreadsheet_path = FEATURE_LABEL_PATH+'ofauhse_0.5_hours.xlsx'\n",
    "    vectors_now = ofauhsemotion_vectors_dict\n",
    "    method_now = 'OFAU+HSE'\n",
    "\n",
    "  elif 'OGAUHSE_' in RESULTS_PREFIX:\n",
    "    spreadsheet_path = FEATURE_LABEL_PATH+'ogauhse_0.5_hours.xlsx'\n",
    "    vectors_now = ogauhsemotion_vectors_dict\n",
    "    method_now = 'OGAU+HSE'\n",
    "\n",
    "  elif 'HSE_' in RESULTS_PREFIX:\n",
    "    spreadsheet_path = FEATURE_LABEL_PATH+'hsemotion_0.5_hours.xlsx'\n",
    "    vectors_now = hsemotion_vectors_dict\n",
    "    method_now = 'HSEmotion'\n",
    "\n",
    "  elif 'ALL_' in RESULTS_PREFIX:\n",
    "    spreadsheet_path = FEATURE_LABEL_PATH+'all_0.5_hours.xlsx'\n",
    "    vectors_now = all_vectors_dict\n",
    "    method_now = 'ALL(OF+OG+HSE)'\n",
    "\n",
    "\n",
    "  # Let's put each setting in its own folder!\n",
    "  os.makedirs(RESULTS_PATH_BASE + RESULTS_PREFIX, exist_ok=True)\n",
    "  results_prefix_unmodified = RESULTS_PREFIX\n",
    "  RESULTS_PREFIX = RESULTS_PREFIX + '/' + RESULTS_PREFIX\n",
    "\n",
    "\n",
    "  # Loop through metrics (Anxiety, Depression, Mood, etc.)\n",
    "  for metric in all_metrics:\n",
    "    print('METRIC NOW: ', metric)\n",
    "    if do_lasso:\n",
    "      alpha_now = best_alphas_lasso[results_prefix_unmodified]\n",
    "    elif do_ridge:\n",
    "      alpha_now = best_alphas_ridge[results_prefix_unmodified]\n",
    "    else:\n",
    "      # Neither lasso nor ridge, so alpha is irrelevant\n",
    "      alpha_now = 1.0\n",
    "\n",
    "    vectors_return, y = extractOneMetric(metric, vectors_now=vectors_now, remove_outliers=REMOVE_OUTLIERS)\n",
    "    scores, preds, y, models = linRegOneMetric(vectors_return, y, do_lasso=do_lasso, do_ridge=do_ridge, alpha=alpha_now)\n",
    "    scores_r, preds_r, _, models_r = linRegOneMetric(vectors_return, y, randShuffle=True, alpha=alpha_now)\n",
    "\n",
    "    # make scatterplots\n",
    "    randShuffleR, _, _ = plot_scatterplots(preds_r, y, f'{metric} Random Shuffle', RESULTS_PATH_BASE + f'{RESULTS_PREFIX}{metric}_linReg_scatterRand{FILE_ENDING}')\n",
    "    r_list, p_list, scatterFig = plot_scatterplots(preds, y, metric, RESULTS_PATH_BASE + f'{RESULTS_PREFIX}{metric}_linReg_scatterplots{FILE_ENDING}', randShuffleR=randShuffleR)\n",
    "\n",
    "    # Determine our best time radius for this metric based on Pearson's R\n",
    "    best_time_radius = list(scores.keys())[np.argmax(r_list)]\n",
    "    best_mse_list = scores[best_time_radius]\n",
    "    best_avg_mse = np.mean(scores[best_time_radius])\n",
    "    best_pearson_r = r_list[np.argmax(r_list)]\n",
    "\n",
    "    # bar plot for pearson r\n",
    "    rPlotFig = make_r_barplot(r_list, list(scores.keys()), metric, RESULTS_PATH_BASE + f'{RESULTS_PREFIX}{metric}_linReg_R{FILE_ENDING}', method_now=method_now)\n",
    "\n",
    "    # make MSE plot\n",
    "    MSEPlotFig = make_mse_boxplot(scores, metric, RESULTS_PATH_BASE + f'{RESULTS_PREFIX}{metric}_linReg_MSE{FILE_ENDING}', method_now=method_now)\n",
    "\n",
    "    # Feature ablation\n",
    "    feat_ab_scores, feat_ab_prs = featureAblate(vectors_return[best_time_radius], y, do_lasso=do_lasso, do_ridge=do_ridge)\n",
    "\n",
    "    top_indices, featAbMSEFig = plotFeatAbMSEs(feat_ab_scores, best_mse_list, metric, best_time_radius, savepath=RESULTS_PATH_BASE + f'{RESULTS_PREFIX}{metric}_featAblate_MSEs{FILE_ENDING}', spreadsheet_path=spreadsheet_path)\n",
    "    plotFeatAbPRs(feat_ab_prs, best_pearson_r, metric, best_time_radius, savepath=RESULTS_PATH_BASE + f'{RESULTS_PREFIX}{metric}_featAblate_R{FILE_ENDING}', spreadsheet_path=spreadsheet_path)\n",
    "\n",
    "    # extract just ONE scatterplot (the best pearson's R) and save it individually\n",
    "    plt.rcParams['lines.markersize'] = 9\n",
    "    _, _, bestScatterFig = plot_predictions(y, preds[best_time_radius], randShuffleR=randShuffleR[np.argmax(r_list)], ax=None, time_rad=best_time_radius, metric=metric)\n",
    "    bestScatterFig.savefig(RESULTS_PATH_BASE + f'{RESULTS_PREFIX}{metric}_linReg_bestScatter{FILE_ENDING}', bbox_inches='tight')\n",
    "\n",
    "    # Plot top n features vs. self-reported scores\n",
    "    PLOT_NOW = 3\n",
    "    plot_feat_scatterplots(vectors_array=vectors_return[best_time_radius], y=y, feat_ind_list=top_indices[:PLOT_NOW], metric=metric, savepath=RESULTS_PATH_BASE + f'{RESULTS_PREFIX}{metric}_topFeats{FILE_ENDING}', spreadsheet_path=spreadsheet_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "flOR18IHgixA"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression: Binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "from sklearn.model_selection import LeaveOneOut\n",
    "from sklearn.preprocessing import binarize\n",
    "import numpy as np\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score\n",
    "\n",
    "def find_optimal_alpha_and_binary_pred(vectors_return, y):\n",
    "    # Step 1: Binarize y\n",
    "    y_binarized = binarize(y.reshape(-1, 1), threshold=7.99, copy=True).reshape(-1)\n",
    "    \n",
    "    results = {}\n",
    "    \n",
    "    # Step 2: Loop through each key in vectors_return\n",
    "    for key, X in vectors_return.items():\n",
    "        # Step 4: Find the ideal alpha for LASSO logistic regression model\n",
    "        # Note: Cs are the inverse of regularization strength; smaller values specify stronger regularization.\n",
    "        # Using Leave-One-Out cross-validation\n",
    "        clf = LogisticRegressionCV(\n",
    "            Cs=10, cv=LeaveOneOut(), penalty='l1', solver='liblinear', scoring='accuracy', max_iter=1000\n",
    "        ).fit(X, y_binarized)\n",
    "        \n",
    "        # Print the ideal alpha value (regularization strength) used\n",
    "        optimal_alpha = 1 / clf.C_[0]\n",
    "        print(f'Time Window {key} Minutes: Optimal alpha value is {optimal_alpha}')\n",
    "        \n",
    "        # Step 5: AUROC and accuracy\n",
    "        proba = clf.predict_proba(X)[:, 1]\n",
    "        predictions = clf.predict(X)\n",
    "\n",
    "        accuracy = accuracy_score(y_binarized, predictions)\n",
    "\n",
    "        auroc = roc_auc_score(y_binarized, proba)\n",
    "        \n",
    "        # Update results dictionary\n",
    "        results[key] = (accuracy, auroc)\n",
    "\n",
    "        print(f\"Time Window {key} Minutes -- Accuracy: {accuracy}, AUROC: {auroc}\")\n",
    "    \n",
    "    # Step 6: Output the dictionary mapping each key to (accuracy, auroc)\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_metrics = ['MADRS']\n",
    "\n",
    "FILE_ENDING = '.png'\n",
    "\n",
    "RESULTS_PREFIX_LIST = ['OF_L_']\n",
    "\n",
    "REMOVE_OUTLIERS = False\n",
    "\n",
    "for RESULTS_PREFIX in RESULTS_PREFIX_LIST:\n",
    "  do_lasso = False\n",
    "  do_ridge = False\n",
    "\n",
    "  if '_L_' in RESULTS_PREFIX:\n",
    "    do_lasso = True\n",
    "\n",
    "  if '_R_' in RESULTS_PREFIX:\n",
    "    do_ridge = True\n",
    "\n",
    "\n",
    "  if 'OF_' in RESULTS_PREFIX:\n",
    "    spreadsheet_path = FEATURE_LABEL_PATH+'experimental_openface_0.5_hours.xlsx'\n",
    "    vectors_now = openface_vectors_dict\n",
    "    method_now = 'OpenFace'\n",
    "\n",
    "  elif 'OGAU_' in RESULTS_PREFIX:\n",
    "    spreadsheet_path = FEATURE_LABEL_PATH+'opengraphau_0.5_hours.xlsx'\n",
    "    vectors_now = opengraphau_vectors_dict\n",
    "    method_now = 'OpenGraphAU'\n",
    "\n",
    "  elif 'OFAUHSE_' in RESULTS_PREFIX:\n",
    "    spreadsheet_path = FEATURE_LABEL_PATH+'ofauhse_0.5_hours.xlsx'\n",
    "    vectors_now = ofauhsemotion_vectors_dict\n",
    "    method_now = 'OFAU+HSE'\n",
    "\n",
    "  elif 'OGAUHSE_' in RESULTS_PREFIX:\n",
    "    spreadsheet_path = FEATURE_LABEL_PATH+'ogauhse_0.5_hours.xlsx'\n",
    "    vectors_now = ogauhsemotion_vectors_dict\n",
    "    method_now = 'OGAU+HSE'\n",
    "\n",
    "  elif 'HSE_' in RESULTS_PREFIX:\n",
    "    spreadsheet_path = FEATURE_LABEL_PATH+'hsemotion_0.5_hours.xlsx'\n",
    "    vectors_now = hsemotion_vectors_dict\n",
    "    method_now = 'HSEmotion'\n",
    "\n",
    "  elif 'ALL_' in RESULTS_PREFIX:\n",
    "    spreadsheet_path = FEATURE_LABEL_PATH+'all_0.5_hours.xlsx'\n",
    "    vectors_now = all_vectors_dict\n",
    "    method_now = 'ALL(OF+OG+HSE)'\n",
    "\n",
    "\n",
    "  # Let's put each setting in its own folder!\n",
    "  os.makedirs(RESULTS_PATH_BASE + RESULTS_PREFIX, exist_ok=True)\n",
    "  results_prefix_unmodified = RESULTS_PREFIX\n",
    "  RESULTS_PREFIX = RESULTS_PREFIX + '/' + RESULTS_PREFIX\n",
    "\n",
    "\n",
    "  # Loop through metrics (Anxiety, Depression, Mood, etc.)\n",
    "  for metric in all_metrics:\n",
    "    print('METRIC NOW: ', metric)\n",
    "\n",
    "    vectors_return, y = extractOneMetric(metric, vectors_now=vectors_now, df_moodTracking=df_moodTracking_orig, remove_outliers=REMOVE_OUTLIERS)\n",
    "\n",
    "    results_dict = find_optimal_alpha_and_binary_pred(vectors_return, y)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "machine_shape": "hm",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
