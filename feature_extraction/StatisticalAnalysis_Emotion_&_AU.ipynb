{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D57PMLHEVlOm"
      },
      "source": [
        "# Set Parameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "frVOpCRsQFEX"
      },
      "outputs": [],
      "source": [
        "PAT_NOW = \"S23_199\"\n",
        "PAT_SHORT_NAME = \"S_199\"\n",
        "\n",
        "MOOD_TRACKING_SHEET_ID = '1lIIDaEYYFaafsP5qmaQFLrX3aazmhtp1EYoHuSOVvmA'\n",
        "VIDEO_TIMESTAMPS_SHEET_ID = {'S_199': '1Imknn0WvfJpn3t81toPkhYuRXVt09HOXLD4eqd1uwtY',\n",
        "                             'S_212': '1AWhYGByvkL6h58PniHYvmQr0ZV91aSbKoHvEM-3QpkI',\n",
        "                             'S_150': '13WvCtmHQYzkl6Oa1pMhqlfqCIIsRAEhRBK2phukSvcU',\n",
        "                             'S_199b': '1UIhMByERDrqCDUBxPxkZhg8Yh25t0cydJ3Njcjoq7-4',\n",
        "                             'S_211': '1Bu410Pv5r2qdBNroRIqbYP7LluWVgcDXJKOUfqXqQgE',\n",
        "                             'S_214': '1MOPKt0D3AdmDlsuFGCocHv392SETaWprWe9FgYqW354',\n",
        "                             'S_10b': '1VlugOY__KWl2pZJX1UkRUXtVXLGXdyZ9JyI70MlUNsc'}\n",
        "\n",
        "BEHAVIOR_LABELS_SHEET_ID = '1KsJFY8Hd-O5Ly1_8tka1heBnvajlsnJPW2RrQmepKZA'\n",
        "\n",
        "OPENFACE_OUTPUT_DIRECTORY = f'/content/drive/MyDrive/Stanford/AudioFacialEEG/Outputs/OpenFace/{PAT_NOW}/'\n",
        "COMBINED_OUTPUT_DIRECTORY = f'/content/drive/MyDrive/Stanford/AudioFacialEEG/Outputs/Combined/{PAT_NOW}/'\n",
        "\n",
        "RUNTIME_VAR_PATH = '/content/drive/MyDrive/Stanford/AudioFacialEEG/Runtime_Vars/'\n",
        "RESULTS_PATH_BASE = f'/content/drive/MyDrive/Stanford/AudioFacialEEG/Results/{PAT_SHORT_NAME}/'\n",
        "FEATURE_VIS_PATH = f'/content/drive/MyDrive/Stanford/AudioFacialEEG/Feature_Visualization/{PAT_SHORT_NAME}/'\n",
        "FEATURE_LABEL_PATH = '/content/drive/MyDrive/Stanford/AudioFacialEEG/Feature_Labels/'\n",
        "QC_PATH = '/content/drive/MyDrive/Stanford/AudioFacialEEG/Quality_Control/'"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "EMO_FEATURE_SETTING = 2\n",
        "\n",
        "# 0 - Our Custom AU --> Emotions, with all emotions\n",
        "# 1 - Our Custom AU --> Emotions, with just OpenDBM's emotions\n",
        "# 2 - OpenDBM's AU--> Emotions"
      ],
      "metadata": {
        "id": "91MVRRaOj-FH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "STATS_FEATURE_SETTING = 3\n",
        "\n",
        "# 0 - Our new features (including autocorrelation, kurtosis, etc.)\n",
        "# 1 - Our new features, excluding extras like autocorrelation and kurtosis\n",
        "# 2 - Just pres_pct\n",
        "# 3 - Our new features, excluding extras. Do NOT threshold AUs before computing metrics. HSE gets 5 event features. OGAU gets num events and presence percent."
      ],
      "metadata": {
        "id": "b_KxZhrQtcmv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "NORMALIZE_DATA = 0\n",
        "\n",
        "# 0 - No time series normalization\n",
        "# 1 - Yes time series normalization (for each time window)"
      ],
      "metadata": {
        "id": "VIc4rrMwD8N9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SU72QcAcVyLy"
      },
      "source": [
        "# Installs & Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7ZpFPBvsPdNe"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t7QHCYhjQTQ0"
      },
      "outputs": [],
      "source": [
        "\n",
        "from google.colab import auth\n",
        "auth.authenticate_user()\n",
        "import gspread\n",
        "import pandas as pd\n",
        "from oauth2client.client import GoogleCredentials\n",
        "from google.auth import default\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "creds, _ = default()\n",
        "\n",
        "gc = gspread.authorize(creds)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LRX3feHKIR1z"
      },
      "outputs": [],
      "source": [
        "import warnings\n",
        "import pandas as pd\n",
        "\n",
        "# Ignore all warnings\n",
        "pd.options.mode.chained_assignment = None\n",
        "pd.set_option('mode.chained_assignment', None)\n",
        "warnings.filterwarnings('ignore')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_kKGUjhTqo-3"
      },
      "source": [
        "# Runtime Variables"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d6_t0DlpTFmi"
      },
      "outputs": [],
      "source": [
        "# SAVE VARIABLES\n",
        "import pickle\n",
        "\n",
        "\n",
        "def get_var_name(our_variable):\n",
        "    namespace = globals()\n",
        "    for name, obj in namespace.items():\n",
        "        if obj is our_variable:\n",
        "            return name\n",
        "    return None\n",
        "\n",
        "# Save the dictionary to a file using pickle\n",
        "def save_var(our_variable, RUNTIME_VAR_PATH=RUNTIME_VAR_PATH, forced_name=None):\n",
        "  if forced_name is None:\n",
        "    name_now = get_var_name(our_variable)\n",
        "  else:\n",
        "    name_now = forced_name\n",
        "\n",
        "  with open(RUNTIME_VAR_PATH + f'{name_now}.pkl', 'wb') as file:\n",
        "      pickle.dump(our_variable, file)\n",
        "\n",
        "def load_var(variable_name, RUNTIME_VAR_PATH=RUNTIME_VAR_PATH):\n",
        "  # Load from the file\n",
        "  with open(RUNTIME_VAR_PATH + f'{variable_name}.pkl', 'rb') as file:\n",
        "      return pickle.load(file)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_r22R0VLV4Gl"
      },
      "source": [
        "# Mood Tracking Sheet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W_bCqQTwV0cr"
      },
      "outputs": [],
      "source": [
        "# Mood_Tracking Sheet ID\n",
        "sheet_id = MOOD_TRACKING_SHEET_ID\n",
        "\n",
        "## read data and put it in a dataframe\n",
        "spreadsheet = gc.open_by_key(sheet_id)\n",
        "\n",
        "wks = spreadsheet.worksheet(f'{PAT_SHORT_NAME}')\n",
        "\n",
        "data = wks.get_all_values()\n",
        "headers = data.pop(0)\n",
        "\n",
        "df = pd.DataFrame(data, columns=headers)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1IyDMQz7PvrR"
      },
      "outputs": [],
      "source": [
        "## Preprocess the mood tracking sheet\n",
        "\n",
        "# Replace the P_number mood headers with just the mood\n",
        "# df.columns = df.columns.str.replace('P[0-9]+ ', '')\n",
        "\n",
        "# Properly deal with the missing values\n",
        "df = df.replace('', np.nan).replace(' ', np.nan).fillna(value=np.nan)\n",
        "\n",
        "df_moodTracking = df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q7eiVTkZVkYq"
      },
      "outputs": [],
      "source": [
        "\n",
        "df_moodTracking[0:4]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iM19VmZb7_2t"
      },
      "outputs": [],
      "source": [
        "\n",
        "import numpy as np\n",
        "\n",
        "# create lists to hold the positive and negative affect items\n",
        "pos_items = [1, 3, 5, 9, 10, 12, 14, 16, 17, 19]\n",
        "neg_items = [2, 4, 6, 7, 8, 11, 13, 15, 18, 20]\n",
        "\n",
        "# get all columns that start with 'P' and split them into pos and neg groups\n",
        "P_cols = [col for col in df_moodTracking.columns if col.startswith('P') and not(col.startswith('Pain')) and not(col.startswith('PANAS'))]\n",
        "pos_cols = [col for col in P_cols if int(col[1:3]) in pos_items]\n",
        "neg_cols = [col for col in P_cols if int(col[1:3]) in neg_items]\n",
        "\n",
        "# create new columns for the summed scores\n",
        "df_moodTracking['Positive Affect Score'] = df_moodTracking[pos_cols].fillna(0).astype(int).sum(axis=1, skipna=True)\n",
        "df_moodTracking['Negative Affect Score'] = df_moodTracking[neg_cols].fillna(0).astype(int).sum(axis=1, skipna=True)\n",
        "df_moodTracking['Overall Affect Score'] = df_moodTracking[['Positive Affect Score', 'Negative Affect Score']].fillna(0).astype(int).sum(axis=1, skipna=True)\n",
        "\n",
        "# replace 0s with NaNs in columns 'Positive Affect Score' and 'Negative Affect Score'\n",
        "df_moodTracking[['Positive Affect Score', 'Negative Affect Score', 'Overall Affect Score']] = \\\n",
        "            df_moodTracking[['Positive Affect Score', 'Negative Affect Score', 'Overall Affect Score']].replace(0, pd.np.nan)\n",
        "\n",
        "# drop the original P columns used to create the scores\n",
        "df_moodTracking.drop(columns=pos_cols + neg_cols, inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
        "import numpy as np\n",
        "\n",
        "def normalize_columns(df, method=1):\n",
        "    # Create a copy of the DataFrame\n",
        "    normalized_df = df.copy()\n",
        "\n",
        "    # Get the column names excluding 'Datetime'\n",
        "    columns_to_normalize = [col for col in normalized_df.columns if col != 'Datetime']\n",
        "\n",
        "    if method == 1:\n",
        "        # No scaling or normalization\n",
        "        pass\n",
        "\n",
        "    elif method == 2:\n",
        "        # MinMax scaling to range 0 to 10\n",
        "        scaler = MinMaxScaler(feature_range=(0, 10))\n",
        "        normalized_df[columns_to_normalize] = scaler.fit_transform(normalized_df[columns_to_normalize])\n",
        "\n",
        "    elif method == 3:\n",
        "        # MinMax scaling to range 0 to 1\n",
        "        scaler = MinMaxScaler(feature_range=(0, 1))\n",
        "        normalized_df[columns_to_normalize] = scaler.fit_transform(normalized_df[columns_to_normalize])\n",
        "\n",
        "    elif method == 4:\n",
        "        # Log scaling\n",
        "        normalized_df[columns_to_normalize] = normalized_df[columns_to_normalize].astype(float)\n",
        "        normalized_df[columns_to_normalize] = np.log1p(normalized_df[columns_to_normalize])\n",
        "\n",
        "    elif method == 5:\n",
        "        # Standard normalization (Z-score normalization)\n",
        "        scaler = StandardScaler()\n",
        "        normalized_df[columns_to_normalize] = scaler.fit_transform(normalized_df[columns_to_normalize])\n",
        "\n",
        "    else:\n",
        "        raise ValueError(\"Invalid method. Choose a value between 1 and 5.\")\n",
        "\n",
        "    return normalized_df"
      ],
      "metadata": {
        "id": "8WpneoG7z-DO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UlXbkPF68v8n"
      },
      "outputs": [],
      "source": [
        "df_moodTracking = normalize_columns(df_moodTracking, method=2)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_moodTracking"
      ],
      "metadata": {
        "id": "i7OKfKaj0A7V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Kg3RagE2u5Pl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-N5cJiTpuyVr"
      },
      "source": [
        "# Video Timestamps"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QoONs-gXu0NZ"
      },
      "outputs": [],
      "source": [
        "# Sheet ID\n",
        "sheet_id = VIDEO_TIMESTAMPS_SHEET_ID[PAT_SHORT_NAME]\n",
        "\n",
        "## read data and put it in a dataframe\n",
        "spreadsheet = gc.open_by_key(sheet_id)\n",
        "\n",
        "wks = spreadsheet.worksheet(f'VideoDatetimes_{PAT_SHORT_NAME.split(\"_\")[-1]}')\n",
        "\n",
        "data = wks.get_all_values()\n",
        "headers = data.pop(0)\n",
        "\n",
        "df_videoTimestamps = pd.DataFrame(data, columns=headers)\n",
        "df_videoTimestamps['Filename'] = df_videoTimestamps['Filename'].str.replace('.m2t', '')\n",
        "\n",
        "if PAT_SHORT_NAME == 'S_199':\n",
        "  # There's no H01 video, so let's drop that filename\n",
        "  df_videoTimestamps = df_videoTimestamps.drop(211)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Check for any missing videos!\n",
        "\n",
        "def print_difference(list1, list2):\n",
        "    for item in list1:\n",
        "        if item not in list2:\n",
        "            print(item)\n",
        "\n",
        "filenames_master_list = list(df_videoTimestamps['Filename'].values)\n",
        "filenames_we_have = [i[:-4] for i in os.listdir(COMBINED_OUTPUT_DIRECTORY)]\n",
        "\n",
        "print_difference(filenames_master_list, filenames_we_have)"
      ],
      "metadata": {
        "id": "M7WfI-u-PR2h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cqMfPe79vFRv"
      },
      "outputs": [],
      "source": [
        "df_videoTimestamps[-5:]"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Danny's Labels (Smile, Laugh, etc.)"
      ],
      "metadata": {
        "id": "Fbw5bePEHjOu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Behavioral labels Sheet ID\n",
        "sheet_id = BEHAVIOR_LABELS_SHEET_ID\n",
        "\n",
        "## read data and put it in a dataframe\n",
        "spreadsheet = gc.open_by_key(sheet_id)\n",
        "\n",
        "wks = spreadsheet.worksheet(PAT_NOW)\n",
        "\n",
        "data = wks.get_all_values()\n",
        "headers = data.pop(0)\n",
        "\n",
        "df = pd.DataFrame(data, columns=headers)\n",
        "\n",
        "columns_to_keep = ['Filename', 'Time Start', 'Time End', 'Behavior']  # List of columns to keep\n",
        "\n",
        "df = df[columns_to_keep]\n",
        "\n",
        "df['Behavior'] = df['Behavior'].str.lower()\n",
        "\n",
        "Danny_Labels = df"
      ],
      "metadata": {
        "id": "TTuEt1ryHoU0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Danny_Labels"
      ],
      "metadata": {
        "id": "JYzTk6QFHoaV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def filter_df_by_behavior(df, desired_string):\n",
        "    # Create a copy of the DataFrame\n",
        "    filtered_df = df.copy()\n",
        "\n",
        "    # Filter the DataFrame based on the desired string within 'Behavior' column\n",
        "    filtered_df = filtered_df[filtered_df['Behavior'].str.contains(desired_string)]\n",
        "\n",
        "    # Reset the index of the filtered DataFrame\n",
        "    filtered_df = filtered_df.reset_index(drop=True)\n",
        "\n",
        "    # Return the filtered DataFrame\n",
        "    return filtered_df"
      ],
      "metadata": {
        "id": "Klnlxpllu2D2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def convert_time(df1, df2):\n",
        "    # df1 has time start and time end for behavior\n",
        "    # df2 has mapping from filename to video start\n",
        "\n",
        "    # Create a copy of the first DataFrame\n",
        "    modified_df = df1.copy()\n",
        "\n",
        "    # Create a dictionary mapping 'Filename' to 'VideoStart'\n",
        "    filename_to_videostart = dict(zip(df2['Filename'], df2['VideoStart']))\n",
        "\n",
        "    # Convert 'Time Start' and 'Time End' columns to datetime based on the filename\n",
        "    if PAT_SHORT_NAME == 'S_150':\n",
        "      # For this patient, the manual labels are in format mm:ss.\n",
        "\n",
        "      modified_df['Time Start'] = modified_df.apply(\n",
        "          lambda row: pd.to_datetime(filename_to_videostart[row['Filename']]) +\n",
        "                      pd.to_timedelta('00:' + row['Time Start'] + ' minutes'),\n",
        "          axis=1\n",
        "      )\n",
        "      modified_df['Time End'] = modified_df.apply(\n",
        "          lambda row: pd.to_datetime(filename_to_videostart[row['Filename']]) +\n",
        "                      pd.to_timedelta('00:' + row['Time End'] + ' minutes'),\n",
        "          axis=1\n",
        "      )\n",
        "    else:\n",
        "      # For all other patients, manual labels are in format mm:ss:00.\n",
        "\n",
        "      modified_df['Time Start'] = modified_df.apply(\n",
        "          lambda row: pd.to_datetime(filename_to_videostart[row['Filename']]) +\n",
        "                      pd.to_timedelta('00:' + row['Time Start'][:-3] + ' minutes'),\n",
        "          axis=1\n",
        "      )\n",
        "      modified_df['Time End'] = modified_df.apply(\n",
        "          lambda row: pd.to_datetime(filename_to_videostart[row['Filename']]) +\n",
        "                      pd.to_timedelta('00:' + row['Time End'][:-3] + ' minutes'),\n",
        "          axis=1\n",
        "      )\n",
        "\n",
        "    # Return the modified DataFrame\n",
        "    return modified_df\n"
      ],
      "metadata": {
        "id": "PP4N11mlw5hx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def buffer_neither(smiles_df, sleep_df):\n",
        "    # returns a single-column pandas df with times when:\n",
        "    # the surrounding 2 minutes (buffer) have neither a smile event nor a sleep event\n",
        "    # note: you can replace smiles_df with any df that has events (e.g. yawns).\n",
        "    # For random sampling, it's looking at a discrete list of datetimes separated by 10 seconds\n",
        "\n",
        "    # Find the earliest and latest times from smiles_df\n",
        "    smiles_earliest = smiles_df['Time Start'].min()\n",
        "    smiles_latest = smiles_df['Time End'].max()\n",
        "\n",
        "    # Find the earliest and latest times from sleep_df\n",
        "    sleep_earliest = sleep_df['Time Start'].min()\n",
        "    sleep_latest = sleep_df['Time End'].max()\n",
        "\n",
        "    # Determine the start and end times\n",
        "    start_time = min(smiles_earliest, sleep_earliest)\n",
        "    end_time = max(smiles_latest, sleep_latest)\n",
        "\n",
        "    # Create a DataFrame with fixed frequency for the time range\n",
        "    time_range = pd.date_range(start=start_time, end=end_time, freq='10S')\n",
        "    tracking_df = pd.DataFrame({'Time': time_range, 'BufferSafe': False})\n",
        "\n",
        "    # Determine the BufferSafe column values\n",
        "    for i in range(len(tracking_df)):\n",
        "        time = tracking_df.loc[i, 'Time']\n",
        "        buffer_before = time - pd.Timedelta(minutes=1)\n",
        "        buffer_after = time + pd.Timedelta(minutes=1)\n",
        "\n",
        "        has_smile_within_buffer = smiles_df[((smiles_df['Time Start'] <= buffer_after) & (smiles_df['Time End'] >= buffer_before))].shape[0] > 0\n",
        "        has_sleep_within_buffer = sleep_df[((sleep_df['Time Start'] <= buffer_after) & (sleep_df['Time End'] >= buffer_before))].shape[0] > 0\n",
        "        tracking_df.loc[i, 'BufferSafe'] = not (has_smile_within_buffer or has_sleep_within_buffer)\n",
        "\n",
        "    # Filter the BufferSafe time intervals\n",
        "    non_smile_non_sleep_buffer_times = tracking_df[tracking_df['BufferSafe']]['Time'].reset_index(drop=True)\n",
        "\n",
        "    return non_smile_non_sleep_buffer_times\n",
        "\n",
        "\n",
        "def create_event_detection_df(smiles_df, safe_series):\n",
        "    # Create a new DataFrame for event detection\n",
        "    event_detection_df = pd.DataFrame(columns=['Datetime', 'EventDetected'])\n",
        "\n",
        "    # Iterate over each row in the smiles_df\n",
        "    for index, row in smiles_df.iterrows():\n",
        "        start_time = row['Time Start']\n",
        "        end_time = row['Time End']\n",
        "\n",
        "        # Generate a range of timestamps at a frequency of 1 second\n",
        "        timestamps = pd.date_range(start=start_time, end=end_time, freq='S', inclusive='right')\n",
        "\n",
        "        # Add each timestamp as a separate row to the event_detection_df\n",
        "        for timestamp in timestamps:\n",
        "            event_detection_df = event_detection_df.append({'Datetime': timestamp, 'EventDetected': 1}, ignore_index=True)\n",
        "\n",
        "    # Get the length of the smile event DataFrame\n",
        "    num_smiles = len(event_detection_df)\n",
        "\n",
        "    # Randomly sample from the buffer safe Series\n",
        "    sampled_safe_series = safe_series.sample(n=num_smiles, replace=False)\n",
        "\n",
        "    # Add nonsmile nonsleep events to the DataFrame\n",
        "    nonsmile_nonsleep_times = sampled_safe_series.reset_index(drop=True)\n",
        "    nonsmile_nonsleep_df = pd.DataFrame({'Datetime': nonsmile_nonsleep_times, 'EventDetected': 0})\n",
        "    event_detection_df = event_detection_df.append(nonsmile_nonsleep_df, ignore_index=True)\n",
        "\n",
        "    # Sort the DataFrame by DateTime in ascending order\n",
        "    event_detection_df = event_detection_df.sort_values(by='Datetime').reset_index(drop=True)\n",
        "\n",
        "    return event_detection_df\n",
        "\n",
        "def get_labels(smile_string, sleep_string):\n",
        "  # gets us our labels df (DateTime and EventDetected columns)\n",
        "  # note: doesn't need to be smiles. Replace 'smile' with any other event as first arg.\n",
        "\n",
        "  # smile string is what we want to detect\n",
        "  # sleep string is what we label as neither smile nor non-smile\n",
        "  # i.e. if a time period is labeled as sleep, exclude from dataset\n",
        "\n",
        "  # Make sure Danny_Labels and df_videoTimestamps have been loaded in already!\n",
        "\n",
        "  Smile_Labels = filter_df_by_behavior(Danny_Labels, smile_string)\n",
        "  Sleep_Labels = filter_df_by_behavior(Danny_Labels, sleep_string)\n",
        "\n",
        "  smiles_df = convert_time(Smile_Labels, df_videoTimestamps)\n",
        "  sleep_df = convert_time(Sleep_Labels, df_videoTimestamps)\n",
        "\n",
        "  non_smile_non_sleep_times = buffer_neither(smiles_df, sleep_df)\n",
        "\n",
        "  return create_event_detection_df(smiles_df, non_smile_non_sleep_times)\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "-7BX6qD1hgA3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# NOTE: The events are defined such that we label the END time and time window looks at 1 s preceding\n",
        "\n",
        "# Eventually, we should run this 500 times to get range of AUROC\n",
        "\n",
        "Final_Smile_Labels = get_labels('smile', 'sleep')"
      ],
      "metadata": {
        "id": "pZ0z-xCgwP6Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Final_Smile_Labels"
      ],
      "metadata": {
        "id": "7tTEJO0CwTKq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Final_Yawn_Labels = get_labels('yawn', 'sleep')"
      ],
      "metadata": {
        "id": "yWzUpbdBYd2C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Final_Yawn_Labels"
      ],
      "metadata": {
        "id": "qDMfrm6WYfS1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Final_Discomfort_Labels = get_labels('discomfort', 'sleep')"
      ],
      "metadata": {
        "id": "fSYsDNu08rQq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Final_Discomfort_Labels"
      ],
      "metadata": {
        "id": "IGStcnbt8128"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Final_Sad_Labels = get_labels('sad', 'sleep')"
      ],
      "metadata": {
        "id": "h_G9TSa3Nm_h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Final_Sad_Labels"
      ],
      "metadata": {
        "id": "QgOC-mWINnPf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dOrT1X_9WU5X"
      },
      "source": [
        "# OpenFace"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YV8_wmALY-hV"
      },
      "outputs": [],
      "source": [
        "# DICTIONARY OF SEPARATE DFS\n",
        "\n",
        "def get_dict_openface(output_dir):\n",
        "  # Create an empty dictionary to hold the DataFrames\n",
        "  dfs_openface = {}\n",
        "\n",
        "  # Get a list of all the CSV files in the directory\n",
        "  csv_files = sorted([f for f in os.listdir(output_dir) if f.endswith('.csv')])\n",
        "\n",
        "  # list of columns to keep\n",
        "  columns_to_keep = ['frame', ' timestamp', ' success',\n",
        "                    ' AU01_r',\n",
        "                    ' AU02_r',\n",
        "                    ' AU04_r',\n",
        "                    ' AU05_r',\n",
        "                    ' AU06_r',\n",
        "                    ' AU07_r',\n",
        "                    ' AU09_r',\n",
        "                    ' AU10_r',\n",
        "                    ' AU12_r',\n",
        "                    ' AU14_r',\n",
        "                    ' AU15_r',\n",
        "                    ' AU17_r',\n",
        "                    ' AU20_r',\n",
        "                    ' AU23_r',\n",
        "                    ' AU25_r',\n",
        "                    ' AU26_r',\n",
        "                    ' AU45_r',\n",
        "                    ' AU01_c',\n",
        "                    ' AU02_c',\n",
        "                    ' AU04_c',\n",
        "                    ' AU05_c',\n",
        "                    ' AU06_c',\n",
        "                    ' AU07_c',\n",
        "                    ' AU09_c',\n",
        "                    ' AU10_c',\n",
        "                    ' AU12_c',\n",
        "                    ' AU14_c',\n",
        "                    ' AU15_c',\n",
        "                    ' AU17_c',\n",
        "                    ' AU20_c',\n",
        "                    ' AU23_c',\n",
        "                    ' AU25_c',\n",
        "                    ' AU26_c',\n",
        "                    ' AU45_c']\n",
        "\n",
        "  # Loop through the CSV files\n",
        "  for csv_file in csv_files:\n",
        "      # Load data into a pandas df\n",
        "      csv_file_path = os.path.join(output_dir, csv_file)\n",
        "      df_temp = pd.read_csv(csv_file_path)\n",
        "\n",
        "      # keep every 6th row such that it's 5 fps!\n",
        "      X = 6\n",
        "      df_temp = df_temp[df_temp.index % X == 0]\n",
        "\n",
        "      # filter DataFrame to keep only columns in list\n",
        "      df_temp = df_temp.loc[:, columns_to_keep]\n",
        "\n",
        "      # fix column names to not have leading or trailing spaces!\n",
        "      df_temp = df_temp.rename(columns=lambda x: x.strip())\n",
        "\n",
        "      # Store the DataFrame in the dictionary with the csv file name as the key\n",
        "      # remove the '.csv' by doing csv_file[:-4]\n",
        "      dfs_openface[csv_file[:-4]] = df_temp\n",
        "      del df_temp\n",
        "\n",
        "  return dfs_openface\n",
        "\n",
        "\n",
        "def only_successful_frames(df):\n",
        "    # get frames where AU/emotion detection was successful!\n",
        "    return df[df['success'] == 1]\n",
        "\n",
        "def apply_function_to_dict(dictionary, func, **kwargs):\n",
        "    \"\"\"\n",
        "    Apply a function to each DataFrame in a dictionary and return a modified copy of the dictionary.\n",
        "\n",
        "    Args:\n",
        "        dictionary (dict): The dictionary containing DataFrames.\n",
        "        func (function): The function to apply to each DataFrame.\n",
        "        **kwargs: Additional keyword arguments to pass to the function.\n",
        "\n",
        "    Returns:\n",
        "        dict: A modified copy of the dictionary with the function applied to each DataFrame.\n",
        "    \"\"\"\n",
        "    return {key: func(df, **kwargs) for key, df in dictionary.items()}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eTOXk7be8YSH"
      },
      "outputs": [],
      "source": [
        "dfs_openface = get_dict_openface(OPENFACE_OUTPUT_DIRECTORY)\n",
        "dfs_openface = apply_function_to_dict(dfs_openface, only_successful_frames)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wkiuU4NVeACU"
      },
      "outputs": [],
      "source": [
        "# SAVE THE OPENFACE DICTIONARY\n",
        "\n",
        "save_var(dfs_openface, forced_name=f'dfs_openface_{PAT_SHORT_NAME}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Py2RgmTAekZS"
      },
      "outputs": [],
      "source": [
        "# LOAD THE OPENFACE DICTIONARY\n",
        "\n",
        "dfs_openface = load_var(f'dfs_openface_{PAT_SHORT_NAME}')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yTcrVT0z0RzO"
      },
      "outputs": [],
      "source": [
        "# RAM CHECK\n",
        "\n",
        "import sys\n",
        "sumsize = 0\n",
        "for i in list(globals().keys()):\n",
        "  size = sys.getsizeof(globals()[i])\n",
        "  # print(i, ': ', size)\n",
        "  sumsize = sumsize + size\n",
        "\n",
        "print(f'Total variables in RAM: {sumsize / (1024 ** 2)} MB')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kzAOLb_jSWk0"
      },
      "outputs": [],
      "source": [
        "# CLEAR UP RAM\n",
        "\n",
        "for key in list(globals().keys()):\n",
        "    if (key.startswith('_i') and key != '_ih') or (key.startswith('_') and key[1:].isdigit()):\n",
        "        del globals()[key]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wkgxRTcLvkw-"
      },
      "outputs": [],
      "source": [
        "dfs_openface['3332W200']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vXD64i_f8az8"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# List to store the average percentages\n",
        "avg_percentages = []\n",
        "\n",
        "# Iterate over each column ending with '_c'\n",
        "for column in dfs_openface['3332W200'].filter(regex='_c$').columns:\n",
        "    # Calculate the percentage of zeros for each key in the dictionary\n",
        "    percentages = [df[column].value_counts(normalize=True)[0] * 100 for df in dfs_openface.values()]\n",
        "\n",
        "    # Calculate the average percentage\n",
        "    avg_percentage = np.mean(percentages)\n",
        "    avg_percentages.append(avg_percentage)\n",
        "\n",
        "# Create the bar plot\n",
        "fig, ax = plt.subplots(figsize=(10, 6))\n",
        "ax.bar(dfs_openface['3332W200'].filter(regex='_c$').columns, avg_percentages, width=0.6)  # Adjust width as desired\n",
        "\n",
        "# Set labels and title\n",
        "ax.set_xlabel('Columns')\n",
        "ax.set_ylabel('Average Percentage of Zeros')\n",
        "ax.set_title(f'Average Percentage of Zeros for Classification Columns, Threshold = Default')\n",
        "\n",
        "# Rotate x-axis labels for better readability\n",
        "plt.xticks(rotation=45)\n",
        "\n",
        "# Display the plot\n",
        "plt.savefig(RESULTS_PATH_BASE + f'openface_threshold_default.png', bbox_inches='tight')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t52_30WQzYeh"
      },
      "source": [
        "# HSEmotion & OpenGraphAU"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aUg5iqkRtIJX"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "\n",
        "def get_dict(output_dir, file_now='outputs_hse.csv', filterOutLR=True):\n",
        "\n",
        "  # Initialize an empty dictionary to store the dataframes\n",
        "  df_dict = {}\n",
        "\n",
        "  # Loop through the subfolders in alphabetical order\n",
        "  for subfolder_name in sorted(os.listdir(output_dir)):\n",
        "\n",
        "    # Check if the subfolder contains CSV files\n",
        "    subfolder_path = os.path.join(output_dir, subfolder_name)\n",
        "    if not os.path.isdir(subfolder_path):\n",
        "      continue\n",
        "\n",
        "    # Load the first CSV file in the subfolder into a dataframe\n",
        "    csv_file_path = os.path.join(subfolder_path, file_now)\n",
        "    if not os.path.isfile(csv_file_path):\n",
        "      continue\n",
        "\n",
        "    try:\n",
        "      df_temp = pd.read_csv(csv_file_path)\n",
        "    except:\n",
        "      df_temp = pd.DataFrame(columns=['frame', 'timestamp', 'success', 'AU1', 'AU2', 'AU4', 'AU5', 'AU6', 'AU7', 'AU9',\n",
        "       'AU10', 'AU11', 'AU12', 'AU13', 'AU14', 'AU15', 'AU16', 'AU17', 'AU18',\n",
        "       'AU19', 'AU20', 'AU22', 'AU23', 'AU24', 'AU25', 'AU26', 'AU27', 'AU32',\n",
        "       'AU38', 'AU39'])\n",
        "\n",
        "\n",
        "    # OpenGraphAU - we are filtering out L and R!\n",
        "    if filterOutLR:\n",
        "      df_temp = df_temp.filter(regex='^(?!AUL|AUR)')\n",
        "\n",
        "    # Add the dataframe to the dictionary with the subfolder name as the key\n",
        "    # We do [:-4] to remove '.mp4' from the end of the string\n",
        "    df_dict[subfolder_name[:-4]] = df_temp\n",
        "\n",
        "  return df_dict\n",
        "\n",
        "def create_binary_columns(df, threshold):\n",
        "    df_copy = df.copy()\n",
        "    # adds classification columns to opengraphAU\n",
        "    for col in df_copy.columns:\n",
        "        if col.startswith('AU'):\n",
        "            # Add _c to the column name for the new column\n",
        "            new_col_name = col + '_c'\n",
        "            # Apply the binary classification to the new column\n",
        "            df_copy[new_col_name] = df_copy[col].apply(lambda x: 1 if x >= threshold else 0)\n",
        "            # Add _r to the original column name\n",
        "            df_copy = df_copy.rename(columns={col: col + '_r'}, inplace=False)\n",
        "    return df_copy\n",
        "\n",
        "def remove_columns_ending_with_r(df):\n",
        "    columns_to_drop = [col for col in df.columns if col.endswith('_r')]\n",
        "    df = df.drop(columns=columns_to_drop, inplace=False)\n",
        "    return df\n",
        "\n",
        "\n",
        "def only_successful_frames(df):\n",
        "    # get frames where AU/emotion detection was successful!\n",
        "    return df[df['success'] == 1]\n",
        "\n",
        "\n",
        "def apply_function_to_dict(dictionary, func, **kwargs):\n",
        "    \"\"\"\n",
        "    Apply a function to each DataFrame in a dictionary and return a modified copy of the dictionary.\n",
        "\n",
        "    Args:\n",
        "        dictionary (dict): The dictionary containing DataFrames.\n",
        "        func (function): The function to apply to each DataFrame.\n",
        "        **kwargs: Additional keyword arguments to pass to the function.\n",
        "\n",
        "    Returns:\n",
        "        dict: A modified copy of the dictionary with the function applied to each DataFrame.\n",
        "    \"\"\"\n",
        "    return {key: func(df, **kwargs) for key, df in dictionary.items()}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mEea0RmkACqS"
      },
      "outputs": [],
      "source": [
        "dfs_hsemotion = get_dict(COMBINED_OUTPUT_DIRECTORY, file_now='outputs_hse.csv')\n",
        "dfs_hsemotion = apply_function_to_dict(dfs_hsemotion, only_successful_frames)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MQjRLc6E7st0"
      },
      "outputs": [],
      "source": [
        "OPENGRAPHAU_THRESHOLD = 0.5\n",
        "dfs_opengraphau = get_dict(COMBINED_OUTPUT_DIRECTORY, file_now='outputs_ogau.csv')\n",
        "dfs_opengraphau = apply_function_to_dict(dfs_opengraphau, create_binary_columns, threshold=OPENGRAPHAU_THRESHOLD)\n",
        "dfs_opengraphau = apply_function_to_dict(dfs_opengraphau, only_successful_frames)\n",
        "dfs_opengraphau = apply_function_to_dict(dfs_opengraphau, remove_columns_ending_with_r)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EA_FYs-8e12m"
      },
      "outputs": [],
      "source": [
        "# SAVE THE HSEMOTION AND OPENGRAPHAU DICTIONARIES\n",
        "\n",
        "save_var(dfs_hsemotion, forced_name=f'dfs_hsemotion_{PAT_SHORT_NAME}')\n",
        "\n",
        "save_var(dfs_opengraphau, forced_name=f'dfs_opengraphau_{PAT_SHORT_NAME}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0c_gdTS1fAoE"
      },
      "outputs": [],
      "source": [
        "# LOAD THE HSEMOTION AND OPENGRAPHAU DICTIONARIES\n",
        "\n",
        "dfs_hsemotion = load_var(f'dfs_hsemotion_{PAT_SHORT_NAME}')\n",
        "\n",
        "dfs_opengraphau = load_var(f'dfs_opengraphau_{PAT_SHORT_NAME}')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Mood Tracking - Testing"
      ],
      "metadata": {
        "id": "m4scOwxaKAMb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dfs_opengraphau['61901L00'].columns"
      ],
      "metadata": {
        "id": "2ZGQCKLtHXoh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W7sqFBq3txG7"
      },
      "outputs": [],
      "source": [
        "dfs_hsemotion['3332W200']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OTt9brsD2CDJ"
      },
      "outputs": [],
      "source": [
        "dfs_opengraphau['3332W200']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LmXRlIgU1iI2"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# List to store the average percentages\n",
        "avg_percentages = []\n",
        "\n",
        "# Iterate over each column ending with '_c'\n",
        "for column in dfs_opengraphau['3332W200'].filter(regex='_c$').columns:\n",
        "    # Calculate the percentage of zeros for each key in the dictionary\n",
        "    percentages = [df[column].value_counts(normalize=True)[0] * 100 for df in dfs_opengraphau.values()]\n",
        "\n",
        "    # Calculate the average percentage\n",
        "    avg_percentage = np.mean(percentages)\n",
        "    avg_percentages.append(avg_percentage)\n",
        "\n",
        "# Create the bar plot\n",
        "fig, ax = plt.subplots(figsize=(10, 6))\n",
        "ax.bar(dfs_opengraphau['3332W200'].filter(regex='_c$').columns, avg_percentages, width=0.6)  # Adjust width as desired\n",
        "\n",
        "# Set labels and title\n",
        "ax.set_xlabel('Columns')\n",
        "ax.set_ylabel('Average Percentage of Zeros')\n",
        "ax.set_title(f'Average Percentage of Zeros for Classification Columns, Threshold = {OPENGRAPHAU_THRESHOLD}')\n",
        "\n",
        "# Rotate x-axis labels for better readability\n",
        "plt.xticks(rotation=45)\n",
        "\n",
        "# Display the plot\n",
        "plt.savefig(RESULTS_PATH_BASE + f'opengraphau_threshold_{OPENGRAPHAU_THRESHOLD}.png', bbox_inches='tight')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Smile, Yawn, Etc."
      ],
      "metadata": {
        "id": "atk8wPgaEnPs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dfs_opengraphau = get_dict(COMBINED_OUTPUT_DIRECTORY, file_now='outputs_ogau.csv')\n",
        "dfs_opengraphau = apply_function_to_dict(dfs_opengraphau, only_successful_frames)\n"
      ],
      "metadata": {
        "id": "vMHW6u8fEpCj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# SAVE DF HSEMOTION\n",
        "save_var(dfs_hsemotion, forced_name=f'dfs_hsemotion_{PAT_SHORT_NAME}')\n"
      ],
      "metadata": {
        "id": "YttjHCDnevzg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# SAVE DF OPENGRAPHAU WITHOUT ANY THRESHOLDING\n",
        "save_var(dfs_opengraphau, forced_name=f'dfs_opengraphau_smile_{PAT_SHORT_NAME}')"
      ],
      "metadata": {
        "id": "CnW9mKJ8FLsE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# LOAD VARS FOR BEHAVIOR PREDICTION\n",
        "# NO THRESHOLDING FOR DF OPENGRAPHAU\n",
        "\n",
        "dfs_hsemotion = load_var(f'dfs_hsemotion_{PAT_SHORT_NAME}')\n",
        "\n",
        "dfs_opengraphau = load_var(f'dfs_opengraphau_smile_{PAT_SHORT_NAME}')"
      ],
      "metadata": {
        "id": "qleLVP1hGXur"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Debug"
      ],
      "metadata": {
        "id": "ivt7KCq6iFAD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# CHECK FOR EMPTY CSVs IN ALL FOLDERS\n",
        "\n",
        "import os\n",
        "import pandas as pd\n",
        "\n",
        "# Replace this with your specific root path\n",
        "root_path = COMBINED_OUTPUT_DIRECTORY\n",
        "\n",
        "# Loop through all subdirectories in the root path\n",
        "for subdir, dirs, files in os.walk(root_path):\n",
        "    for file in files:\n",
        "        # Check if the current file is 'outputs_ogau.csv'\n",
        "        if file == 'outputs_ogau.csv' or file == 'outputs_hse.csv':\n",
        "            file_path = os.path.join(subdir, file)\n",
        "            try:\n",
        "                # Attempt to read the csv file\n",
        "                df = pd.read_csv(file_path)\n",
        "\n",
        "                # Check if the DataFrame is empty\n",
        "                if df.empty:\n",
        "                    print(f\"Empty CSV in folder: {subdir}\")\n",
        "                # Check if the DataFrame has no columns\n",
        "                elif df.shape[1] == 0:\n",
        "                    print(f\"No columns in CSV in folder: {subdir}\")\n",
        "                # Check if the DataFrame has only header but no rows\n",
        "                elif df.shape[0] == 0:\n",
        "                    print(f\"Only header, no rows in CSV in folder: {subdir}\")\n",
        "            except pd.errors.EmptyDataError:\n",
        "                # This exception is raised if the CSV is empty/no columns\n",
        "                print(f\"CSV file is empty or has no columns in folder: {subdir}\")\n",
        "            except Exception as e:\n",
        "                print(f\"An error occurred while processing file {file_path}: {e}\")\n"
      ],
      "metadata": {
        "id": "XH_WYGCviGVL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pjDp31PcyrBD"
      },
      "source": [
        "# Select Specific Times"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Setup"
      ],
      "metadata": {
        "id": "7rrCWvN5Kmjr"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rgRoAaIsyuFY"
      },
      "outputs": [],
      "source": [
        "def get_data_within_duration(dfs_dict, df_video_timestamps, datetime, duration):\n",
        "    # Takes in:\n",
        "    # dfs_dict -- a dictionary of dataframes containing csv data from one of the pipelines\n",
        "    # df_video_timestamps -- the VideoDateTimes_199 csv\n",
        "    # datetime -- a pd.datetime value to center our extraction\n",
        "    # duration -- a duration (in minutes) BEFORE the datetime to extract\n",
        "\n",
        "    # Outputs:\n",
        "    # One dataframe with all rows we want, with timestamps converted into correct datetimes\n",
        "    start_datetime = datetime - pd.Timedelta(minutes=duration)\n",
        "    end_datetime = datetime\n",
        "\n",
        "    relevant_keys = df_video_timestamps.loc[(pd.to_datetime(df_video_timestamps['VideoEnd']) >= start_datetime) &\n",
        "                                            (pd.to_datetime(df_video_timestamps['VideoStart']) <= end_datetime), 'Filename'].values\n",
        "\n",
        "    relevant_dfs = []\n",
        "    for key in relevant_keys:\n",
        "        if key in dfs_dict:\n",
        "            video_start = pd.to_datetime(df_video_timestamps.loc[df_video_timestamps['Filename'] == key, 'VideoStart'].values[0])\n",
        "            video_end = pd.to_datetime(df_video_timestamps.loc[df_video_timestamps['Filename'] == key, 'VideoEnd'].values[0])\n",
        "            time_mask = ((dfs_dict[key]['timestamp'] >= (start_datetime - video_start).total_seconds()) &\n",
        "                         (dfs_dict[key]['timestamp'] <= (end_datetime - video_start).total_seconds()))\n",
        "            df = dfs_dict[key].loc[time_mask].copy()\n",
        "            df['timestamp'] = video_start + pd.to_timedelta(df['timestamp'], unit='s')\n",
        "            relevant_dfs.append(df)\n",
        "\n",
        "    if relevant_dfs:\n",
        "        df_combined = pd.concat(relevant_dfs, ignore_index=True, sort=False)\n",
        "        df_combined = df_combined.drop(columns='frame')\n",
        "\n",
        "        return df_combined\n",
        "\n",
        "    print(f\"MAJOR ERROR! ZERO RELEVANT DFS!! DATETIME: {datetime}\")\n",
        "    return pd.DataFrame()\n",
        "\n",
        "def get_radius_dict(TIME_RADIUS_IN_MINUTES, INPUT_DF, df_videoTimestamps, df_moodTracking, takeAll=True):\n",
        "  # takes in the:\n",
        "  # --time radius,\n",
        "  # --input dataframe dict (e.g. is it from OpenFace? HSEmotion?)\n",
        "  # --df with video timestamps\n",
        "  # --df with mood tracking patient reports\n",
        "  # --takeAll - are we taking all reports, or filtering out values w/o mood (e.g. anxiety)? True = no filtering\n",
        "\n",
        "  # returns dictionary of timestamp : df with relevant frames\n",
        "\n",
        "  # We'll make a dictionary, with the relevant df for each datetime we have a report\n",
        "  radius_df_dict = {}\n",
        "  for oneIndex in range(len(df_moodTracking)):\n",
        "    # Let's make sure there's a value collected (or takeAll = True)!\n",
        "    if takeAll:\n",
        "      dt_now = get_moodTracking_datetime(oneIndex, df_moodTracking=df_moodTracking)\n",
        "      filtered_df = get_data_within_duration(INPUT_DF, df_videoTimestamps, dt_now, TIME_RADIUS_IN_MINUTES)\n",
        "      radius_df_dict[dt_now] = filtered_df\n",
        "    else:\n",
        "      val_now = df_moodTracking[oneIndex:oneIndex+1]['Anxiety'][oneIndex]\n",
        "      if isinstance(val_now, str):\n",
        "        # Value was collected\n",
        "        dt_now = get_moodTracking_datetime(oneIndex, df_moodTracking=df_moodTracking)\n",
        "        filtered_df = get_data_within_duration(INPUT_DF, df_videoTimestamps, dt_now, TIME_RADIUS_IN_MINUTES)\n",
        "        radius_df_dict[dt_now] = filtered_df\n",
        "      else:\n",
        "        # No value collected!\n",
        "        print('No value for Anxiety for index ', oneIndex, f'corresponding to {get_moodTracking_datetime(oneIndex, df_moodTracking=df_moodTracking)}')\n",
        "  return radius_df_dict\n",
        "\n",
        "def generate_number_list(start, interval, count):\n",
        "    number_list = [start + i * interval for i in range(count)]\n",
        "    return number_list\n",
        "\n",
        "def get_moodTracking_datetime(index, df_moodTracking):\n",
        "  temp_var = pd.to_datetime(pd.to_datetime(df_moodTracking[index:index+1]['Datetime']).dt.strftime('%d-%b-%Y %H:%M:%S'))\n",
        "  return pd.Timestamp(temp_var[index])"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "9TfTqzxUavwP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Emotion/Affect"
      ],
      "metadata": {
        "id": "WN-kMqgqKobt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# EMOTION DETECTION & AFFECT\n",
        "\n",
        "takeAll = True # we are taking all patient reports\n",
        "\n",
        "# start and interval are in minutes\n",
        "TIME_RADIUS_LIST = generate_number_list(start=15, interval=15, count=16)\n",
        "#TIME_RADIUS_LIST = [60, 120, 180, 240]\n",
        "\n",
        "\n",
        "ENABLE_OPENFACE = False\n",
        "\n",
        "if ENABLE_OPENFACE:\n",
        "  openface_radius_dict = {}\n",
        "\n",
        "hsemotion_radius_dict = {}\n",
        "opengraphau_radius_dict = {}\n",
        "\n",
        "for i in TIME_RADIUS_LIST:\n",
        "  if ENABLE_OPENFACE:\n",
        "    openface_radius_now = get_radius_dict(i, dfs_openface, df_videoTimestamps, df_moodTracking, takeAll=takeAll)\n",
        "\n",
        "  hsemotion_radius_now = get_radius_dict(i, dfs_hsemotion, df_videoTimestamps, df_moodTracking, takeAll=takeAll)\n",
        "  opengraphau_radius_now = get_radius_dict(i, dfs_opengraphau, df_videoTimestamps, df_moodTracking, takeAll=takeAll)\n",
        "\n",
        "  if ENABLE_OPENFACE:\n",
        "    openface_radius_dict[f'{i}'] = openface_radius_now\n",
        "\n",
        "  hsemotion_radius_dict[f'{i}'] = hsemotion_radius_now\n",
        "  opengraphau_radius_dict[f'{i}'] = opengraphau_radius_now\n",
        "\n"
      ],
      "metadata": {
        "id": "YFPiVE4vEgv0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# SAVE VARIABLES - EMOTION DETECTION & AFFECT\n",
        "\n",
        "#save_var(openface_radius_dict, forced_name=f'openface_radius_dict_{PAT_SHORT_NAME}')\n",
        "\n",
        "save_var(hsemotion_radius_dict, forced_name=f'hsemotion_radius_dict_{PAT_SHORT_NAME}')\n",
        "\n",
        "save_var(opengraphau_radius_dict, forced_name=f'opengraphau_radius_dict_{PAT_SHORT_NAME}')\n"
      ],
      "metadata": {
        "id": "W0zI-hKiovfv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# LOAD VARIABLES - EMOTION DETECTION & AFFECT\n",
        "\n",
        "openface_radius_dict = load_var(f'openface_radius_dict_{PAT_SHORT_NAME}')\n",
        "\n",
        "hsemotion_radius_dict = load_var(f'hsemotion_radius_dict_{PAT_SHORT_NAME}')\n",
        "\n",
        "opengraphau_radius_dict = load_var(f'opengraphau_radius_dict_{PAT_SHORT_NAME}')\n"
      ],
      "metadata": {
        "id": "Z1mpGJiz276a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Smile/Yawn"
      ],
      "metadata": {
        "id": "czlR-fFPLagB"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0x2raU986J3R"
      },
      "outputs": [],
      "source": [
        "# SHORT EVENT DETECTION (SMILE, ETC.)\n",
        "takeAll = True # we are taking all patient reports\n",
        "\n",
        "# start and interval are in minutes\n",
        "# example: 0.01666 is 1 second\n",
        "TIME_RADIUS_LIST = [0.01666] # JUST one second\n",
        "\n",
        "openface_radius_dict = {}\n",
        "hsemotion_radius_dict = {}\n",
        "opengraphau_radius_dict = {}\n",
        "\n",
        "DANNY_LABELS_NOW = Final_Smile_Labels\n",
        "\n",
        "for i in TIME_RADIUS_LIST:\n",
        "  openface_radius_now = get_radius_dict(i, dfs_openface, df_videoTimestamps, DANNY_LABELS_NOW, takeAll=takeAll)\n",
        "  hsemotion_radius_now = get_radius_dict(i, dfs_hsemotion, df_videoTimestamps, DANNY_LABELS_NOW, takeAll=takeAll)\n",
        "  opengraphau_radius_now = get_radius_dict(i, dfs_opengraphau, df_videoTimestamps, DANNY_LABELS_NOW, takeAll=takeAll)\n",
        "\n",
        "  openface_radius_dict[f'{i}'] = openface_radius_now\n",
        "  hsemotion_radius_dict[f'{i}'] = hsemotion_radius_now\n",
        "  opengraphau_radius_dict[f'{i}'] = opengraphau_radius_now\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# SAVE VARIABLES - Smile\n",
        "\n",
        "save_var(openface_radius_dict, forced_name=f'openface_radius_dict_smile_1_{PAT_SHORT_NAME}')\n",
        "\n",
        "save_var(hsemotion_radius_dict, forced_name=f'hsemotion_radius_dict_smile_1_{PAT_SHORT_NAME}')\n",
        "\n",
        "save_var(opengraphau_radius_dict, forced_name=f'opengraphau_radius_dict_smile_1_{PAT_SHORT_NAME}')\n",
        "\n",
        "save_var(Final_Smile_Labels, forced_name=f'Final_Smile_Labels_{PAT_SHORT_NAME}')\n"
      ],
      "metadata": {
        "id": "u9rekzkgrNrI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# SAVE VARIABLES - Yawn\n",
        "\n",
        "save_var(openface_radius_dict, forced_name=f'openface_radius_dict_yawn_1_{PAT_SHORT_NAME}')\n",
        "\n",
        "save_var(hsemotion_radius_dict, forced_name=f'hsemotion_radius_dict_yawn_1_{PAT_SHORT_NAME}')\n",
        "\n",
        "save_var(opengraphau_radius_dict, forced_name=f'opengraphau_radius_dict_yawn_1_{PAT_SHORT_NAME}')\n",
        "\n",
        "save_var(Final_Yawn_Labels, forced_name=f'Final_Yawn_Labels_{PAT_SHORT_NAME}')\n"
      ],
      "metadata": {
        "id": "AHuHH7QpwXiP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# SAVE VARIABLES - Discomfort\n",
        "\n",
        "save_var(openface_radius_dict, forced_name=f'openface_radius_dict_discomfort_1_{PAT_SHORT_NAME}')\n",
        "\n",
        "save_var(hsemotion_radius_dict, forced_name=f'hsemotion_radius_dict_discomfort_1_{PAT_SHORT_NAME}')\n",
        "\n",
        "save_var(opengraphau_radius_dict, forced_name=f'opengraphau_radius_dict_discomfort_1_{PAT_SHORT_NAME}')\n",
        "\n",
        "save_var(Final_Discomfort_Labels, forced_name=f'Final_Discomfort_Labels_{PAT_SHORT_NAME}')\n"
      ],
      "metadata": {
        "id": "QpUABDp59pvc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# SAVE VARIABLES - Sad\n",
        "\n",
        "save_var(openface_radius_dict, forced_name=f'openface_radius_dict_sad_1_{PAT_SHORT_NAME}')\n",
        "\n",
        "save_var(hsemotion_radius_dict, forced_name=f'hsemotion_radius_dict_sad_1_{PAT_SHORT_NAME}')\n",
        "\n",
        "save_var(opengraphau_radius_dict, forced_name=f'opengraphau_radius_dict_sad_1_{PAT_SHORT_NAME}')\n",
        "\n",
        "save_var(Final_Sad_Labels, forced_name=f'Final_Sad_Labels_{PAT_SHORT_NAME}')\n"
      ],
      "metadata": {
        "id": "N_GRnXglN0tY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# LOAD VARIABLES - Smile\n",
        "\n",
        "openface_radius_dict = load_var(f'openface_radius_dict_smile_1_{PAT_SHORT_NAME}')\n",
        "\n",
        "hsemotion_radius_dict = load_var(f'hsemotion_radius_dict_smile_1_{PAT_SHORT_NAME}')\n",
        "\n",
        "opengraphau_radius_dict = load_var(f'opengraphau_radius_dict_smile_1_{PAT_SHORT_NAME}')\n",
        "\n",
        "Final_Smile_Labels = load_var(f'Final_Smile_Labels_{PAT_SHORT_NAME}')"
      ],
      "metadata": {
        "id": "LG8Njg5BXRvb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# LOAD VARIABLES - Yawn\n",
        "\n",
        "openface_radius_dict = load_var(f'openface_radius_dict_yawn_1_{PAT_SHORT_NAME}')\n",
        "\n",
        "hsemotion_radius_dict = load_var(f'hsemotion_radius_dict_yawn_1_{PAT_SHORT_NAME}')\n",
        "\n",
        "opengraphau_radius_dict = load_var(f'opengraphau_radius_dict_yawn_1_{PAT_SHORT_NAME}')\n",
        "\n",
        "Final_Yawn_Labels = load_var(f'Final_Yawn_Labels_{PAT_SHORT_NAME}')"
      ],
      "metadata": {
        "id": "XVzLp0ceXR20"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# LOAD VARIABLES - Discomfort\n",
        "\n",
        "openface_radius_dict = load_var(f'openface_radius_dict_discomfort_1_{PAT_SHORT_NAME}')\n",
        "\n",
        "hsemotion_radius_dict = load_var(f'hsemotion_radius_dict_discomfort_1_{PAT_SHORT_NAME}')\n",
        "\n",
        "opengraphau_radius_dict = load_var(f'opengraphau_radius_dict_discomfort_1_{PAT_SHORT_NAME}')\n",
        "\n",
        "Final_Discomfort_Labels = load_var(f'Final_Discomfort_Labels_{PAT_SHORT_NAME}')\n"
      ],
      "metadata": {
        "id": "OWmK_Sz9-unC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# LOAD VARIABLES - Sad\n",
        "\n",
        "openface_radius_dict = load_var(f'openface_radius_dict_sad_1_{PAT_SHORT_NAME}')\n",
        "\n",
        "hsemotion_radius_dict = load_var(f'hsemotion_radius_dict_sad_1_{PAT_SHORT_NAME}')\n",
        "\n",
        "opengraphau_radius_dict = load_var(f'opengraphau_radius_dict_sad_1_{PAT_SHORT_NAME}')\n",
        "\n",
        "Final_Sad_Labels = load_var(f'Final_Sad_Labels_{PAT_SHORT_NAME}')\n"
      ],
      "metadata": {
        "id": "nyPFe1-0N9ax"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J3GZCcHA-jaR"
      },
      "outputs": [],
      "source": [
        "hsemotion_radius_dict['60'].keys()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YiGJoUmQAuEr"
      },
      "outputs": [],
      "source": [
        "hsemotion_radius_dict['60'][get_moodTracking_datetime(2)]"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# LogReg Mapping (Smile, Yawn, etc.)"
      ],
      "metadata": {
        "id": "9DIJGifEdj0g"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Prep"
      ],
      "metadata": {
        "id": "1cLXNBE-dm6y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def only_successful_frames(df):\n",
        "    # get frames where AU/emotion detection was successful!\n",
        "    return df[df['success'] == 1]\n",
        "\n",
        "\n",
        "def clean_data(pipeline_emotion, labels):\n",
        "    # Convert the Datetime column to datetime objects for comparison\n",
        "    labels['Datetime'] = pd.to_datetime(labels['Datetime'])\n",
        "\n",
        "    # Create a list to store keys to be removed\n",
        "    keys_to_remove = []\n",
        "\n",
        "    # Iterate through the pipeline_emotion dictionary\n",
        "    for key, df in pipeline_emotion.items():\n",
        "        # Check if the dataframe is empty\n",
        "        if df.empty:\n",
        "            # Add the key to keys_to_remove list\n",
        "            keys_to_remove.append(key)\n",
        "\n",
        "    # Remove empty dataframes from pipeline_emotion\n",
        "    for key in keys_to_remove:\n",
        "        del pipeline_emotion[key]\n",
        "\n",
        "    # Remove the relevant rows from labels\n",
        "    labels = labels[~labels['Datetime'].isin(keys_to_remove)]\n",
        "\n",
        "    return pipeline_emotion, labels\n",
        "\n",
        "def preprocess_df_radius_dict(df_radius_dict, labels_now, columns_to_keep):\n",
        "  # Takes only successful frames\n",
        "  # Chooses specific columns from each df to keep\n",
        "\n",
        "  df_radius_dict_clean, labels_now_clean = clean_data(df_radius_dict, labels_now)\n",
        "\n",
        "  new_radius_dict = {}\n",
        "  for key1, one_time_df in df_radius_dict_clean.items():\n",
        "    success_df = only_successful_frames(one_time_df)\n",
        "    new_radius_dict[key1] = success_df.loc[:, columns_to_keep]\n",
        "\n",
        "  return new_radius_dict"
      ],
      "metadata": {
        "id": "u2kPJFEadoy2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "openface_radius_dict = openface_radius_dict['0.01666']\n",
        "hsemotion_radius_dict = hsemotion_radius_dict['0.01666']\n",
        "opengraphau_radius_dict = opengraphau_radius_dict['0.01666']\n"
      ],
      "metadata": {
        "id": "989qK4Oqdo1h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# DEBUG ONLY\n",
        "import random; random.choice(list(openface_radius_dict.keys()))"
      ],
      "metadata": {
        "id": "EKgwfdkOBVCw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# SMILE\n",
        "openface_smile = preprocess_df_radius_dict(openface_radius_dict, Final_Smile_Labels,\n",
        "                                                ['AU01_r', 'AU02_r', 'AU04_r', 'AU05_r',\n",
        "       'AU06_r', 'AU07_r', 'AU09_r', 'AU10_r', 'AU12_r', 'AU14_r', 'AU15_r',\n",
        "       'AU17_r', 'AU20_r', 'AU23_r', 'AU25_r', 'AU26_r', 'AU45_r', 'AU01_c',\n",
        "       'AU02_c', 'AU04_c', 'AU05_c', 'AU06_c', 'AU07_c', 'AU09_c', 'AU10_c',\n",
        "       'AU12_c', 'AU14_c', 'AU15_c', 'AU17_c', 'AU20_c', 'AU23_c', 'AU25_c',\n",
        "       'AU26_c', 'AU45_c'])\n",
        "\n",
        "opengraphau_smile = preprocess_df_radius_dict(opengraphau_radius_dict, Final_Smile_Labels,\n",
        "                                                   ['AU1', 'AU2', 'AU4', 'AU5', 'AU6', 'AU7', 'AU9',\n",
        "       'AU10', 'AU11', 'AU12', 'AU13', 'AU14', 'AU15', 'AU16', 'AU17', 'AU18',\n",
        "       'AU19', 'AU20', 'AU22', 'AU23', 'AU24', 'AU25', 'AU26', 'AU27', 'AU32',\n",
        "       'AU38', 'AU39'])\n",
        "\n",
        "hsemotion_smile = preprocess_df_radius_dict(hsemotion_radius_dict, Final_Smile_Labels,\n",
        "                                                 ['Happiness'])\n"
      ],
      "metadata": {
        "id": "dVjZKc7udrhi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# YAWN\n",
        "openface_yawn = preprocess_df_radius_dict(openface_radius_dict, Final_Yawn_Labels,\n",
        "                                                ['AU01_r', 'AU02_r', 'AU04_r', 'AU05_r',\n",
        "       'AU06_r', 'AU07_r', 'AU09_r', 'AU10_r', 'AU12_r', 'AU14_r', 'AU15_r',\n",
        "       'AU17_r', 'AU20_r', 'AU23_r', 'AU25_r', 'AU26_r', 'AU45_r', 'AU01_c',\n",
        "       'AU02_c', 'AU04_c', 'AU05_c', 'AU06_c', 'AU07_c', 'AU09_c', 'AU10_c',\n",
        "       'AU12_c', 'AU14_c', 'AU15_c', 'AU17_c', 'AU20_c', 'AU23_c', 'AU25_c',\n",
        "       'AU26_c', 'AU45_c'])\n",
        "\n",
        "opengraphau_yawn = preprocess_df_radius_dict(opengraphau_radius_dict, Final_Yawn_Labels,\n",
        "                                                   ['AU1', 'AU2', 'AU4', 'AU5', 'AU6', 'AU7', 'AU9',\n",
        "       'AU10', 'AU11', 'AU12', 'AU13', 'AU14', 'AU15', 'AU16', 'AU17', 'AU18',\n",
        "       'AU19', 'AU20', 'AU22', 'AU23', 'AU24', 'AU25', 'AU26', 'AU27', 'AU32',\n",
        "       'AU38', 'AU39'])\n",
        "\n",
        "hsemotion_yawn = preprocess_df_radius_dict(hsemotion_radius_dict, Final_Yawn_Labels,\n",
        "                                                 ['Anger', 'Disgust', 'Fear', 'Happiness',\n",
        "       'Neutral', 'Sadness', 'Surprise'])\n"
      ],
      "metadata": {
        "id": "-nwYcRh4K1Kq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# DISCOMFORT\n",
        "openface_discomfort = preprocess_df_radius_dict(openface_radius_dict, Final_Discomfort_Labels,\n",
        "                                                ['AU01_r', 'AU02_r', 'AU04_r', 'AU05_r',\n",
        "       'AU06_r', 'AU07_r', 'AU09_r', 'AU10_r', 'AU12_r', 'AU14_r', 'AU15_r',\n",
        "       'AU17_r', 'AU20_r', 'AU23_r', 'AU25_r', 'AU26_r', 'AU45_r', 'AU01_c',\n",
        "       'AU02_c', 'AU04_c', 'AU05_c', 'AU06_c', 'AU07_c', 'AU09_c', 'AU10_c',\n",
        "       'AU12_c', 'AU14_c', 'AU15_c', 'AU17_c', 'AU20_c', 'AU23_c', 'AU25_c',\n",
        "       'AU26_c', 'AU45_c'])\n",
        "opengraphau_discomfort = preprocess_df_radius_dict(opengraphau_radius_dict, Final_Discomfort_Labels,\n",
        "                                                   ['AU1', 'AU2', 'AU4', 'AU5', 'AU6', 'AU7', 'AU9',\n",
        "       'AU10', 'AU11', 'AU12', 'AU13', 'AU14', 'AU15', 'AU16', 'AU17', 'AU18',\n",
        "       'AU19', 'AU20', 'AU22', 'AU23', 'AU24', 'AU25', 'AU26', 'AU27', 'AU32',\n",
        "       'AU38', 'AU39'])\n",
        "hsemotion_discomfort = preprocess_df_radius_dict(hsemotion_radius_dict, Final_Discomfort_Labels,\n",
        "                                                 ['Anger', 'Disgust', 'Fear', 'Happiness',\n",
        "       'Neutral', 'Sadness', 'Surprise'])"
      ],
      "metadata": {
        "id": "oei3peGcBJII"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# SAD\n",
        "openface_sad = preprocess_df_radius_dict(openface_radius_dict, Final_Sad_Labels,\n",
        "                                                ['AU01_r', 'AU02_r', 'AU04_r', 'AU05_r',\n",
        "       'AU06_r', 'AU07_r', 'AU09_r', 'AU10_r', 'AU12_r', 'AU14_r', 'AU15_r',\n",
        "       'AU17_r', 'AU20_r', 'AU23_r', 'AU25_r', 'AU26_r', 'AU45_r', 'AU01_c',\n",
        "       'AU02_c', 'AU04_c', 'AU05_c', 'AU06_c', 'AU07_c', 'AU09_c', 'AU10_c',\n",
        "       'AU12_c', 'AU14_c', 'AU15_c', 'AU17_c', 'AU20_c', 'AU23_c', 'AU25_c',\n",
        "       'AU26_c', 'AU45_c'])\n",
        "opengraphau_sad = preprocess_df_radius_dict(opengraphau_radius_dict, Final_Sad_Labels,\n",
        "                                                   ['AU1', 'AU2', 'AU4', 'AU5', 'AU6', 'AU7', 'AU9',\n",
        "       'AU10', 'AU11', 'AU12', 'AU13', 'AU14', 'AU15', 'AU16', 'AU17', 'AU18',\n",
        "       'AU19', 'AU20', 'AU22', 'AU23', 'AU24', 'AU25', 'AU26', 'AU27', 'AU32',\n",
        "       'AU38', 'AU39'])\n",
        "hsemotion_sad = preprocess_df_radius_dict(hsemotion_radius_dict, Final_Sad_Labels,\n",
        "                                                 ['Sadness'])"
      ],
      "metadata": {
        "id": "EpILl3dlOH7h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def shuffle_labels(df):\n",
        "    \"\"\"\n",
        "    Takes in a DataFrame, makes a copy of it, and randomly shuffles the 'EventDetected' labels.\n",
        "\n",
        "    Args:\n",
        "        df (pd.DataFrame): DataFrame containing 'EventDetected' column.\n",
        "\n",
        "    Returns:\n",
        "        shuffled_df (pd.DataFrame): A copy of the original DataFrame with shuffled 'EventDetected' column.\n",
        "    \"\"\"\n",
        "    shuffled_df = df.copy()\n",
        "    shuffled_df['EventDetected'] = df['EventDetected'].sample(frac=1, random_state=42).reset_index(drop=True)\n",
        "    return shuffled_df"
      ],
      "metadata": {
        "id": "DshcJyDzeOyh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Shuffled_Smile_Labels = shuffle_labels(Final_Smile_Labels)"
      ],
      "metadata": {
        "id": "n21wY8yleV0c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Shuffled_Yawn_Labels = shuffle_labels(Final_Yawn_Labels)"
      ],
      "metadata": {
        "id": "rrFnSQyzK-I8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Shuffled_Discomfort_Labels = shuffle_labels(Final_Discomfort_Labels)"
      ],
      "metadata": {
        "id": "tOCDiE9Yfdi4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Shuffled_Sad_Labels = shuffle_labels(Final_Sad_Labels)"
      ],
      "metadata": {
        "id": "9xskTc2qOR7z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Func: Train + Eval (5-Fold CV)"
      ],
      "metadata": {
        "id": "ApAP7JQ3kCxi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import roc_auc_score, roc_curve, accuracy_score, f1_score, average_precision_score\n",
        "import matplotlib.pyplot as plt\n",
        "from IPython.display import display\n",
        "from scipy import interp\n",
        "\n",
        "\n",
        "def train_and_evaluate(smile_dict, Final_Smile_Labels, pipeline_name='OpenFace', results_path=RESULTS_PATH_BASE + 'Smile/'):\n",
        "    # Averaging values across rows for each DataFrame in smile_dict\n",
        "    averaged_values = {timestamp: df.mean() for timestamp, df in smile_dict.items()}\n",
        "\n",
        "    # Convert the dictionary to a DataFrame\n",
        "    averaged_df = pd.DataFrame.from_dict(averaged_values, orient='index', columns=smile_dict[next(iter(smile_dict))].columns)\n",
        "\n",
        "    # Merge with Final_Smile_Labels\n",
        "    merged_df = pd.merge(Final_Smile_Labels, averaged_df, left_on='Datetime', right_index=True)\n",
        "\n",
        "    merged_df.fillna(0, inplace=True)\n",
        "\n",
        "    # Split features and labels\n",
        "    X = merged_df.drop(['Datetime', 'EventDetected'], axis=1)\n",
        "    y = merged_df['EventDetected']\n",
        "    y = y.astype('int')\n",
        "\n",
        "    # Initialize StratifiedKFold and LogisticRegression\n",
        "    NUMBER_OF_FOLDS = 5\n",
        "    skf = StratifiedKFold(n_splits=NUMBER_OF_FOLDS, shuffle=True, random_state=42)\n",
        "    log_reg = LogisticRegression()\n",
        "\n",
        "    # Lists to hold metrics and ROC curve values across folds\n",
        "    auroc_list, accuracy_list, f1_list, auprc_list = [], [], [], []\n",
        "    mean_fpr = np.linspace(0, 1, 100)  # Common grid of FPR values for averaging the ROC curves\n",
        "    tprs = []  # List to hold the TPR values for each fold\n",
        "\n",
        "    for train_index, test_index in skf.split(X, y):\n",
        "        X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
        "        y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
        "\n",
        "        log_reg.fit(X_train, y_train)\n",
        "        y_pred = log_reg.predict(X_test)\n",
        "        y_proba = log_reg.predict_proba(X_test)[:, 1]\n",
        "\n",
        "        # Metrics computation\n",
        "        auroc_list.append(roc_auc_score(y_test, y_proba))\n",
        "        accuracy_list.append(accuracy_score(y_test, y_pred))\n",
        "        f1_list.append(f1_score(y_test, y_pred))\n",
        "        auprc_list.append(average_precision_score(y_test, y_proba))\n",
        "\n",
        "        # ROC Curve values for the current fold\n",
        "        fpr, tpr, _ = roc_curve(y_test, y_proba)\n",
        "        tprs.append(interp(mean_fpr, fpr, tpr))  # Interpolate the TPR values to the common grid of FPR values\n",
        "\n",
        "\n",
        "    # Compute the mean TPR values at each FPR to get the \"averaged\" ROC curve\n",
        "    mean_tpr = np.mean(tprs, axis=0)\n",
        "\n",
        "    # Plotting the curves\n",
        "    for tpr in tprs:\n",
        "      plt.plot(mean_fpr, tpr, color='b', alpha=0.1)  # Plot each fold's ROC curve with a light color\n",
        "    plt.plot(mean_fpr, mean_tpr, color='b', linewidth=2)  # Plot the \"averaged\" ROC curve in bold\n",
        "    plt.title(f'{pipeline_name} 5-Fold CV LogReg')\n",
        "    plt.xlabel('False Positive Rate')\n",
        "    plt.ylabel('True Positive Rate')\n",
        "\n",
        "    # Save the figure to a file\n",
        "    os.makedirs(results_path, exist_ok=True)\n",
        "    output_file_path = os.path.join(results_path, f'{pipeline_name} roc_curve.png')\n",
        "    plt.savefig(output_file_path)\n",
        "\n",
        "    plt.show()\n",
        "\n",
        "    # Reporting metrics\n",
        "    metrics_df = pd.DataFrame({\n",
        "        'Fold': list(range(1, NUMBER_OF_FOLDS + 1)) + ['Average'],\n",
        "        'Accuracy': accuracy_list + [np.mean(accuracy_list)],\n",
        "        'F1 Score': f1_list + [np.mean(f1_list)],\n",
        "        'AUPRC': auprc_list + [np.mean(auprc_list)],\n",
        "        'AUROC': auroc_list + [np.mean(auroc_list)]\n",
        "    })\n",
        "\n",
        "    # Specify the path for the CSV file\n",
        "    csv_file_path = os.path.join(results_path, f'{pipeline_name} metrics.csv')\n",
        "\n",
        "    # Save the DataFrame to a CSV file\n",
        "    metrics_df.to_csv(csv_file_path, index=False)\n",
        "\n",
        "\n",
        "    return metrics_df, mean_fpr, mean_tpr\n",
        "\n"
      ],
      "metadata": {
        "id": "XEV1aNXXkC-G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Smile Results: Train + Eval (5-Fold CV)"
      ],
      "metadata": {
        "id": "zmVhXeUbneQd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "of_metrics_df, of_mean_fpr, of_mean_tpr = train_and_evaluate(openface_smile, Final_Smile_Labels, pipeline_name='OpenFace', results_path=RESULTS_PATH_BASE + 'Smile/')\n",
        "print('OPENFACE: ')\n",
        "display(of_metrics_df)"
      ],
      "metadata": {
        "id": "vNO88rbBkGTW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ogau_metrics_df, ogau_mean_fpr, ogau_mean_tpr = train_and_evaluate(opengraphau_smile, Final_Smile_Labels, pipeline_name='OpenGraphAU', results_path=RESULTS_PATH_BASE + 'Smile/')\n",
        "print('OPENGRAPHAU: ')\n",
        "display(ogau_metrics_df)"
      ],
      "metadata": {
        "id": "JuiVMXa4kItE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "hse_metrics_df, hse_mean_fpr, hse_mean_tpr = train_and_evaluate(hsemotion_smile, Final_Smile_Labels, pipeline_name='HSEmotion', results_path=RESULTS_PATH_BASE + 'Smile/')\n",
        "print('HSEMOTION: ')\n",
        "display(hse_metrics_df)"
      ],
      "metadata": {
        "id": "EE2ULS8NmhY_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Smile Checking shuffled labels"
      ],
      "metadata": {
        "id": "fxrnpeIEvAcL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "s_of_metrics_df, s_of_mean_fpr, s_of_mean_tpr = train_and_evaluate(openface_smile, Shuffled_Smile_Labels, pipeline_name='Shuffled OpenFace', results_path=RESULTS_PATH_BASE + 'Smile/')\n",
        "print('OPENFACE SHUFFLED: ')\n",
        "display(s_of_metrics_df)"
      ],
      "metadata": {
        "id": "zCoJoNXrvESx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "s_ogau_metrics_df, s_ogau_mean_fpr, s_ogau_mean_tpr = train_and_evaluate(opengraphau_smile, Shuffled_Smile_Labels, pipeline_name='Shuffled OpenGraphAU', results_path=RESULTS_PATH_BASE + 'Smile/')\n",
        "print('OPENGRAPHAU SHUFFLED: ')\n",
        "display(s_ogau_metrics_df)"
      ],
      "metadata": {
        "id": "zgvBDcjQvEYE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "s_hse_metrics_df, s_hse_mean_fpr, s_hse_mean_tpr = train_and_evaluate(hsemotion_smile, Shuffled_Smile_Labels, pipeline_name='Shuffled HSEmotion', results_path=RESULTS_PATH_BASE + 'Smile/')\n",
        "print('HSEMOTION SHUFFLED: ')\n",
        "display(s_hse_metrics_df)"
      ],
      "metadata": {
        "id": "6LvfNe14vEaN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Yawn Results: Train + Eval (5-Fold CV)"
      ],
      "metadata": {
        "id": "tmyYDNpMLFQ7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "of_metrics_df, of_mean_fpr, of_mean_tpr = train_and_evaluate(openface_yawn, Final_Yawn_Labels, pipeline_name='OpenFace', results_path=RESULTS_PATH_BASE + 'Yawn/')\n",
        "print('OPENFACE: ')\n",
        "display(of_metrics_df)"
      ],
      "metadata": {
        "id": "NXU-RwXyLFRE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ogau_metrics_df, ogau_mean_fpr, ogau_mean_tpr = train_and_evaluate(opengraphau_yawn, Final_Yawn_Labels, pipeline_name='OpenGraphAU', results_path=RESULTS_PATH_BASE + 'Yawn/')\n",
        "print('OPENGRAPHAU: ')\n",
        "display(ogau_metrics_df)"
      ],
      "metadata": {
        "id": "9EE_6JcBLFRE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "hse_metrics_df, hse_mean_fpr, hse_mean_tpr = train_and_evaluate(hsemotion_yawn, Final_Yawn_Labels, pipeline_name='HSEmotion', results_path=RESULTS_PATH_BASE + 'Yawn/')\n",
        "print('HSEMOTION: ')\n",
        "display(hse_metrics_df)"
      ],
      "metadata": {
        "id": "fWMiTFsJLFRE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Yawn Checking shuffled labels"
      ],
      "metadata": {
        "id": "ppJdd12YLFRE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "s_of_metrics_df, s_of_mean_fpr, s_of_mean_tpr = train_and_evaluate(openface_yawn, Shuffled_Yawn_Labels, pipeline_name='Shuffled OpenFace', results_path=RESULTS_PATH_BASE + 'Yawn/')\n",
        "print('OPENFACE SHUFFLED: ')\n",
        "display(s_of_metrics_df)"
      ],
      "metadata": {
        "id": "3CIZI4TiLFRF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "s_ogau_metrics_df, s_ogau_mean_fpr, s_ogau_mean_tpr = train_and_evaluate(opengraphau_yawn, Shuffled_Yawn_Labels, pipeline_name='Shuffled OpenGraphAU', results_path=RESULTS_PATH_BASE + 'Yawn/')\n",
        "print('OPENGRAPHAU SHUFFLED: ')\n",
        "display(s_ogau_metrics_df)"
      ],
      "metadata": {
        "id": "CA41WG3OLFRF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "s_hse_metrics_df, s_hse_mean_fpr, s_hse_mean_tpr = train_and_evaluate(hsemotion_yawn, Shuffled_Yawn_Labels, pipeline_name='Shuffled HSEmotion', results_path=RESULTS_PATH_BASE + 'Yawn/')\n",
        "print('HSEMOTION SHUFFLED: ')\n",
        "display(s_hse_metrics_df)"
      ],
      "metadata": {
        "id": "EVtTnFFcLFRF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Discomfort Results: Train + Eval (5-Fold CV)"
      ],
      "metadata": {
        "id": "H6iAlq7kDllA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "of_metrics_df, of_mean_fpr, of_mean_tpr = train_and_evaluate(openface_discomfort, Final_Discomfort_Labels, pipeline_name='OpenFace', results_path=RESULTS_PATH_BASE + 'Discomfort/')\n",
        "print('OPENFACE: ')\n",
        "display(of_metrics_df)"
      ],
      "metadata": {
        "id": "e9hXxu7PDllI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ogau_metrics_df, ogau_mean_fpr, ogau_mean_tpr = train_and_evaluate(opengraphau_discomfort, Final_Discomfort_Labels, pipeline_name='OpenGraphAU', results_path=RESULTS_PATH_BASE + 'Discomfort/')\n",
        "print('OPENGRAPHAU: ')\n",
        "display(ogau_metrics_df)"
      ],
      "metadata": {
        "id": "HdiSirIfDllI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "hse_metrics_df, hse_mean_fpr, hse_mean_tpr = train_and_evaluate(hsemotion_discomfort, Final_Discomfort_Labels, pipeline_name='HSEmotion', results_path=RESULTS_PATH_BASE + 'Discomfort/')\n",
        "print('HSEMOTION: ')\n",
        "display(hse_metrics_df)"
      ],
      "metadata": {
        "id": "gDldawZ6DllJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Discomfort Checking shuffled labels"
      ],
      "metadata": {
        "id": "kATmbM88DllJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "s_of_metrics_df, s_of_mean_fpr, s_of_mean_tpr = train_and_evaluate(openface_discomfort, Shuffled_Discomfort_Labels, pipeline_name='Shuffled OpenFace', results_path=RESULTS_PATH_BASE + 'Discomfort/')\n",
        "print('OPENFACE SHUFFLED: ')\n",
        "display(s_of_metrics_df)"
      ],
      "metadata": {
        "id": "qtp25XrADllJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "s_ogau_metrics_df, s_ogau_mean_fpr, s_ogau_mean_tpr = train_and_evaluate(opengraphau_discomfort, Shuffled_Discomfort_Labels, pipeline_name='Shuffled OpenGraphAU', results_path=RESULTS_PATH_BASE + 'Discomfort/')\n",
        "print('OPENGRAPHAU SHUFFLED: ')\n",
        "display(s_ogau_metrics_df)"
      ],
      "metadata": {
        "id": "5CuNgv_-DllJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "s_hse_metrics_df, s_hse_mean_fpr, s_hse_mean_tpr = train_and_evaluate(hsemotion_discomfort, Shuffled_Discomfort_Labels, pipeline_name='Shuffled HSEmotion', results_path=RESULTS_PATH_BASE + 'Discomfort/')\n",
        "print('HSEMOTION SHUFFLED: ')\n",
        "display(s_hse_metrics_df)"
      ],
      "metadata": {
        "id": "zyTcX6qrDllJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Sad Results: Train + Eval (5-Fold CV)"
      ],
      "metadata": {
        "id": "nXss5kzANd5b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "of_metrics_df, of_mean_fpr, of_mean_tpr = train_and_evaluate(openface_sad, Final_Sad_Labels, pipeline_name='OpenFace', results_path=RESULTS_PATH_BASE + 'Sad/')\n",
        "print('OPENFACE: ')\n",
        "display(of_metrics_df)"
      ],
      "metadata": {
        "id": "HcrVOsk1Nd5n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ogau_metrics_df, ogau_mean_fpr, ogau_mean_tpr = train_and_evaluate(opengraphau_sad, Final_Sad_Labels, pipeline_name='OpenGraphAU', results_path=RESULTS_PATH_BASE + 'Sad/')\n",
        "print('OPENGRAPHAU: ')\n",
        "display(ogau_metrics_df)"
      ],
      "metadata": {
        "id": "Xnp2LEpvNd5o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "hse_metrics_df, hse_mean_fpr, hse_mean_tpr = train_and_evaluate(hsemotion_sad, Final_Sad_Labels, pipeline_name='HSEmotion', results_path=RESULTS_PATH_BASE + 'Sad/')\n",
        "print('HSEMOTION: ')\n",
        "display(hse_metrics_df)"
      ],
      "metadata": {
        "id": "p6oM_AGWNd5o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Sad Checking shuffled labels"
      ],
      "metadata": {
        "id": "TV6bRuHgNd5o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "s_of_metrics_df, s_of_mean_fpr, s_of_mean_tpr = train_and_evaluate(openface_sad, Shuffled_Sad_Labels, pipeline_name='Shuffled OpenFace', results_path=RESULTS_PATH_BASE + 'Sad/')\n",
        "print('OPENFACE SHUFFLED: ')\n",
        "display(s_of_metrics_df)"
      ],
      "metadata": {
        "id": "-QdQwBuCNd5o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "s_ogau_metrics_df, s_ogau_mean_fpr, s_ogau_mean_tpr = train_and_evaluate(opengraphau_sad, Shuffled_Sad_Labels, pipeline_name='Shuffled OpenGraphAU', results_path=RESULTS_PATH_BASE + 'Sad/')\n",
        "print('OPENGRAPHAU SHUFFLED: ')\n",
        "display(s_ogau_metrics_df)"
      ],
      "metadata": {
        "id": "KHnhUMl7Nd5p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "s_hse_metrics_df, s_hse_mean_fpr, s_hse_mean_tpr = train_and_evaluate(hsemotion_sad, Shuffled_Sad_Labels, pipeline_name='Shuffled HSEmotion', results_path=RESULTS_PATH_BASE + 'Sad/')\n",
        "print('HSEMOTION SHUFFLED: ')\n",
        "display(s_hse_metrics_df)"
      ],
      "metadata": {
        "id": "XNyShjKENd5p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# OLD Simple Mapping (Smile, Yawn, etc.)"
      ],
      "metadata": {
        "id": "Z_flcA2k7IYS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Prep"
      ],
      "metadata": {
        "id": "Hzfci6LDhIIF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def only_successful_frames(df):\n",
        "    # get frames where AU/emotion detection was successful!\n",
        "    return df[df['success'] == 1]\n",
        "\n",
        "\n",
        "def preprocess_df_radius_dict(df_radius_dict, columns_to_keep):\n",
        "  # Takes only successful frames\n",
        "  # Chooses specific columns from each df to keep\n",
        "\n",
        "  new_radius_dict = {}\n",
        "  for key1, one_time_df in df_radius_dict.items():\n",
        "    success_df = only_successful_frames(one_time_df)\n",
        "    new_radius_dict[key1] = success_df.loc[:, columns_to_keep]\n",
        "\n",
        "  return new_radius_dict"
      ],
      "metadata": {
        "id": "aBIpg32v7M49"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "openface_radius_dict = openface_radius_dict['0.01666']\n",
        "hsemotion_radius_dict = hsemotion_radius_dict['0.01666']\n",
        "opengraphau_radius_dict = opengraphau_radius_dict['0.01666']\n"
      ],
      "metadata": {
        "id": "1DXGuZpj7M7k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "def rule_mean_raw(outputs_dict, column):\n",
        "  # Creates a pandas df with two columns\n",
        "  # Datetime and EventDetected (probability)\n",
        "  # Based on the rule: mean(column)\n",
        "\n",
        "  rows = []\n",
        "  for key_time, value_df in outputs_dict.items():\n",
        "    if value_df.empty:\n",
        "      rows.append(\n",
        "          {'Datetime': key_time,\n",
        "         'EventDetected': 0}\n",
        "      )\n",
        "    else:\n",
        "      calculated_value = value_df.loc[:, column].mean(axis=0)\n",
        "\n",
        "      rows.append(\n",
        "          {'Datetime': key_time,\n",
        "          'EventDetected': calculated_value}\n",
        "      )\n",
        "\n",
        "  return pd.DataFrame(rows)\n",
        "\n",
        "\n",
        "def rule_mean_add(outputs_dict, columns_to_add, threshold, leq=False):\n",
        "  # Creates a pandas df with two columns\n",
        "  # Datetime and EventDetected\n",
        "  # Based on the rule: mean(sum(columns_to_add)) >= threshold\n",
        "  # If leq (less than or equal to): flip the rule. <= threshold\n",
        "\n",
        "  rows = []\n",
        "  for key_time, value_df in outputs_dict.items():\n",
        "    if value_df.empty:\n",
        "      rows.append(\n",
        "          {'Datetime': key_time,\n",
        "         'EventDetected': 0}\n",
        "      )\n",
        "    else:\n",
        "      calculated_value = value_df.loc[:, columns_to_add].sum(axis=1).mean(axis=0)\n",
        "\n",
        "      if leq:\n",
        "        event_det = int(calculated_value <= threshold)\n",
        "      else:\n",
        "        event_det = int(calculated_value >= threshold)\n",
        "\n",
        "      rows.append(\n",
        "          {'Datetime': key_time,\n",
        "          'EventDetected': event_det}\n",
        "      )\n",
        "\n",
        "  return pd.DataFrame(rows)\n",
        "\n",
        "from sklearn.metrics import roc_auc_score, confusion_matrix, roc_curve\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def calculate_metrics(preds, labels, plot_roc=False, title='Receiver Operating Characteristic Curve'):\n",
        "    \"\"\"\n",
        "    Calculates AUROC, sensitivity and specificity given predictions and labels as Pandas DataFrames.\n",
        "    Optionally, it can plot the ROC curve.\n",
        "\n",
        "    Args:\n",
        "        preds (pd.DataFrame): DataFrame containing predicted values (0 or 1).\n",
        "        labels (pd.DataFrame): DataFrame containing true labels (0 or 1).\n",
        "        plot_roc (bool): Whether to plot the ROC curve.\n",
        "\n",
        "    Returns:\n",
        "        auroc (float): AUROC value.\n",
        "        sensitivity (float): Sensitivity value.\n",
        "        specificity (float): Specificity value.\n",
        "    \"\"\"\n",
        "    preds = np.array(preds['EventDetected']).astype(int)\n",
        "    labels = np.array(labels['EventDetected']).astype(int)\n",
        "\n",
        "    auroc = roc_auc_score(labels, preds)\n",
        "\n",
        "    # Calculate the confusion matrix\n",
        "    conf_matrix = confusion_matrix(labels, preds)\n",
        "\n",
        "    # Unpack the confusion matrix values\n",
        "    tn, fp, fn, tp = conf_matrix.ravel()\n",
        "    sensitivity = tp / (tp + fn)\n",
        "    specificity = tn / (tn + fp)\n",
        "\n",
        "    fpr, tpr, thresholds = roc_curve(labels, preds)\n",
        "\n",
        "    best_threshold_index = np.argmax(tpr - fpr)\n",
        "\n",
        "    best_threshold = thresholds[best_threshold_index]\n",
        "\n",
        "    if plot_roc:\n",
        "\n",
        "        plt.figure()\n",
        "        plt.plot(fpr, tpr, label='ROC curve (area = %0.2f)' % auroc)\n",
        "        plt.plot([0, 1], [0, 1], 'k--')\n",
        "        plt.xlim([0.0, 1.0])\n",
        "        plt.ylim([0.0, 1.05])\n",
        "        plt.xlabel('False Positive Rate')\n",
        "        plt.ylabel('True Positive Rate')\n",
        "        plt.title(title)\n",
        "        plt.legend(loc=\"lower right\")\n",
        "        plt.show()\n",
        "\n",
        "    return auroc, sensitivity, specificity, best_threshold\n",
        "\n",
        "def calculate_auroc(preds, labels):\n",
        "    \"\"\"\n",
        "    Calculates AUROC (Area Under the Receiver Operating Characteristic Curve)\n",
        "    given predictions and labels as Pandas DataFrames.\n",
        "\n",
        "    Args:\n",
        "        preds (pd.DataFrame): DataFrame containing predicted values (0 or 1).\n",
        "        labels (pd.DataFrame): DataFrame containing true labels (0 or 1).\n",
        "\n",
        "    Returns:\n",
        "        float: AUROC value.\n",
        "    \"\"\"\n",
        "    preds = np.array(preds['EventDetected']).astype(int)\n",
        "    labels = np.array(labels['EventDetected']).astype(int)\n",
        "    auroc = roc_auc_score(labels, preds)\n",
        "    return auroc"
      ],
      "metadata": {
        "id": "lMTZO1dmH8hZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_predicted_prob_histograms(labels_df, predicted_probs_df):\n",
        "    # Filter predicted probabilities where labels_df has EventDetected = 0\n",
        "    event_detected_0_probs = predicted_probs_df[labels_df['EventDetected'] == 0]['EventDetected']\n",
        "\n",
        "    # Filter predicted probabilities where labels_df has EventDetected = 1\n",
        "    event_detected_1_probs = predicted_probs_df[labels_df['EventDetected'] == 1]['EventDetected']\n",
        "\n",
        "    # Plot histogram for EventDetected = 0\n",
        "    plt.hist(event_detected_0_probs, bins=20, alpha=0.5, label='True EventDetected = 0')\n",
        "    plt.xlabel('Predicted Probability')\n",
        "    plt.ylabel('Frequency')\n",
        "    plt.title('Distribution of Predicted Probabilities for True EventDetected = 0')\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "\n",
        "    # Plot histogram for EventDetected = 1\n",
        "    plt.hist(event_detected_1_probs, bins=20, alpha=0.5, label='True EventDetected = 1')\n",
        "    plt.xlabel('Predicted Probability')\n",
        "    plt.ylabel('Frequency')\n",
        "    plt.title('Distribution of Predicted Probabilities for True EventDetected = 1')\n",
        "    plt.legend()\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "cKQgHZsZf7dc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_sensitivity_specificity(thresholds, sensitivity_values, specificity_values):\n",
        "    if len(thresholds) != len(sensitivity_values) or len(thresholds) != len(specificity_values):\n",
        "        raise ValueError(\"The lengths of the input lists must be the same.\")\n",
        "\n",
        "    # Create a figure and axis object\n",
        "    fig, ax = plt.subplots()\n",
        "\n",
        "    # Plot sensitivity values as a blue line\n",
        "    ax.plot(thresholds, sensitivity_values, label='Sensitivity', color='blue')\n",
        "\n",
        "    # Plot specificity values as a green line\n",
        "    ax.plot(thresholds, specificity_values, label='Specificity', color='green')\n",
        "\n",
        "    # Set labels and title\n",
        "    ax.set_xlabel('Threshold')\n",
        "    ax.set_ylabel('Value')\n",
        "    ax.set_title('Sensitivity and Specificity')\n",
        "\n",
        "    # Show the legend\n",
        "    ax.legend()\n",
        "\n",
        "    # Display the plot\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "def and_or_operation(df1, df2, operation='AND'):\n",
        "    if not isinstance(df1, pd.DataFrame) or not isinstance(df2, pd.DataFrame):\n",
        "        raise ValueError(\"Both inputs must be pandas DataFrames.\")\n",
        "\n",
        "    if 'EventDetected' not in df1.columns or 'EventDetected' not in df2.columns:\n",
        "        raise ValueError(\"Both DataFrames must have an 'EventDetected' column.\")\n",
        "\n",
        "    if df1.shape != df2.shape:\n",
        "        raise ValueError(\"Both DataFrames must have the same shape.\")\n",
        "\n",
        "    result_df = df1.copy()\n",
        "\n",
        "    if operation == 'AND':\n",
        "        result_df['EventDetected'] = df1['EventDetected'] & df2['EventDetected']\n",
        "    elif operation == 'OR':\n",
        "        result_df['EventDetected'] = df1['EventDetected'] | df2['EventDetected']\n",
        "    else:\n",
        "        raise ValueError(\"Invalid operation. Please use 'AND' or 'OR'.\")\n",
        "\n",
        "    return result_df"
      ],
      "metadata": {
        "id": "u1DPIusMjY3-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def shuffle_labels(df):\n",
        "    \"\"\"\n",
        "    Takes in a DataFrame, makes a copy of it, and randomly shuffles the 'EventDetected' labels.\n",
        "\n",
        "    Args:\n",
        "        df (pd.DataFrame): DataFrame containing 'EventDetected' column.\n",
        "\n",
        "    Returns:\n",
        "        shuffled_df (pd.DataFrame): A copy of the original DataFrame with shuffled 'EventDetected' column.\n",
        "    \"\"\"\n",
        "    shuffled_df = df.copy()\n",
        "    shuffled_df['EventDetected'] = df['EventDetected'].sample(frac=1, random_state=42).reset_index(drop=True)\n",
        "    return shuffled_df"
      ],
      "metadata": {
        "id": "VzSNo0ZRkHON"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "openface_smile = preprocess_df_radius_dict(openface_radius_dict, ['AU06_r', 'AU07_r', 'AU10_r', 'AU12_r', 'AU14_r', 'AU25_r', 'AU06_c', 'AU07_c', 'AU10_c', 'AU12_c', 'AU14_c', 'AU25_c'])\n",
        "opengraphau_smile = preprocess_df_radius_dict(opengraphau_radius_dict, ['AU6', 'AU7', 'AU10', 'AU12', 'AU14', 'AU25'])\n",
        "hsemotion_smile = preprocess_df_radius_dict(hsemotion_radius_dict, ['Happiness'])"
      ],
      "metadata": {
        "id": "le9zOcGD7M-S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "\n",
        "random.choice(list(openface_smile.values()))"
      ],
      "metadata": {
        "id": "wXImvz1DHEjX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "of_columns = ['AU01_r', 'AU02_r', 'AU04_r', 'AU05_r',\n",
        "       'AU06_r', 'AU07_r', 'AU09_r', 'AU10_r', 'AU12_r', 'AU14_r', 'AU15_r',\n",
        "       'AU17_r', 'AU20_r', 'AU23_r', 'AU25_r', 'AU26_r', 'AU45_r', 'AU01_c',\n",
        "       'AU02_c', 'AU04_c', 'AU05_c', 'AU06_c', 'AU07_c', 'AU09_c', 'AU10_c',\n",
        "       'AU12_c', 'AU14_c', 'AU15_c', 'AU17_c', 'AU20_c', 'AU23_c', 'AU25_c',\n",
        "       'AU26_c', 'AU45_c']\n",
        "\n",
        "og_columns = ['AU1', 'AU2', 'AU4', 'AU5', 'AU6', 'AU7', 'AU9',\n",
        "       'AU10', 'AU11', 'AU12', 'AU13', 'AU14', 'AU15', 'AU16', 'AU17', 'AU18',\n",
        "       'AU19', 'AU20', 'AU22', 'AU23', 'AU24', 'AU25', 'AU26', 'AU27', 'AU32',\n",
        "       'AU38', 'AU39']\n",
        "\n",
        "hse_columns = ['Anger', 'Disgust', 'Fear', 'Happiness', 'Neutral', 'Sadness', 'Surprise']"
      ],
      "metadata": {
        "id": "-MCeACB00GMV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_AU_avg_df(aunames, au_without_event, au_with_event):\n",
        "    if len(aunames) != len(au_without_event) or len(aunames) != len(au_with_event):\n",
        "        raise ValueError(\"All lists must have the same length.\")\n",
        "\n",
        "    data = {\n",
        "        'Feature Name': aunames,\n",
        "        'Value without Event': au_without_event,\n",
        "        'Value with Event': au_with_event\n",
        "    }\n",
        "\n",
        "    df = pd.DataFrame(data)\n",
        "    return df\n",
        "\n",
        "\n",
        "def average_values_for_event(df, inner_df_dict, columns_of_interest):\n",
        "    # df -- has event detected for each timestamp\n",
        "    # inner_df_dict -- dictionary mapping each timestamp to a df with pipeline data\n",
        "    # columns_of_interest -- list with the columns we care about\n",
        "\n",
        "    # Filter the main DataFrame for EventDetected = 0 and 1\n",
        "    event_detected_0 = df[df['EventDetected'] == 0]['Datetime'].values\n",
        "    event_detected_1 = df[df['EventDetected'] == 1]['Datetime'].values\n",
        "\n",
        "    # Initialize lists to store average values for EventDetected = 0 and 1\n",
        "    avg_values_event_0 = [0] * len(columns_of_interest)\n",
        "    avg_values_event_1 = [0] * len(columns_of_interest)\n",
        "\n",
        "    # Process inner DataFrames for each timestamp\n",
        "    for timestamp, inner_df in inner_df_dict.items():\n",
        "        if timestamp in df['Datetime'].values:  # Check if the timestamp exists in the main DataFrame\n",
        "            for enum, column in enumerate(columns_of_interest):\n",
        "                num_now = inner_df[column].mean()\n",
        "                if not(np.isnan(num_now)):\n",
        "                  if timestamp in event_detected_0:\n",
        "                    avg_values_event_0[enum] += num_now\n",
        "                  else:\n",
        "                    avg_values_event_1[enum] += num_now\n",
        "\n",
        "\n",
        "\n",
        "    # Calculate the final average values for EventDetected = 0 and 1 by dividing with the total count\n",
        "    total_count_event_0 = len(event_detected_0)\n",
        "    total_count_event_1 = len(event_detected_1)\n",
        "\n",
        "    avg_values_event_0 = [i/total_count_event_0 for i in avg_values_event_0]\n",
        "    avg_values_event_1 = [i/total_count_event_1 for i in avg_values_event_1]\n",
        "\n",
        "    df_now = create_AU_avg_df(columns_of_interest, avg_values_event_0, avg_values_event_1)\n",
        "\n",
        "    return df_now\n"
      ],
      "metadata": {
        "id": "SWo8WaHo3FpI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "average_values_for_event(Final_Smile_Labels, opengraphau_smile, ['AU6', 'AU7', 'AU10', 'AU12', 'AU14', 'AU25'])"
      ],
      "metadata": {
        "id": "VTg8fyK34j_R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "average_values_for_event(Final_Smile_Labels, openface_smile, ['AU06_r', 'AU07_r', 'AU10_r', 'AU12_r', 'AU14_r', 'AU25_r', 'AU06_c', 'AU07_c', 'AU10_c', 'AU12_c', 'AU14_c', 'AU25_c'])"
      ],
      "metadata": {
        "id": "mUtIorDB57yR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Shuffled_Smile_Labels = shuffle_labels(Final_Smile_Labels)"
      ],
      "metadata": {
        "id": "2tJIyqEykIfC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "openface_yawn = preprocess_df_radius_dict(openface_radius_dict, ['AU26_r', 'AU26_c'])\n",
        "opengraphau_yawn = preprocess_df_radius_dict(opengraphau_radius_dict, ['AU26', 'AU27'])\n",
        "hsemotion_yawn = hsemotion_radius_dict"
      ],
      "metadata": {
        "id": "5ZCMoVk0xAEB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Shuffled_Yawn_Labels = shuffle_labels(Final_Yawn_Labels)"
      ],
      "metadata": {
        "id": "mqMBz5I5xAHv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "average_values_for_event(Final_Yawn_Labels, opengraphau_radius_dict, og_columns)"
      ],
      "metadata": {
        "id": "e-hzVHfnxAL-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "average_values_for_event(Final_Yawn_Labels, openface_radius_dict, [i for i in of_columns if i.endswith('_c')])"
      ],
      "metadata": {
        "id": "QV6VVutXS6nK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "average_values_for_event(Final_Yawn_Labels, hsemotion_radius_dict, hse_columns)"
      ],
      "metadata": {
        "id": "I7-enO6RUEo8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## OpenFace - Smile"
      ],
      "metadata": {
        "id": "5SCTCypshLxa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "for one_au_now in ['AU06_c', 'AU07_c', 'AU10_c', 'AU12_c', 'AU14_c', 'AU25_c']:\n",
        "  if '10' in one_au_now:\n",
        "    # We want to AVOID AU10 for smile\n",
        "    leq = True\n",
        "  else:\n",
        "    leq = False\n",
        "  of_smile_raw = rule_mean_raw(openface_smile, one_au_now)\n",
        "  auroc_now, _, _, best_threshold = calculate_metrics(of_smile_raw, Final_Smile_Labels, plot_roc=True, title=f'OF Smile: {one_au_now} Only')\n",
        "  print(f'OF Using {one_au_now} Only, AUROC = {auroc_now:.3f}')\n",
        "  print(f'Best threshold is {best_threshold:.3f}')\n",
        "\n",
        "  for threshold in [0, 0.2, 0.4, 0.6, 0.8, 1]:\n",
        "    of_smile = rule_mean_add(openface_smile, [one_au_now], threshold, leq=leq)\n",
        "    _, sens_of_smile, spec_of_smile, _ = calculate_metrics(of_smile, Final_Smile_Labels)\n",
        "    print(f'OF Using {one_au_now} Only, Threshold={threshold:.3f}: Sens={sens_of_smile:.3f}, Spec={spec_of_smile:.3f}')\n",
        "\n"
      ],
      "metadata": {
        "id": "7vGH_agYeQQj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Histogram\n",
        "\n",
        "of_smile_raw = rule_mean_raw(openface_smile, 'AU06_c')\n",
        "plot_predicted_prob_histograms(Final_Smile_Labels, of_smile_raw)"
      ],
      "metadata": {
        "id": "VAoggVaUf1q5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "for one_au_now in ['AU06_r', 'AU07_r', 'AU10_r', 'AU12_r', 'AU14_r', 'AU25_r']:\n",
        "  if '10' in one_au_now:\n",
        "    # We want to AVOID AU10 for smile\n",
        "    leq = True\n",
        "  else:\n",
        "    leq = False\n",
        "  of_smile_raw = rule_mean_raw(openface_smile, one_au_now)\n",
        "  of_smile_raw['EventDetected'] = of_smile_raw['EventDetected'] / 5 # Scale down to 0 to 1\n",
        "  auroc_now, _, _, best_threshold = calculate_metrics(of_smile_raw, Final_Smile_Labels, plot_roc=True, title=f'OF Smile: {one_au_now} Only')\n",
        "  print(f'OF Using {one_au_now} Only, AUROC = {auroc_now:.3f}')\n",
        "  print(f'Best threshold is {best_threshold:.3f}')\n",
        "\n",
        "  for threshold in np.linspace(0, 1, 6):\n",
        "    of_smile = rule_mean_add(openface_smile, [one_au_now], threshold, leq=leq)\n",
        "    _, sens_of_smile, spec_of_smile, _ = calculate_metrics(of_smile, Final_Smile_Labels)\n",
        "    print(f'OF Using {one_au_now} Only, Threshold={threshold:.3f}: Sens={sens_of_smile:.3f}, Spec={spec_of_smile:.3f}')\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "cIEIzemLfs-3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "for two_aus_now in [['AU06_c', 'AU12_c'],\n",
        "                    ['AU06_c', 'AU14_c'],\n",
        "                    ['AU12_c', 'AU14_c']]:\n",
        "\n",
        "  raw_dfs = []\n",
        "  for one_au_now in two_aus_now:\n",
        "    of_smile_raw = rule_mean_raw(openface_smile, one_au_now)\n",
        "    raw_dfs.append(of_smile_raw)\n",
        "\n",
        "  for threshold1 in np.linspace(0, 1, 6):\n",
        "    for threshold2 in np.linspace(0, 1, 6):\n",
        "      df_thresholded_1 = rule_mean_add(openface_smile, [two_aus_now[0]], threshold1)\n",
        "      df_thresholded_2 = rule_mean_add(openface_smile, [two_aus_now[1]], threshold2)\n",
        "      of_smile_and = and_or_operation(df_thresholded_1, df_thresholded_2, operation='AND')\n",
        "      _, sens_of_smile, spec_of_smile, _ = calculate_metrics(of_smile_and, Final_Smile_Labels)\n",
        "      print(f'OF Using {two_aus_now[0]} >= {threshold1:.3f} AND {two_aus_now[1]} >= {threshold2:.3f}: Sens={sens_of_smile:.3f}, Spec={spec_of_smile:.3f}')\n",
        "\n",
        "      of_smile_or = and_or_operation(df_thresholded_1, df_thresholded_2, operation='OR')\n",
        "      _, sens_of_smile, spec_of_smile, _ = calculate_metrics(of_smile_or, Final_Smile_Labels)\n",
        "      print(f'OF Using {two_aus_now[0]} >= {threshold1:.3f} OR {two_aus_now[1]} >= {threshold2:.3f}: Sens={sens_of_smile:.3f}, Spec={spec_of_smile:.3f}')\n"
      ],
      "metadata": {
        "id": "q5qK6bqbmK9f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## OpenGraphAU - Smile"
      ],
      "metadata": {
        "id": "vN9_NBVXhgB9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for one_au_now in ['AU6', 'AU7', 'AU10', 'AU12', 'AU14', 'AU25']:\n",
        "  if '10' in one_au_now:\n",
        "    # We want to AVOID AU10 for smile\n",
        "    leq = True\n",
        "  else:\n",
        "    leq = False\n",
        "  og_smile_raw = rule_mean_raw(opengraphau_smile, one_au_now)\n",
        "  auroc_now, _, _, best_threshold = calculate_metrics(og_smile_raw, Final_Smile_Labels, plot_roc=True, title=f'OGAU Smile: {one_au_now} Only')\n",
        "  print(f'OG Using {one_au_now} Only, AUROC = {auroc_now:.3f}')\n",
        "  print(f'Best threshold is {best_threshold:.3f}')\n",
        "\n",
        "  for threshold in np.linspace(0, 1, 6):\n",
        "    og_smile = rule_mean_add(opengraphau_smile, [one_au_now], threshold, leq=leq)\n",
        "    _, sens_og_smile, spec_og_smile, _ = calculate_metrics(og_smile, Final_Smile_Labels)\n",
        "    print(f'OG Using {one_au_now} Only, Threshold={threshold:.3f}: Sens={sens_og_smile:.3f}, Spec={spec_og_smile:.3f}')\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "x43pJ_64hAc2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for one_au_now in ['AU6', 'AU7', 'AU10', 'AU12', 'AU14', 'AU25']:\n",
        "  if '10' in one_au_now:\n",
        "    # We want to AVOID AU10 for smile\n",
        "    leq = True\n",
        "  else:\n",
        "    leq = False\n",
        "  og_smile_raw = rule_mean_raw(opengraphau_smile, one_au_now)\n",
        "  auroc_now, _, _, best_threshold = calculate_metrics(og_smile_raw, Final_Smile_Labels, plot_roc=True, title=f'OGAU Smile: {one_au_now} Only')\n",
        "  print(f'OG Using {one_au_now} Only, AUROC = {auroc_now}')\n",
        "  print(f'Best threshold is {best_threshold:.3f}')\n",
        "\n",
        "  for threshold in np.linspace(0.4, 0.5, 40):\n",
        "    og_smile = rule_mean_add(opengraphau_smile, [one_au_now], threshold, leq=leq)\n",
        "    _, sens_og_smile, spec_og_smile, _ = calculate_metrics(og_smile, Final_Smile_Labels)\n",
        "    print(f'OG Using {one_au_now} Only, Threshold={threshold:.3f}: Sens={sens_og_smile:.3f}, Spec={spec_og_smile:.3f}')\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "PtRkt_7K-uE6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "for two_aus_now in [['AU6', 'AU7'],\n",
        "                    ['AU6', 'AU25'],\n",
        "                    ['AU7', 'AU25']]:\n",
        "\n",
        "  scaling_dict = {\n",
        "      'AU6': np.linspace(0.42, 0.48, 10),\n",
        "      'AU7': np.linspace(0.30, 0.36, 10),\n",
        "      'AU25': np.linspace(0.74, 0.80, 10)\n",
        "  }\n",
        "  raw_dfs = []\n",
        "  for one_au_now in two_aus_now:\n",
        "    og_smile_raw = rule_mean_raw(opengraphau_smile, one_au_now)\n",
        "    raw_dfs.append(og_smile_raw)\n",
        "\n",
        "  tuple_list = []\n",
        "  and_sums = []\n",
        "  or_sums = []\n",
        "\n",
        "  for threshold1 in scaling_dict[two_aus_now[0]]:\n",
        "    for threshold2 in scaling_dict[two_aus_now[1]]:\n",
        "      tuple_now = (threshold1, threshold2)\n",
        "      tuple_list.append(tuple_now)\n",
        "      df_thresholded_1 = rule_mean_add(opengraphau_smile, [two_aus_now[0]], threshold1)\n",
        "      df_thresholded_2 = rule_mean_add(opengraphau_smile, [two_aus_now[1]], threshold2)\n",
        "      og_smile_and = and_or_operation(df_thresholded_1, df_thresholded_2, operation='AND')\n",
        "      _, sens_og_smile, spec_og_smile, _ = calculate_metrics(og_smile_and, Final_Smile_Labels)\n",
        "      and_sums.append(sens_og_smile + spec_og_smile)\n",
        "      print(f'OG Using {two_aus_now[0]} >= {threshold1:.3f} AND {two_aus_now[1]} >= {threshold2:.3f}: Sens={sens_og_smile:.3f}, Spec={spec_og_smile:.3f}')\n",
        "\n",
        "      og_smile_or = and_or_operation(df_thresholded_1, df_thresholded_2, operation='OR')\n",
        "      _, sens_og_smile, spec_og_smile, _ = calculate_metrics(og_smile_or, Final_Smile_Labels)\n",
        "      or_sums.append(sens_og_smile + spec_og_smile)\n",
        "      print(f'OG Using {two_aus_now[0]} >= {threshold1:.3f} OR {two_aus_now[1]} >= {threshold2:.3f}: Sens={sens_og_smile:.3f}, Spec={spec_og_smile:.3f}')\n",
        "\n",
        "  print('-'*40)\n",
        "  print('-'*40)\n",
        "  best_tuple_and = tuple_list[and_sums.index(max(and_sums))]\n",
        "  print(f'OG Best Thresholds for {two_aus_now[0]} AND {two_aus_now[1]}: {best_tuple_and}')\n",
        "  best_tuple_or = tuple_list[or_sums.index(max(or_sums))]\n",
        "  print(f'OG Best Thresholds for {two_aus_now[0]} OR {two_aus_now[1]}: {best_tuple_or}')\n",
        "  print('-'*40)\n",
        "  print('-'*40)"
      ],
      "metadata": {
        "id": "1khNnTl4x10n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "dXz3YHeNhAj1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## HSE - Smile"
      ],
      "metadata": {
        "id": "doehm9Fois6e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "hse_smile_raw = rule_mean_raw(hsemotion_smile, 'Happiness')\n",
        "auroc_now, _, _, best_threshold = calculate_metrics(hse_smile_raw, Final_Smile_Labels, plot_roc=True, title=f'HSE Smile: Happiness Only')\n",
        "print(f'HSE Using Happiness Only, AUROC = {auroc_now}')\n",
        "print(f'Best threshold is {best_threshold}')\n",
        "\n",
        "threshold_list = []\n",
        "sens_list = []\n",
        "spec_list = []\n",
        "\n",
        "for threshold in np.linspace(0, 0.2, 40):\n",
        "    threshold_list.append(threshold)\n",
        "    hse_smile = rule_mean_add(hsemotion_smile, ['Happiness'], threshold)\n",
        "    _, sens_hse_smile, spec_hse_smile, _ = calculate_metrics(hse_smile, Final_Smile_Labels)\n",
        "    sens_list.append(sens_hse_smile)\n",
        "    spec_list.append(spec_hse_smile)\n",
        "    print(f'HSE Using Happiness Only, Threshold={threshold}: Sens={sens_hse_smile}, Spec={spec_hse_smile}')\n",
        "\n",
        "for threshold in np.linspace(0.3, 1, 8):\n",
        "    threshold_list.append(threshold)\n",
        "    hse_smile = rule_mean_add(hsemotion_smile, ['Happiness'], threshold)\n",
        "    _, sens_hse_smile, spec_hse_smile, _ = calculate_metrics(hse_smile, Final_Smile_Labels)\n",
        "    sens_list.append(sens_hse_smile)\n",
        "    spec_list.append(spec_hse_smile)\n",
        "    print(f'HSE Using Happiness Only, Threshold={threshold}: Sens={sens_hse_smile}, Spec={spec_hse_smile}')"
      ],
      "metadata": {
        "id": "JVJ6syjOhAm8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_sensitivity_specificity(threshold_list, sens_list, spec_list)"
      ],
      "metadata": {
        "id": "sUMEkgtpjd4L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## OpenFace - Yawn"
      ],
      "metadata": {
        "id": "gFsx7QdXwvhH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for threshold in np.arange(0, 1, 0.1):\n",
        "    of_yawn = rule_mean_add(openface_yawn, ['AU26_c'], threshold)\n",
        "    auroc_of_yawn, sens_of_yawn, spec_of_yawn = calculate_metrics(of_yawn, Final_Yawn_Labels)\n",
        "    print(f'OF Yawn Using AU26_c Only, Threshold={threshold}: AUROC = {auroc_of_yawn}, Sens={sens_of_yawn}, Spec={spec_of_yawn}')"
      ],
      "metadata": {
        "id": "DpHpuI5kwxxZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "best_threshold = 0.1\n",
        "title_now = f\"ROC: AU26_c only, {best_threshold}\"\n",
        "of_yawn = rule_mean_add(openface_yawn, ['AU26_c'], best_threshold)\n",
        "auroc_of_yawn, sens_of_yawn, spec_of_yawn = calculate_metrics(of_yawn, Final_Yawn_Labels, plot_roc=True, title=title_now)\n",
        "\n"
      ],
      "metadata": {
        "id": "erOvzdmozKYX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "best_threshold = 0.1\n",
        "title_now = f\"(Shuffled) ROC: AU26_c only, {best_threshold}\"\n",
        "of_yawn = rule_mean_add(openface_yawn, ['AU26_c'], best_threshold)\n",
        "auroc_of_yawn, sens_of_yawn, spec_of_yawn = calculate_metrics(of_yawn, Shuffled_Yawn_Labels, plot_roc=True, title=title_now)\n",
        "\n"
      ],
      "metadata": {
        "id": "xvrMEmbXzZvy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for threshold in np.arange(0, 5, 0.5):\n",
        "    of_yawn = rule_mean_add(openface_yawn, ['AU26_r'], threshold)\n",
        "    auroc_of_yawn, sens_of_yawn, spec_of_yawn = calculate_metrics(of_yawn, Final_Yawn_Labels)\n",
        "    print(f'OF Yawn Using AU26_r Only, Threshold={threshold}: AUROC = {auroc_of_yawn}, Sens={sens_of_yawn}, Spec={spec_of_yawn}')"
      ],
      "metadata": {
        "id": "vUmG0y0Nwx1c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "sD0xkN8Gwx5n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "C4JoGOYbzHCc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Old Code & Notes\n",
        "\n"
      ],
      "metadata": {
        "id": "4IfIp8A2ixwc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# OpenFace - c columns\n",
        "\n",
        "\n",
        "# Add a few more thresholds - 0.5 and 1.5\n",
        "\n",
        "# We want very high specificity. Based on best AUROC model,\n",
        "# find best threshold for specificity and then figure out sensitivity\n",
        "\n",
        "# Detected in all frames\n",
        "of_smile_6c = rule_mean_add(openface_smile, ['AU06_c'], 1)\n",
        "auroc_of_smile_6c = calculate_auroc(of_smile_6c, Final_Smile_Labels)\n",
        "print(f'OF Using AU06_c Only: AUROC = {auroc_of_smile_6c}')\n",
        "\n",
        "# Detected in all frames\n",
        "of_smile_12c = rule_mean_add(openface_smile, ['AU12_c'], 1)\n",
        "auroc_of_smile_12c = calculate_auroc(of_smile_12c, Final_Smile_Labels)\n",
        "print(f'OF Using AU12_c Only: AUROC = {auroc_of_smile_12c}')\n",
        "\n",
        "# 50% are 1s over the 5 frames\n",
        "of_smile_6c_or_12c = rule_mean_add(openface_smile, ['AU06_c', 'AU12_c'], 1)\n",
        "auroc_of_smile_6c_or_12c = calculate_auroc(of_smile_6c_or_12c, Final_Smile_Labels)\n",
        "print(f'OF Using AU12_c or AU06_c: AUROC = {auroc_of_smile_6c_or_12c}')\n",
        "\n",
        "# Both 1s for all 5 frames\n",
        "of_smile_6c_and_12c = rule_mean_add(openface_smile, ['AU06_c', 'AU12_c'], 2)\n",
        "auroc_of_smile_6c_and_12c = calculate_auroc(of_smile_6c_and_12c, Final_Smile_Labels)\n",
        "print(f'OF Using AU12_c and AU06_c: AUROC = {auroc_of_smile_6c_and_12c}')"
      ],
      "metadata": {
        "id": "16XUkc5pJ2hR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# OpenFace - r columns\n",
        "auroc_of_smile_6r_all = []\n",
        "for i in np.linspace(0, 5, 11):\n",
        "  of_smile_6r = rule_mean_add(openface_smile, ['AU06_r'], i)\n",
        "  auroc_of_smile_6r = calculate_auroc(of_smile_6r, Final_Smile_Labels)\n",
        "  auroc_of_smile_6r_all.append(auroc_of_smile_6r)\n",
        "  print(f'OF Using AU06_r Only, Threshold of {i}: AUROC = {auroc_of_smile_6r}')\n"
      ],
      "metadata": {
        "id": "PmOoecDCMNkg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# OpenFace - r columns\n",
        "auroc_of_smile_12r_all = []\n",
        "for i in np.linspace(0, 5, 11):\n",
        "  of_smile_12r = rule_mean_add(openface_smile, ['AU12_r'], i)\n",
        "  auroc_of_smile_12r = calculate_auroc(of_smile_12r, Final_Smile_Labels)\n",
        "  auroc_of_smile_12r_all.append(auroc_of_smile_12r)\n",
        "  print(f'OF Using AU12_r Only, Threshold of {i}: AUROC = {auroc_of_smile_12r}')\n"
      ],
      "metadata": {
        "id": "uBVporqFM3xU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# SMILE AU ANALYSIS:\n",
        "\n",
        "# We want the absence of AU10 for smile\n",
        "# Presence of AUs 6 and 12 is good\n",
        "# When looking at combos, just use AND (e.g. AU 6 > 0.8 AND AU 12 > 0.2)\n",
        "# AU7 is good\n",
        "# AU14 and AU25 are also good\n",
        "\n",
        "\n",
        "# Do all separately\n",
        "# 6 and 12 combined\n",
        "# Model with all\n",
        "\n",
        "\n",
        "\n",
        "# HSE: 0 : 0.1 : 1 for Happiness\n",
        "\n",
        "\n",
        "# Do a random permute of labels to make sure AUROC goes down\n",
        "\n",
        "\n",
        "# Distinguish between different types of smiles (intensity)\n",
        "\n"
      ],
      "metadata": {
        "id": "wN8F6at1NBKn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Final_Smile_Labels"
      ],
      "metadata": {
        "id": "Wy8Knz1vHpGd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "X5DcPbuwY1Jr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# YAWN\n",
        "\n",
        "# 26 and 27\n",
        "\n",
        "# HSE: Plot mean value of each of emotions for yawn vs. control - how does it classify yawn?\n",
        "\n"
      ],
      "metadata": {
        "id": "MGg-gz-dY1M9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Final_Yawn_Labels"
      ],
      "metadata": {
        "id": "JPWS13sta1zm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# DISCOMFORT\n",
        "\n"
      ],
      "metadata": {
        "id": "6PQZWd08bxB3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# SAD\n",
        "\n"
      ],
      "metadata": {
        "id": "GctTW4iLb17p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ykKwMzyALzsN"
      },
      "source": [
        "# Sanity Checks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2il6NAvZL31T"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "def calculate_success_percentage(df):\n",
        "    total_rows = len(df)\n",
        "    success_rows = len(df[df['success'] == 1])\n",
        "    success_percentage = (success_rows / total_rows) * 100\n",
        "    return success_percentage\n",
        "\n",
        "def plot_histogram_sp(df_dict, savepath, title_add):\n",
        "    # gives us mapping from timestamp --> success percentage\n",
        "    sp_dict = apply_function_to_dict(df_dict, calculate_success_percentage)\n",
        "    timestamps = list(sp_dict.keys())\n",
        "    percentages = list(sp_dict.values())\n",
        "\n",
        "    fig, ax = plt.subplots()\n",
        "\n",
        "    # Plot the histogram\n",
        "\n",
        "    ax.hist(percentages, bins=10)\n",
        "\n",
        "    # Set labels and title\n",
        "    ax.set_xlabel('Percentage')\n",
        "    ax.set_ylabel('Frequency')\n",
        "    ax.set_title('Histogram of Success Percentages' + title_add)\n",
        "\n",
        "    # Save the plot\n",
        "    plt.savefig(savepath, bbox_inches='tight')\n",
        "    plt.close(fig)\n",
        "\n",
        "def plot_line_sp(df_dict, savepath, title_add):\n",
        "    # gives us mapping from timestamp --> success percentage\n",
        "    sp_dict = apply_function_to_dict(df_dict, calculate_success_percentage)\n",
        "\n",
        "    timestamps = list(sp_dict.keys())\n",
        "    percentages = list(sp_dict.values())\n",
        "\n",
        "    fig, ax = plt.subplots()\n",
        "\n",
        "    # Plot the line graph\n",
        "    ax.plot(timestamps, percentages)\n",
        "\n",
        "    # Set labels and title\n",
        "    ax.set_xlabel('Time')\n",
        "    ax.set_ylabel('Success Percentage')\n",
        "    ax.set_title('Success Percentage Over Time' + title_add)\n",
        "\n",
        "    # Rotate x-axis labels for better readability\n",
        "    plt.xticks(rotation=45)\n",
        "\n",
        "    # Save the plot\n",
        "    plt.savefig(savepath, bbox_inches='tight')\n",
        "    plt.close(fig)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qxCBarQPMFr6"
      },
      "outputs": [],
      "source": [
        "for i in TIME_RADIUS_LIST:\n",
        "  title_now = f', Time Window = {i / 60} Hours'\n",
        "\n",
        "  plot_histogram_sp(openface_radius_dict[f'{i}'], RESULTS_PATH_BASE + f'report_window_sp_histogram_{i}.png', title_now)\n",
        "  plot_line_sp(openface_radius_dict[f'{i}'], RESULTS_PATH_BASE + f'report_window_sp_line_{i}.png', title_now)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def check_success_percentage(dfs_openface, dump_path, verbose=False):\n",
        "  unsuccessful_data_dict = {}\n",
        "  for key, df in dfs_openface.items():\n",
        "    unsuccess_percentage_saved = (df['success'] == 0).mean() * 100\n",
        "    real_unsuccess_percentage = 100 - ((df.shape[0] / 18004) * 100) # there are 18004 frames in the best video\n",
        "    if unsuccess_percentage_saved > 5:\n",
        "      if verbose:\n",
        "        print('UNSUCCESSFUL FILTERING: ', key)\n",
        "    if real_unsuccess_percentage > 80:\n",
        "      unsuccessful_data_dict[key] = real_unsuccess_percentage\n",
        "      if verbose:\n",
        "        print('UNSUCCESSFUL DATA: ', key, f'UNSUCCESSFUL = {real_unsuccess_percentage}%')\n",
        "\n",
        "  df = pd.DataFrame(unsuccessful_data_dict.items(), columns=['Filename', 'Percent Unsuccessful'])\n",
        "  df.to_excel(dump_path, index=False)\n",
        "\n",
        "  return unsuccessful_data_dict"
      ],
      "metadata": {
        "id": "RC9BY_6m2qr8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "of_unsuccess = check_success_percentage(dfs_openface, dump_path=f'{QC_PATH}/of_unsuccess.xlsx')"
      ],
      "metadata": {
        "id": "zqKFDQ9b2rc_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "list(of_unsuccess.keys())"
      ],
      "metadata": {
        "id": "49VsJ_Bf-U7T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "og_unsuccess = check_success_percentage(dfs_opengraphau, dump_path=f'{QC_PATH}/og_unsuccess.xlsx')"
      ],
      "metadata": {
        "id": "gd_gPaugzfS2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "hse_unsuccess = check_success_percentage(dfs_hsemotion, dump_path=f'{QC_PATH}/hse_unsuccess.xlsx')"
      ],
      "metadata": {
        "id": "RWg3EwYJ9F0F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "good_for_all = [x for x in list(dfs_openface.keys()) if x not in list(of_unsuccess.keys()) and x not in list(og_unsuccess.keys()) and x not in list(hse_unsuccess.keys())]\n",
        "good_for_all"
      ],
      "metadata": {
        "id": "sfqpnmiBzfbx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def sanity_detect_emotions_og(df, method, emo_AUs, threshold=0.3, additional_filter=None):\n",
        "    # INPUT:\n",
        "    # df -- dataframe with AUs for each frame\n",
        "    # method -- must be 'OpenGraphAU'\n",
        "    # emo_AUs -- the hash table\n",
        "    # additional_filter -- are we just doing lower half? upper half? This is None or a list of ints (which AUs to keep)\n",
        "    # threshold -- what is the threshold for yes/no we're using for OpenGraphAU?\n",
        "\n",
        "    # OUTPUT:\n",
        "    # 1 datafrme with emotion values for each frame\n",
        "    # emo_binary (see OpenDBM docs for details)\n",
        "\n",
        "\n",
        "    if df.empty:\n",
        "      return df\n",
        "    # We start by mapping AUs to emotions for each of our two methods\n",
        "    # Using this mapping: https://aicure.github.io/open_dbm/docs/emotional-expressivity\n",
        "\n",
        "\n",
        "    if method == 'OpenGraphAU':\n",
        "        columns = ['AU1', 'AU2', 'AU4', 'AU5', 'AU6', 'AU7', 'AU9',\n",
        "                   'AU10', 'AU11', 'AU12', 'AU13', 'AU14', 'AU15', 'AU16', 'AU17',\n",
        "                   'AU18', 'AU19', 'AU20', 'AU22', 'AU23', 'AU24', 'AU25', 'AU26', 'AU27', 'AU32',\n",
        "                   'AU38', 'AU39']\n",
        "\n",
        "        # add the classification columns!\n",
        "        columns = [item for sublist in [[col+'_r', col] for col in columns] for item in sublist]\n",
        "\n",
        "        # hash tables for presence and intensity\n",
        "        emo_AUs_presence = {}\n",
        "        for key in emo_AUs.keys():\n",
        "            new_values_c = []\n",
        "            for value in emo_AUs[key]:\n",
        "                if isinstance(value, int):\n",
        "                    AU_key_c = f\"AU{value}\"\n",
        "\n",
        "                    if AU_key_c in columns:\n",
        "                        if additional_filter is not None:\n",
        "                          if value in additional_filter:\n",
        "                            new_values_c.append(AU_key_c)\n",
        "                        else:\n",
        "                          new_values_c.append(AU_key_c)\n",
        "            if new_values_c:\n",
        "                emo_AUs_presence[key] = new_values_c\n",
        "\n",
        "    else:\n",
        "        # if the method specified is not OpenFace or OpenGraphAU, raise an error (pipeline doesn't support others yet)\n",
        "        raise ValueError(\"Invalid method parameter. Method must be 'OpenGraphAU'.\")\n",
        "\n",
        "    # Create an empty dictionary to store the emotion scores\n",
        "    emotion_scores_binary = {} # 1 or 0: are all AUs present?\n",
        "\n",
        "    # Compute emotion scores for each emotion\n",
        "    for emotion in emo_AUs_presence.keys():\n",
        "        # Get the relevant columns for presence\n",
        "        presence_cols = emo_AUs_presence[emotion]\n",
        "\n",
        "        # Compute the emotion score for each row in the dataframe\n",
        "        emotion_scores_binary[emotion] = df[presence_cols].gt(threshold).all(axis=1)\n",
        "        emotion_scores_binary[emotion] = emotion_scores_binary[emotion].fillna(0)\n",
        "\n",
        "    # Create a new dataframe with the emotion scores\n",
        "    emotion_df_binary = pd.DataFrame(emotion_scores_binary)\n",
        "    emotion_df_binary = emotion_df_binary.replace({False: 0, True: 1})\n",
        "\n",
        "    # Let's add timestamp and success on\n",
        "    columns_of_interest = ['timestamp', 'success']\n",
        "    df_temp = df[columns_of_interest]\n",
        "\n",
        "    # Concatenate the columns from df2 with df1\n",
        "    emotion_df_binary = pd.concat([df_temp, emotion_df_binary], axis=1)\n",
        "\n",
        "    return emotion_df_binary"
      ],
      "metadata": {
        "id": "utT5os2z_cfY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def convert_seconds_to_mmss(seconds):\n",
        "  minutes = int(seconds // 60)\n",
        "  seconds = int(seconds % 60)\n",
        "  return f'{minutes:02d}:{seconds:02d}'\n",
        "\n",
        "\n",
        "def sanity_check_find(one_filename, emotion_to_find, threshold_for_search, method):\n",
        "  # filename of video\n",
        "  # emotion (e.g. Happiness)\n",
        "  # threshold_for_search - e.g. if it's 0.6 and OpenFace, only timestamps where OpenFace says Happiness>0.6\n",
        "  # method - OpenFace, OpenGraphAU, or HSEmotion\n",
        "\n",
        "  if method == 'OpenFace':\n",
        "    one_df = detect_emotions(dfs_openface[one_filename], 'OpenFace', emo_AUs, additional_filter=None)[1]\n",
        "    filtered_df = one_df[(one_df[emotion_to_find] > threshold_for_search) & (one_df[emotion_to_find] == one_df[['Happiness', 'Sadness', 'Surprise', 'Fear', 'Anger', 'Disgust', 'Contempt']].max(axis=1))]\n",
        "  elif method == 'OpenGraphAU':\n",
        "    one_df = sanity_detect_emotions_og(dfs_opengraphau[one_filename], 'OpenGraphAU', emo_AUs)\n",
        "    filtered_df = one_df[(one_df[emotion_to_find] > threshold_for_search) & (one_df[emotion_to_find] == one_df[['Happiness', 'Sadness', 'Surprise', 'Fear', 'Anger', 'Disgust', 'Contempt']].max(axis=1))]\n",
        "  elif method == 'HSEmotion':\n",
        "    one_df = dfs_hsemotion[one_filename].copy()\n",
        "    filtered_df = one_df[(one_df[emotion_to_find] > threshold_for_search) & (one_df[emotion_to_find] == one_df[['Happiness', 'Sadness', 'Surprise', 'Fear', 'Anger', 'Disgust', 'Neutral']].max(axis=1))]\n",
        "  else:\n",
        "    print(\"ERROR! CHECK THE METHOD PARAMETER!!\")\n",
        "\n",
        "  # Apply the function to the 'timestamp' column\n",
        "  filtered_df['timestamp'] = filtered_df['timestamp'].apply(lambda x: convert_seconds_to_mmss(x))\n",
        "\n",
        "  return filtered_df"
      ],
      "metadata": {
        "id": "Xo4DNKQi_ccd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sanity_check_find('3332W300', 'Happiness', 0.4, method='OpenGraphAU')"
      ],
      "metadata": {
        "id": "RGyHRKUnIzNm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fLS17fOTDz17"
      },
      "source": [
        "# Feature Extraction - OpenDBM\n",
        "\n",
        "Having lots of trouble installing OpenDBM package on Colab. The main issue is the dependency deepspeech can't be installed. Tried installing deepspeech from github, but it seems to require another library that I can't install on colab\n",
        "\n",
        "When I install without dependencies, then manually install only those that are necessary, there are some conflicting version requirements.\n",
        "\n",
        "Tried forking repo and manually changing requirements to remove deepspeech. Installing from github seems to fail.\n",
        "\n",
        "Tried cloning repo here, adding its path via sys, and importing just feature extraction, but there seem to be no callable libraries there.\n",
        "\n",
        "Tried modifying setup and requirements in here after cloning repo, and it still didn't work. Pip says it's an issue with the package, but doens't give a useful error trace.\n",
        "\n",
        "Tried conda as well and it failed\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BRsYE1lfD3AY"
      },
      "outputs": [],
      "source": [
        "!pip install opendbm --no-deps"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LV4QOulKaOgs"
      },
      "outputs": [],
      "source": [
        "!pip install stopit"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J5zENq-javTY"
      },
      "outputs": [],
      "source": [
        "!pip install git+https://github.com/AiCure/open_dbm.git@master#egg=opendbm.dbm_lib"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2vltsupTdnEY"
      },
      "outputs": [],
      "source": [
        "!pip install git+https://github.com/JayRGopal/open_dbm.git@master"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8dalyjvFbGOF"
      },
      "outputs": [],
      "source": [
        "!pip install condacolab"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "To7z8r2ZbRYn"
      },
      "outputs": [],
      "source": [
        "!conda create -n myenv\n",
        "!conda activate myenv\n",
        "!conda install -c conda-forge cmake ffmpeg sox"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-lv1i3iYetJq"
      },
      "outputs": [],
      "source": [
        "!sudo apt-get install nano\n",
        "!nano ~/.bashrc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vyUWX0JJe40f"
      },
      "outputs": [],
      "source": [
        "!nano ~/.bashrc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tvt-T8hVclMV"
      },
      "outputs": [],
      "source": [
        "!pip install -v opendbm==0.0.1b6"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5fVH9B5cc5Wp"
      },
      "outputs": [],
      "source": [
        "!pip3 install opendbm==0.0.1b6 --no-deps=deepface"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9m_cH7yvhRfY"
      },
      "outputs": [],
      "source": [
        "!git clone https://github.com/AiCure/open_dbm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z5L3kQkihmD_"
      },
      "outputs": [],
      "source": [
        "%cd open_dbm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "775mV-dihrPC"
      },
      "outputs": [],
      "source": [
        "!pip install -r requirements.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o3qiHTuoi32D"
      },
      "outputs": [],
      "source": [
        "%cd /content/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nUL3wpJAiKOD"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "sys.path.append('/content/open_dbm/opendbm/')\n",
        "from dbm_lib import dbm_features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "otISeGY3ktFf"
      },
      "outputs": [],
      "source": [
        "import inspect\n",
        "\n",
        "module = __import__('dbm_lib.dbm_features.derived_features.derive')\n",
        "\n",
        "callable_methods = [\n",
        "  method for method in dir(module)\n",
        "  #if inspect.ismethod(getattr(module, method))\n",
        "]\n",
        "\n",
        "print(callable_methods)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nfu4VybLEzqp"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Create a dbm_features object.\n",
        "dbm_features = dbm_features()\n",
        "\n",
        "# Set the features that you want to extract.\n",
        "dbm_features.set_features(\n",
        "    [\n",
        "        \"action_units\",\n",
        "        \"emotional_expressivity\",\n",
        "        \"overall_expressivity\",\n",
        "    ]\n",
        ")\n",
        "\n",
        "# Pass the pandas df to the dbm_features object.\n",
        "dbm_features.fit(openface_radius[get_moodTracking_datetime(0)])\n",
        "\n",
        "# Call the extract_features() method.\n",
        "extracted_features = dbm_features.extract_features()\n",
        "\n",
        "# Get the extracted features.\n",
        "print(extracted_features)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d29KucDj8nhK"
      },
      "source": [
        "# Feature Extraction 1.0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0jeNfFA9Fo3z"
      },
      "source": [
        "## AU --> Emotion & Lower/Upper"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q6z8PGgWp5Bm"
      },
      "outputs": [],
      "source": [
        "# Define emotion to AU mapping\n",
        "\n",
        "# OpenDBM:\n",
        "emo_AUs = {'Happiness': [6, 12],\n",
        "           'Sadness': [1, 4, 15],\n",
        "           'Surprise': [1, 2, 5, 26],\n",
        "           'Fear': [1, 2, 4, 5, 7, 20, 26],\n",
        "           'Anger': [4, 5, 7, 23],\n",
        "           'Disgust': [9, 15, 16],\n",
        "           'Contempt': [12, 14]}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tVaChzOTx522"
      },
      "outputs": [],
      "source": [
        "# Define AU to lower/upper\n",
        "\n",
        "# OpenDBM:\n",
        "AU_lower = [12, 15, 26, 20, 23, 14]\n",
        "AU_upper = [6, 1, 4, 2, 5, 7, 9]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YnTMYRufFs6t"
      },
      "source": [
        "## Emotion Processing - HSEmotion"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ujhYO5vxCY8S"
      },
      "outputs": [],
      "source": [
        "def only_successful_frames(df):\n",
        "    # get frames where AU/emotion detection was successful!\n",
        "    return df[df['success'] == 1]\n",
        "\n",
        "def filter_max_emotion(df, threshold):\n",
        "\n",
        "    if df.empty:\n",
        "      return df\n",
        "\n",
        "    # create a copy of the input df\n",
        "    df_copy = df.copy()\n",
        "\n",
        "    # success\n",
        "    df_copy = only_successful_frames(df_copy)\n",
        "\n",
        "    # find the maximum emotion value for each frame\n",
        "    cols_to_check = [col for col in df_copy.columns if col not in ['success', 'timestamp']]\n",
        "    max_emotion = df_copy[cols_to_check].max(axis=1)\n",
        "\n",
        "    # set all non-max emotion values to 0 for each frame\n",
        "    for col in cols_to_check:\n",
        "      df_copy.loc[df_copy[col] < max_emotion, col] = 0\n",
        "\n",
        "    # filter for frames where max emotion is above threshold\n",
        "    df_filtered = df_copy[max_emotion > threshold]\n",
        "\n",
        "    return df_filtered\n",
        "\n",
        "def add_event_column(df, time_thresh, min_event_length):\n",
        "    \"\"\"\n",
        "    Adds an 'event' column to a dataframe, assigning an event ID to each frame based on the specified time threshold and\n",
        "    event length.\n",
        "\n",
        "    Args:\n",
        "        df (pandas DataFrame): A dataframe with video frames as rows and emotion features as columns. The dataframe\n",
        "            should have a 'timestamp' column containing timestamps for each frame.\n",
        "        time_thresh (int or float): The time threshold (in seconds) to use when defining events. Any two consecutive\n",
        "            frames with a time difference greater than this threshold will belong to different events.\n",
        "        min_event_length (int): The minimum length of an event. Events shorter than this length will be filtered out.\n",
        "\n",
        "    Returns:\n",
        "        pandas DataFrame: A new dataframe with an additional 'event' column, leaving the input dataframe unchanged.\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "    if df.empty:\n",
        "      return df\n",
        "\n",
        "    # Make a copy of the dataframe\n",
        "    df_copy = df.copy()\n",
        "\n",
        "    # Convert time threshold to Timedelta\n",
        "    time_thresh = pd.Timedelta(seconds=time_thresh)\n",
        "\n",
        "    # Sort the dataframe by timestamp\n",
        "    df_copy = df_copy.sort_values('timestamp')\n",
        "\n",
        "    # Compute the time difference between consecutive frames\n",
        "    time_diff = df_copy['timestamp'].diff()\n",
        "\n",
        "    # Initialize event ID and current event emotion\n",
        "    global event_id, current_emotion\n",
        "    event_id = 1\n",
        "    current_emotion = None\n",
        "\n",
        "    # Initialize the event column with zeros\n",
        "    df_copy['event'] = 0\n",
        "\n",
        "    # define emotion columns\n",
        "    emotion_cols = [col for col in df_copy.columns if col not in ['success', 'timestamp']]\n",
        "\n",
        "\n",
        "\n",
        "    def assign_event_id(row, emotion_cols):\n",
        "        global event_id, current_emotion\n",
        "\n",
        "        this_frame_emotion = emotion_cols[np.nanargmax(row[emotion_cols].values)]\n",
        "        if pd.isnull(current_emotion) or time_diff.loc[row.name] > time_thresh or this_frame_emotion != current_emotion:\n",
        "            event_id += 1\n",
        "            current_emotion = this_frame_emotion\n",
        "\n",
        "        return event_id\n",
        "\n",
        "    df_copy['event'] = df_copy.apply(lambda row: assign_event_id(row, emotion_cols), axis=1)\n",
        "\n",
        "    # Filter out events with length less than min_event_length\n",
        "    event_counts = df_copy['event'].value_counts()\n",
        "    short_events = event_counts[event_counts < min_event_length].index\n",
        "    df_copy = df_copy[~df_copy['event'].isin(short_events)]\n",
        "\n",
        "    # factorize event column\n",
        "    df_copy['event'] = pd.factorize(df_copy['event'])[0]\n",
        "\n",
        "    return df_copy\n",
        "\n",
        "def calculate_emotion_statistics(df):\n",
        "    \"\"\"\n",
        "    Calculates statistics for each emotion in a pandas DataFrame.\n",
        "\n",
        "    Args:\n",
        "        df (pandas DataFrame): The DataFrame containing emotion values and event information.\n",
        "\n",
        "    Returns:\n",
        "        pandas DataFrame: The DataFrame with statistics for each emotion.\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "    if df.empty:\n",
        "      return df\n",
        "\n",
        "    # List of emotions (assuming they are the columns in the dataframe)\n",
        "    emotions = [col for col in df.columns if col not in ['success', 'timestamp', 'event']]\n",
        "\n",
        "    # Initialize an empty dictionary to store the computed statistics\n",
        "    stats = {'emotion': [], 'num_events': [], 'avg_intensity': [], 'avg_event_length': [], 'avg_event_duration': [],\n",
        "             'std': [], 'skewness': [], 'kurtosis': [], 'autocorrelation': []}\n",
        "\n",
        "    for emotion in emotions:\n",
        "        # Filter the dataframe for rows with non-zero values for the current emotion\n",
        "        filtered_df = df[df[emotion] != 0]\n",
        "\n",
        "        # Calculate the statistics for the emotion\n",
        "        num_events = filtered_df['event'].nunique()\n",
        "        avg_intensity = filtered_df[emotion].mean()\n",
        "        avg_event_length = filtered_df.groupby('event', group_keys=True).size().mean()\n",
        "        avg_event_duration = filtered_df.groupby('event', group_keys=True)['timestamp'].apply(lambda x: (x.max() - x.min()).total_seconds()).mean()\n",
        "\n",
        "        # Additional features\n",
        "        std = filtered_df[emotion].std()\n",
        "        skewness = filtered_df[emotion].skew()\n",
        "        kurtosis = filtered_df[emotion].kurtosis()\n",
        "        autocorrelation = np.corrcoef(filtered_df[emotion][:-1], filtered_df[emotion][1:])[0, 1]\n",
        "\n",
        "        # Add the statistics to the dictionary\n",
        "        stats['emotion'].append(emotion)\n",
        "        stats['num_events'].append(num_events)\n",
        "        stats['avg_intensity'].append(avg_intensity)\n",
        "        stats['avg_event_length'].append(avg_event_length)\n",
        "        stats['avg_event_duration'].append(avg_event_duration)\n",
        "        stats['std'].append(std)\n",
        "        stats['skewness'].append(skewness)\n",
        "        stats['kurtosis'].append(kurtosis)\n",
        "        stats['autocorrelation'].append(autocorrelation)\n",
        "\n",
        "    # Create a DataFrame from the dictionary of statistics\n",
        "    stats_df = pd.DataFrame(stats)\n",
        "    stats_df = stats_df.fillna(0)\n",
        "\n",
        "    return stats_df"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def fill_empty_dfs(dictionary):\n",
        "  # when we do emotion processing, some dfs will have ZERO successful frames,\n",
        "  # leading to ZERO events, and an empty df.\n",
        "  # we need to fill the empty dfs with a df with all 0s\n",
        "\n",
        "  non_empty_dfs = [df for df in dictionary.values() if not df.empty]\n",
        "\n",
        "  if not non_empty_dfs:\n",
        "      return dictionary  # Return the original dictionary if all DataFrames are empty\n",
        "\n",
        "  non_empty_df = non_empty_dfs[0]  # Choose the first non-empty DataFrame as replacement\n",
        "\n",
        "  modified_dictionary = {}\n",
        "  for key, df in dictionary.items():\n",
        "      if df.empty:\n",
        "          modified_df = pd.DataFrame(0, index=non_empty_df.index, columns=non_empty_df.columns)\n",
        "          # Preserve string columns from non-empty DataFrame\n",
        "          for column in non_empty_df.columns:\n",
        "              if non_empty_df[column].dtype == object:\n",
        "                  modified_df[column] = non_empty_df[column]\n",
        "      else:\n",
        "          modified_df = df.copy()\n",
        "\n",
        "      modified_dictionary[key] = modified_df\n",
        "\n",
        "  return modified_dictionary"
      ],
      "metadata": {
        "id": "hwRS2uUqcHNb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7jZKlIodZ1G0"
      },
      "outputs": [],
      "source": [
        "# DON'T DO THIS! We are now using Feature Extraction 2.0 for event analysis\n",
        "# dictionary to store results from each different time window we test!\n",
        "hsemotion_emo_stats_dict = {}\n",
        "\n",
        "for time_radius, hsemotion_radius_now in hsemotion_radius_dict.items():\n",
        "  print('Time Radius: ', time_radius)\n",
        "  hssemotion_fme = apply_function_to_dict(hsemotion_radius_now, filter_max_emotion, threshold=0.7)\n",
        "  hsemotion_aec = apply_function_to_dict(hssemotion_fme, add_event_column, time_thresh=10, min_event_length=6)\n",
        "  hsemotion_emo_stats = apply_function_to_dict(hsemotion_aec, calculate_emotion_statistics)\n",
        "  hsemotion_emo_stats_fixed = fill_empty_dfs(hsemotion_emo_stats)\n",
        "  hsemotion_emo_stats_dict[time_radius] = hsemotion_emo_stats_fixed"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "save_var(hsemotion_emo_stats_dict, forced_name=f'hsemotion_emo_stats_dict_{PAT_SHORT_NAME}')"
      ],
      "metadata": {
        "id": "XkSIdJ13FUym"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hZQOUoIxbWQR"
      },
      "outputs": [],
      "source": [
        "hsemotion_emo_stats_dict['60'][get_moodTracking_datetime(0)]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C9ZqapEhJiAe"
      },
      "source": [
        "## Copying OpenDBM Feature Extraction\n",
        "\n",
        "We are manually coding this based on their documentation, with the goal of maximizing customization in the future. We've also applied their stats pipeline to other AU detectors beyond OpenFace"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ijCyU-AVhAqR"
      },
      "source": [
        "### Convert AU to Emotion"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k8U9rA0HJYV1"
      },
      "outputs": [],
      "source": [
        "import scipy.stats as stats\n",
        "\n",
        "def detect_emotions(df, method, emo_AUs, additional_filter=None):\n",
        "    # INPUT:\n",
        "    # df -- dataframe with AUs for each frame\n",
        "    # method -- must be 'OpenFace'\n",
        "    # emo_AUs -- the hash table\n",
        "    # additional_filter -- are we just doing lower half? upper half? This is None or a list of ints (which AUs to keep)\n",
        "\n",
        "    # OUTPUT:\n",
        "    # 3 datafrmes. Each has emotion values for each frame\n",
        "    # emo_hard, emo_soft, emo_binary (see OpenDBM docs for details)\n",
        "\n",
        "\n",
        "    if df.empty:\n",
        "      return (df, df, df)\n",
        "    # We start by mapping AUs to emotions for each of our two methods\n",
        "    # Using this mapping: https://aicure.github.io/open_dbm/docs/emotional-expressivity\n",
        "    if method == 'OpenFace':\n",
        "        columns = ['AU01_r','AU02_r', 'AU04_r', 'AU05_r', 'AU06_r', 'AU07_r', 'AU09_r', 'AU10_r',\n",
        "                    'AU12_r', 'AU14_r', 'AU15_r', 'AU17_r', 'AU20_r', 'AU23_r', 'AU25_r',\n",
        "                    'AU26_r', 'AU45_r',\n",
        "                    'AU01_c',\n",
        "                    'AU02_c',\n",
        "                    'AU04_c',\n",
        "                    'AU05_c',\n",
        "                    'AU06_c',\n",
        "                    'AU07_c',\n",
        "                    'AU09_c',\n",
        "                    'AU10_c',\n",
        "                    'AU12_c',\n",
        "                    'AU14_c',\n",
        "                    'AU15_c',\n",
        "                    'AU17_c',\n",
        "                    'AU20_c',\n",
        "                    'AU23_c',\n",
        "                    'AU25_c',\n",
        "                    'AU26_c',\n",
        "                    'AU45_c']\n",
        "\n",
        "        # hash tables for presence and intensity\n",
        "        emo_AUs_presence = {}\n",
        "        emo_AUs_intensity = {}\n",
        "        for key in emo_AUs.keys(): # loop through emotion strings\n",
        "            new_values_r = [] # regression\n",
        "            new_values_c = [] # classification\n",
        "\n",
        "            for value in emo_AUs[key]:\n",
        "                if isinstance(value, int):\n",
        "                    AU_key_r = \"AU{:02d}_r\".format(value)\n",
        "                    AU_key_c = \"AU{:02d}_c\".format(value)\n",
        "                    if AU_key_r in columns:\n",
        "                        if additional_filter is not None:\n",
        "                          if value in additional_filter:\n",
        "                            new_values_r.append(AU_key_r)\n",
        "                        else:\n",
        "                          new_values_r.append(AU_key_r)\n",
        "                    if AU_key_c in columns:\n",
        "                        if additional_filter is not None:\n",
        "                          if value in additional_filter:\n",
        "                            new_values_c.append(AU_key_c)\n",
        "                        else:\n",
        "                          new_values_c.append(AU_key_c)\n",
        "            if new_values_r:\n",
        "                emo_AUs_intensity[key] = new_values_r\n",
        "            if new_values_c:\n",
        "                emo_AUs_presence[key] = new_values_c\n",
        "\n",
        "    # elif method == 'OpenGraphAU':\n",
        "    #     raise ValueError(\"Invalid method parameter. Method must be 'OpenFace'.\")\n",
        "        # columns = ['AU1', 'AU2', 'AU4', 'AU5', 'AU6', 'AU7', 'AU9',\n",
        "        #            'AU10', 'AU11', 'AU12', 'AU13', 'AU14', 'AU15', 'AU16', 'AU17',\n",
        "        #            'AU18', 'AU19', 'AU20', 'AU22', 'AU23', 'AU24', 'AU25', 'AU26', 'AU27', 'AU32',\n",
        "        #            'AU38', 'AU39']\n",
        "\n",
        "        # # add the classification columns!\n",
        "        # columns = [item for sublist in [[col+'_r', col+'_c'] for col in columns] for item in sublist]\n",
        "\n",
        "        # # hash tables for presence and intensity\n",
        "        # emo_AUs_presence = {}\n",
        "        # emo_AUs_intensity = {}\n",
        "        # for key in emo_AUs.keys():\n",
        "        #     new_values_r = []\n",
        "        #     new_values_c = []\n",
        "        #     for value in emo_AUs[key]:\n",
        "        #         if isinstance(value, int):\n",
        "        #             AU_key_r = f\"AU{value}_r\"\n",
        "        #             AU_key_c = f\"AU{value}_c\"\n",
        "        #             if AU_key_r in columns:\n",
        "        #                 if additional_filter is not None:\n",
        "        #                   if value in additional_filter:\n",
        "        #                     new_values_r.append(AU_key_r)\n",
        "        #                 else:\n",
        "        #                   new_values_r.append(AU_key_r)\n",
        "        #             if AU_key_c in columns:\n",
        "        #                 if additional_filter is not None:\n",
        "        #                   if value in additional_filter:\n",
        "        #                     new_values_c.append(AU_key_c)\n",
        "        #                 else:\n",
        "        #                   new_values_c.append(AU_key_c)\n",
        "        #     if new_values_r:\n",
        "        #         emo_AUs_intensity[key] = new_values_r\n",
        "        #     if new_values_c:\n",
        "        #         emo_AUs_presence[key] = new_values_c\n",
        "\n",
        "    else:\n",
        "        # if the method specified is not OpenFace or OpenGraphAU, raise an error (pipeline doesn't support others yet)\n",
        "        raise ValueError(\"Invalid method parameter. Method must be 'OpenFace'.\")\n",
        "\n",
        "    # Create an empty dictionary to store the emotion scores\n",
        "    emotion_scores_hard = {} # only non-zero if all AUs present\n",
        "    emotion_scores_soft = {} # average of AU intensities even if all not present\n",
        "    emotion_scores_binary = {} # 1 or 0: are all AUs present?\n",
        "\n",
        "    # Compute emotion scores for each emotion\n",
        "    for emotion in emo_AUs_presence.keys():\n",
        "        # Get the relevant columns for presence and intensity\n",
        "        presence_cols = emo_AUs_presence[emotion]\n",
        "        intensity_cols = emo_AUs_intensity[emotion]\n",
        "\n",
        "        # Compute the emotion score for each row in the dataframe\n",
        "        emotion_scores_hard[emotion] = df[intensity_cols].mean(axis=1) * df[presence_cols].all(axis=1)\n",
        "        emotion_scores_hard[emotion] = emotion_scores_hard[emotion].fillna(0)\n",
        "\n",
        "        emotion_scores_soft[emotion] = df[intensity_cols].mean(axis=1)\n",
        "        emotion_scores_soft[emotion] = emotion_scores_soft[emotion].fillna(0)\n",
        "\n",
        "        emotion_scores_binary[emotion] = df[presence_cols].all(axis=1)\n",
        "        emotion_scores_binary[emotion] = emotion_scores_binary[emotion].fillna(0)\n",
        "\n",
        "    # Create a new dataframe with the emotion scores\n",
        "    emotion_df_hard = pd.DataFrame(emotion_scores_hard)\n",
        "    emotion_df_soft = pd.DataFrame(emotion_scores_soft)\n",
        "    emotion_df_binary = pd.DataFrame(emotion_scores_binary)\n",
        "    emotion_df_binary = emotion_df_binary.replace({False: 0, True: 1})\n",
        "\n",
        "    # Let's add timestamp and success on\n",
        "    columns_of_interest = ['timestamp', 'success']\n",
        "    df_temp = df[columns_of_interest]\n",
        "\n",
        "    # Concatenate the columns from df2 with df1\n",
        "    emotion_df_hard = pd.concat([df_temp, emotion_df_hard], axis=1)\n",
        "    emotion_df_soft = pd.concat([df_temp, emotion_df_soft], axis=1)\n",
        "    emotion_df_binary = pd.concat([df_temp, emotion_df_binary], axis=1)\n",
        "\n",
        "    return emotion_df_hard, emotion_df_soft, emotion_df_binary\n",
        "\n",
        "\n",
        "\n",
        "def detect_emotions_og(df, method, emo_AUs, additional_filter=None):\n",
        "    # INPUT:\n",
        "    # df -- dataframe with AUs for each frame\n",
        "    # method -- must be 'OpenGraphAU'\n",
        "    # emo_AUs -- the hash table\n",
        "    # additional_filter -- are we just doing lower half? upper half? This is None or a list of ints (which AUs to keep)\n",
        "\n",
        "    # OUTPUT:\n",
        "    # 1 datafrme with emotion values for each frame\n",
        "    # emo_binary (see OpenDBM docs for details)\n",
        "\n",
        "\n",
        "    if df.empty:\n",
        "      return df\n",
        "    # We start by mapping AUs to emotions for each of our two methods\n",
        "    # Using this mapping: https://aicure.github.io/open_dbm/docs/emotional-expressivity\n",
        "\n",
        "\n",
        "    if method == 'OpenGraphAU':\n",
        "        columns = ['AU1', 'AU2', 'AU4', 'AU5', 'AU6', 'AU7', 'AU9',\n",
        "                   'AU10', 'AU11', 'AU12', 'AU13', 'AU14', 'AU15', 'AU16', 'AU17',\n",
        "                   'AU18', 'AU19', 'AU20', 'AU22', 'AU23', 'AU24', 'AU25', 'AU26', 'AU27', 'AU32',\n",
        "                   'AU38', 'AU39']\n",
        "\n",
        "        # add the classification columns!\n",
        "        columns = [item for sublist in [[col+'_r', col+'_c'] for col in columns] for item in sublist]\n",
        "\n",
        "        # hash tables for presence and intensity\n",
        "        emo_AUs_presence = {}\n",
        "        for key in emo_AUs.keys():\n",
        "            new_values_c = []\n",
        "            for value in emo_AUs[key]:\n",
        "                if isinstance(value, int):\n",
        "                    AU_key_c = f\"AU{value}_c\"\n",
        "\n",
        "                    if AU_key_c in columns:\n",
        "                        if additional_filter is not None:\n",
        "                          if value in additional_filter:\n",
        "                            new_values_c.append(AU_key_c)\n",
        "                        else:\n",
        "                          new_values_c.append(AU_key_c)\n",
        "            if new_values_c:\n",
        "                emo_AUs_presence[key] = new_values_c\n",
        "\n",
        "    else:\n",
        "        # if the method specified is not OpenFace or OpenGraphAU, raise an error (pipeline doesn't support others yet)\n",
        "        raise ValueError(\"Invalid method parameter. Method must be 'OpenGraphAU'.\")\n",
        "\n",
        "    # Create an empty dictionary to store the emotion scores\n",
        "    emotion_scores_binary = {} # 1 or 0: are all AUs present?\n",
        "\n",
        "    # Compute emotion scores for each emotion\n",
        "    for emotion in emo_AUs_presence.keys():\n",
        "        # Get the relevant columns for presence\n",
        "        presence_cols = emo_AUs_presence[emotion]\n",
        "\n",
        "        # Compute the emotion score for each row in the dataframe\n",
        "        emotion_scores_binary[emotion] = df[presence_cols].all(axis=1)\n",
        "        emotion_scores_binary[emotion] = emotion_scores_binary[emotion].fillna(0)\n",
        "\n",
        "    # Create a new dataframe with the emotion scores\n",
        "    emotion_df_binary = pd.DataFrame(emotion_scores_binary)\n",
        "    emotion_df_binary = emotion_df_binary.replace({False: 0, True: 1})\n",
        "\n",
        "    # Let's add timestamp and success on\n",
        "    columns_of_interest = ['timestamp', 'success']\n",
        "    df_temp = df[columns_of_interest]\n",
        "\n",
        "    # Concatenate the columns from df2 with df1\n",
        "    emotion_df_binary = pd.concat([df_temp, emotion_df_binary], axis=1)\n",
        "\n",
        "    return emotion_df_binary\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R2RyDtfUbkFe"
      },
      "outputs": [],
      "source": [
        "# Raw Variables for Emotional Expressivity!\n",
        "\n",
        "openface_emoHardSoftPres_dict = {}\n",
        "\n",
        "# key: (df_emohard, df_emosoft, df_emopres)\n",
        "\n",
        "for time_radius, openface_radius_now in openface_radius_dict.items():\n",
        "  print('Time Radius: ', time_radius)\n",
        "  openface_emoHardSoftPres_dict[time_radius] = apply_function_to_dict(openface_radius_now, detect_emotions, method='OpenFace', emo_AUs=emo_AUs)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "opengraphau_emoPres_dict = {}\n",
        "\n",
        "for time_radius, opengraphau_radius_now in opengraphau_radius_dict.items():\n",
        "  print('Time Radius: ', time_radius)\n",
        "  opengraphau_radius_now_temp = apply_function_to_dict(opengraphau_radius_now, create_binary_columns, threshold=0.4)\n",
        "  opengraphau_radius_now_bin = apply_function_to_dict(opengraphau_radius_now_temp, remove_columns_ending_with_r)\n",
        "  opengraphau_emoPres_dict[time_radius] = apply_function_to_dict(opengraphau_radius_now_bin, detect_emotions_og, method='OpenGraphAU', emo_AUs=emo_AUs)\n"
      ],
      "metadata": {
        "id": "LtqG8nfDBGHE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j-0Eqzje4OdE"
      },
      "outputs": [],
      "source": [
        "# This will help us get Raw Variables for Overall Expressivity!\n",
        "\n",
        "# key: (df_emohard, df_emosoft, df_emopres)\n",
        "\n",
        "\n",
        "\n",
        "openface_lowerHardSoftPres_dict = {}\n",
        "openface_upperHardSoftPres_dict = {}\n",
        "\n",
        "for time_radius, openface_radius_now in openface_radius_dict.items():\n",
        "  openface_lowerHardSoftPres_dict[time_radius] = apply_function_to_dict(openface_radius_now, detect_emotions, method='OpenFace', emo_AUs=emo_AUs, additional_filter=AU_lower)\n",
        "  openface_upperHardSoftPres_dict[time_radius] = apply_function_to_dict(openface_radius_now, detect_emotions, method='OpenFace', emo_AUs=emo_AUs, additional_filter=AU_upper)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "opengraphau_lowerPres_dict = {}\n",
        "opengraphau_upperPres_dict = {}\n",
        "\n",
        "for time_radius, opengraphau_radius_now in opengraphau_radius_dict.items():\n",
        "  print('Time Radius: ', time_radius)\n",
        "  opengraphau_radius_now_temp = apply_function_to_dict(opengraphau_radius_now, create_binary_columns, threshold=0.4)\n",
        "  opengraphau_radius_now_bin = apply_function_to_dict(opengraphau_radius_now_temp, remove_columns_ending_with_r)\n",
        "  opengraphau_lowerPres_dict[time_radius] = apply_function_to_dict(opengraphau_radius_now_bin, detect_emotions_og, method='OpenGraphAU', emo_AUs=emo_AUs, additional_filter=AU_lower)\n",
        "  opengraphau_upperPres_dict[time_radius] = apply_function_to_dict(opengraphau_radius_now_bin, detect_emotions_og, method='OpenGraphAU', emo_AUs=emo_AUs, additional_filter=AU_upper)"
      ],
      "metadata": {
        "id": "p8iH_axvBCYY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# example: binary values from openface!\n",
        "openface_emoHardSoftPres_dict['60'][get_moodTracking_datetime(0)][2]"
      ],
      "metadata": {
        "id": "DvFobszX3qGS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8vkyPb1PdAOk"
      },
      "outputs": [],
      "source": [
        "# example: binary values from opengraphAU!\n",
        "opengraphau_emoPres_dict['60'][get_moodTracking_datetime(1)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jjNMM9DA4-A_"
      },
      "outputs": [],
      "source": [
        "# just upper half of face! soft values from openface\n",
        "openface_upperHardSoftPres_dict['60'][get_moodTracking_datetime(1)][1]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NjInHNtNhZXd"
      },
      "source": [
        "### Apply Our HSEmotion Analysis to AU Detectors!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Dux34pPqgSsW"
      },
      "outputs": [],
      "source": [
        "# Dictionary of dictionary of just soft values\n",
        "openface_emoSoft_dict = {}\n",
        "\n",
        "for time_radius, openface_emoHardSoftPres_now in openface_emoHardSoftPres_dict.items():\n",
        "  openface_emoSoft_dict[time_radius] = {key: val[1] for key, val in openface_emoHardSoftPres_now.items()}\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# We can't do this anymore since we're only using binary columns from opengraphAU!\n",
        "opengraphau_emoSoft_dict = {}\n",
        "\n",
        "for time_radius, opengraphau_emoHardSoftPres_now in opengraphau_emoHardSoftPres_dict.items():\n",
        "  opengraphau_emoSoft_dict[time_radius] = {key: val[1] for key, val in opengraphau_emoHardSoftPres_now.items()}\n"
      ],
      "metadata": {
        "id": "12M01MZPILF0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h-uhxDQHhf-a"
      },
      "outputs": [],
      "source": [
        "# DON'T DO THIS! We are now using Feature Extraction 2.0 for event analysis\n",
        "# We can't do this anymore since we're only using binary columns from opengraphAU!\n",
        "\n",
        "# OPENGRAPHAU\n",
        "\n",
        "# dictionary to store results from each different time window we test!\n",
        "opengraphau_emo_stats_dict = {}\n",
        "\n",
        "for time_radius, opengraphau_radius_now in opengraphau_emoSoft_dict.items():\n",
        "  opengraphau_fme = apply_function_to_dict(opengraphau_radius_now, filter_max_emotion, threshold=0.6)\n",
        "  opengraphau_aec = apply_function_to_dict(opengraphau_fme, add_event_column, time_thresh=2, min_event_length=10)\n",
        "  opengraphau_emo_stats = apply_function_to_dict(opengraphau_aec, calculate_emotion_statistics)\n",
        "  opengraphau_emo_stats_fixed = fill_empty_dfs(opengraphau_emo_stats)\n",
        "  opengraphau_emo_stats_dict[time_radius] = opengraphau_emo_stats_fixed\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vsLLAH3tl04e"
      },
      "outputs": [],
      "source": [
        "opengraphau_emo_stats_dict['60'][get_moodTracking_datetime(1)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OYVc6SnsmyL1"
      },
      "outputs": [],
      "source": [
        "# OPENFACE - affect/emotions (longer term)\n",
        "openface_emo_stats_dict = {}\n",
        "\n",
        "for time_radius, openface_radius_now in openface_emoSoft_dict.items():\n",
        "  openface_fme = apply_function_to_dict(openface_radius_now, filter_max_emotion, threshold=0.6)\n",
        "  openface_aec = apply_function_to_dict(openface_fme, add_event_column, time_thresh=2, min_event_length=10)\n",
        "  openface_emo_stats = apply_function_to_dict(openface_aec, calculate_emotion_statistics)\n",
        "  openface_emo_stats_fixed = fill_empty_dfs(openface_emo_stats)\n",
        "\n",
        "  openface_emo_stats_dict[time_radius] = openface_emo_stats_fixed\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# OPENFACE - smile (shorter term)\n",
        "openface_emo_stats_dict = {}\n",
        "\n",
        "for time_radius, openface_radius_now in openface_emoSoft_dict.items():\n",
        "  openface_fme = apply_function_to_dict(openface_radius_now, filter_max_emotion, threshold=0.6)\n",
        "  openface_aec = apply_function_to_dict(openface_fme, add_event_column, time_thresh=10, min_event_length=6)\n",
        "  openface_emo_stats = apply_function_to_dict(openface_aec, calculate_emotion_statistics)\n",
        "  openface_emo_stats_fixed = fill_empty_dfs(openface_emo_stats)\n",
        "\n",
        "  openface_emo_stats_dict[time_radius] = openface_emo_stats_fixed\n",
        "\n"
      ],
      "metadata": {
        "id": "7NfKynX4r_mb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gOCiRy5zyy8S"
      },
      "outputs": [],
      "source": [
        "# SAVE openface_emo_stats_dict\n",
        "save_var(openface_emo_stats_dict, forced_name=f'openface_emo_stats_dict_{PAT_SHORT_NAME}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JBj9E0Rqy1Ro"
      },
      "outputs": [],
      "source": [
        "# LOAD openface_emo_stats_dict\n",
        "\n",
        "openface_emo_stats_dict = load_var(f'openface_emo_stats_dict_{PAT_SHORT_NAME}')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V6WIgfxt54Eb"
      },
      "outputs": [],
      "source": [
        "openface_emo_stats_dict['60'][get_moodTracking_datetime(1)]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fvxvof3FXOHG"
      },
      "source": [
        "### Action Units"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nCTZF0HDJnaR"
      },
      "outputs": [],
      "source": [
        "def rename_columns(df):\n",
        "    \"\"\"\n",
        "    Renames the columns in a DataFrame according to specified pattern.\n",
        "\n",
        "    Args:\n",
        "        df (pandas DataFrame): The DataFrame to rename columns.\n",
        "\n",
        "    Returns:\n",
        "        pandas DataFrame: The DataFrame with renamed columns.\n",
        "    \"\"\"\n",
        "\n",
        "    # Copy the DataFrame\n",
        "    df_copy = df.copy()\n",
        "\n",
        "    # Define the mapping for renaming columns\n",
        "    column_mapping = {\n",
        "        '_r': 'int',\n",
        "        '_c': 'pres'\n",
        "    }\n",
        "\n",
        "    # Function to rename the columns\n",
        "    def rename_column(column_name):\n",
        "        au_number = column_name[2:4]\n",
        "        if au_number.endswith('_'):\n",
        "          au_number = '0' + au_number[0:1]\n",
        "        suffix = column_name[-2:]\n",
        "        if suffix in column_mapping:\n",
        "            return f'fac_au{au_number}{column_mapping[suffix]}'\n",
        "        else:\n",
        "            return column_name\n",
        "\n",
        "    # Rename the columns in the copied DataFrame\n",
        "    df_copy = df_copy.rename(columns=rename_column)\n",
        "\n",
        "    return df_copy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UIyBBzD6VD2T"
      },
      "outputs": [],
      "source": [
        "def calculate_AU_statistics(df):\n",
        "    # Initialize an empty dictionary to store the computed statistics\n",
        "    stats = {'AU': [], 'pres_pct': [], 'int_mean': [], 'int_std': []}\n",
        "\n",
        "    # Iterate over the AU columns\n",
        "    for col in df.columns:\n",
        "        if col.startswith('fac_au') and ('pres' in col):\n",
        "            # Calculate the percentage of frames where AU is present\n",
        "            pres_pct = df[col].mean() * 100\n",
        "            # Extract the AU number\n",
        "            AU = col.split('au')[1][0:2]\n",
        "            # Calculate the mean and standard deviation of intensity for the AU\n",
        "            int_mean = df[f'fac_au{AU}int'].mean()\n",
        "            int_std = df[f'fac_au{AU}int'].std()\n",
        "\n",
        "            # Add the statistics to the dictionary\n",
        "            stats['AU'].append(AU)\n",
        "            stats['pres_pct'].append(pres_pct)\n",
        "            stats['int_mean'].append(int_mean)\n",
        "            stats['int_std'].append(int_std)\n",
        "\n",
        "    # Create a DataFrame from the dictionary of statistics\n",
        "    stats_df = pd.DataFrame(stats)\n",
        "\n",
        "    return stats_df\n",
        "\n",
        "def calculate_AU_statistics_og(df):\n",
        "    # Stats for ONLY binary columns!\n",
        "    # Initialize an empty dictionary to store the computed statistics\n",
        "    stats = {'AU': [], 'pres_pct': []}\n",
        "\n",
        "    # Iterate over the AU columns\n",
        "    for col in df.columns:\n",
        "        if col.startswith('fac_au') and ('pres' in col):\n",
        "            # Calculate the percentage of frames where AU is present\n",
        "            pres_pct = df[col].mean() * 100\n",
        "            # Extract the AU number\n",
        "            AU = col.split('au')[1][0:2]\n",
        "\n",
        "            # Add the statistics to the dictionary\n",
        "            stats['AU'].append(AU)\n",
        "            stats['pres_pct'].append(pres_pct)\n",
        "\n",
        "    # Create a DataFrame from the dictionary of statistics\n",
        "    stats_df = pd.DataFrame(stats)\n",
        "\n",
        "    return stats_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Elg7u1XDjv3X"
      },
      "outputs": [],
      "source": [
        "# Raw Variables!\n",
        "openface_radius_renamed_dict = {}\n",
        "\n",
        "for time_radius, openface_radius_now in openface_radius_dict.items():\n",
        "  openface_radius_renamed_dict[time_radius] = apply_function_to_dict(openface_radius_now, rename_columns)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "opengraphau_radius_renamed_dict = {}\n",
        "\n",
        "for time_radius, opengraphau_radius_now in opengraphau_radius_dict.items():\n",
        "  print('Time Radius: ', time_radius)\n",
        "  opengraphau_radius_now_temp = apply_function_to_dict(opengraphau_radius_now, create_binary_columns, threshold=0.4)\n",
        "  opengraphau_radius_now_bin = apply_function_to_dict(opengraphau_radius_now_temp, remove_columns_ending_with_r)\n",
        "  opengraphau_radius_renamed_dict[time_radius] = apply_function_to_dict(opengraphau_radius_now_bin, rename_columns)\n"
      ],
      "metadata": {
        "id": "6wjYgSdZIhoh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kCYjKsxJkGP1"
      },
      "outputs": [],
      "source": [
        "# Derived Variables!\n",
        "openface_au_derived_dict = {}\n",
        "\n",
        "for time_radius, openface_radius_renamed_now in openface_radius_renamed_dict.items():\n",
        "  openface_au_derived_dict[time_radius] = apply_function_to_dict(openface_radius_renamed_now, calculate_AU_statistics)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "opengraphau_au_derived_dict = {}\n",
        "\n",
        "for time_radius, opengraphau_radius_renamed_now in opengraphau_radius_renamed_dict.items():\n",
        "  opengraphau_au_derived_dict[time_radius] = apply_function_to_dict(opengraphau_radius_renamed_now, calculate_AU_statistics_og)"
      ],
      "metadata": {
        "id": "G6MzjU03Ilv8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "opengraphau_au_derived_dict['60'][get_moodTracking_datetime(1)]"
      ],
      "metadata": {
        "id": "hlTfdyiEh51l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xqar5VjEXXo1"
      },
      "source": [
        "### Emotional Expressivity"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YNQO9_omd8o3"
      },
      "outputs": [],
      "source": [
        "def calculate_emotion_express_statistics(tuple_to_unpack):\n",
        "    \"\"\"\n",
        "    Calculates statistics for each emotion in the given DataFrames.\n",
        "\n",
        "    Args:\n",
        "        tuple_to_unpack: 3-membered tuple that has:\n",
        "          df_emo_inthard (pandas DataFrame): DataFrame with emotion intensity (hard) values.\n",
        "          df_emo_intsoft (pandas DataFrame): DataFrame with emotion intensity (soft) values.\n",
        "          df_emo_pres (pandas DataFrame): DataFrame with emotion presence values.\n",
        "\n",
        "    Returns:\n",
        "        pandas DataFrame: A DataFrame with statistics for each emotion.\n",
        "    \"\"\"\n",
        "    df_emo_inthard, df_emo_intsoft, df_emo_pres = tuple_to_unpack\n",
        "    stats = {'emotion': [], 'pres_pct': [], 'intsoft_mean': [], 'intsoft_std': [], 'inthard_mean': []}\n",
        "\n",
        "    emotions = [col for col in df_emo_inthard.columns if col not in ['timestamp', 'success']]\n",
        "\n",
        "    for emotion in emotions:\n",
        "        pres_pct = (df_emo_pres[emotion] == 1).mean() * 100\n",
        "        intsoft_mean = df_emo_intsoft[emotion].mean()\n",
        "        intsoft_std = df_emo_intsoft[emotion].std()\n",
        "        inthard_mean = df_emo_inthard[emotion].mean()\n",
        "\n",
        "        stats['emotion'].append(emotion)\n",
        "        stats['pres_pct'].append(pres_pct)\n",
        "        stats['intsoft_mean'].append(intsoft_mean)\n",
        "        stats['intsoft_std'].append(intsoft_std)\n",
        "        stats['inthard_mean'].append(inthard_mean)\n",
        "\n",
        "    stats_df = pd.DataFrame(stats)\n",
        "    return stats_df\n",
        "\n",
        "def calculate_ee_stats_og(df_emo_pres):\n",
        "    \"\"\"\n",
        "    Calculates statistics for each emotion in the given DataFrame.\n",
        "\n",
        "    Args:\n",
        "        df_emo_pres (pandas DataFrame): DataFrame with emotion presence values.\n",
        "\n",
        "    Returns:\n",
        "        pandas DataFrame: A DataFrame with statistics for each emotion.\n",
        "    \"\"\"\n",
        "    stats = {'emotion': [], 'pres_pct': []}\n",
        "\n",
        "    emotions = [col for col in df_emo_pres.columns if col not in ['timestamp', 'success']]\n",
        "\n",
        "    for emotion in emotions:\n",
        "        pres_pct = (df_emo_pres[emotion] == 1).mean() * 100\n",
        "\n",
        "\n",
        "        stats['emotion'].append(emotion)\n",
        "        stats['pres_pct'].append(pres_pct)\n",
        "\n",
        "    stats_df = pd.DataFrame(stats)\n",
        "    return stats_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ch2W7fH3GHQf"
      },
      "outputs": [],
      "source": [
        "def calculate_ee_stats_hse(df, threshold):\n",
        "    \"\"\"\n",
        "    Calculates statistics for each emotion in the given DataFrame.\n",
        "\n",
        "    Args:\n",
        "    df with emotion intensities for every video frame\n",
        "    threshold for presence of emotion (i.e. 0.5)\n",
        "\n",
        "    Returns:\n",
        "        pandas DataFrame: A DataFrame with statistics for each emotion.\n",
        "    \"\"\"\n",
        "    df_emo_intsoft = df\n",
        "    stats = {'emotion': [], 'pres_pct': [], 'intsoft_mean': [], 'intsoft_std': []}\n",
        "\n",
        "    emotions = [col for col in df_emo_intsoft.columns if col not in ['timestamp', 'success']]\n",
        "\n",
        "    for emotion in emotions:\n",
        "        pres_pct = (df_emo_intsoft[emotion] >= threshold).mean() * 100\n",
        "        intsoft_mean = df_emo_intsoft[emotion].mean()\n",
        "        intsoft_std = df_emo_intsoft[emotion].std()\n",
        "\n",
        "        stats['emotion'].append(emotion)\n",
        "        stats['pres_pct'].append(pres_pct)\n",
        "        stats['intsoft_mean'].append(intsoft_mean)\n",
        "        stats['intsoft_std'].append(intsoft_std)\n",
        "\n",
        "    stats_df = pd.DataFrame(stats)\n",
        "    return stats_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dw-ZfINxXcSO"
      },
      "outputs": [],
      "source": [
        "# Raw Variables for Emotional Expressivity were calculated above:\n",
        "# openface_emoHardSoftPres\n",
        "# opengraphau_emoHardSoftPres"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mPhTX8E0lWNf"
      },
      "outputs": [],
      "source": [
        "# Derived Variables for Emotional Expressivity\n",
        "openface_ee_derived_dict = {}\n",
        "\n",
        "for time_radius, openface_emoHardSoftPres_now in openface_emoHardSoftPres_dict.items():\n",
        "  openface_ee_derived_dict[time_radius] = apply_function_to_dict(openface_emoHardSoftPres_now, calculate_emotion_express_statistics)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "opengraphau_ee_derived_dict = {}\n",
        "\n",
        "for time_radius, opengraphau_emoPres_now in opengraphau_emoPres_dict.items():\n",
        "  opengraphau_ee_derived_dict[time_radius] = apply_function_to_dict(opengraphau_emoPres_now, calculate_ee_stats_og)\n"
      ],
      "metadata": {
        "id": "SpqQMUX4B6hc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "hsemotion_ee_derived_dict = {}\n",
        "\n",
        "for time_radius, hsemotion_radius_now in hsemotion_radius_dict.items():\n",
        "  hsemotion_ee_derived_dict[time_radius] = apply_function_to_dict(hsemotion_radius_now, calculate_ee_stats_hse, threshold=0.5)\n"
      ],
      "metadata": {
        "id": "FjWanNgEB6oU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DiAEqJOzHeKw"
      },
      "outputs": [],
      "source": [
        "hsemotion_ee_derived_dict['60'][get_moodTracking_datetime(1)]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "hsemotion_ee_derived_dict['0.08333'][get_moodTracking_datetime(1, df_moodTracking=Final_Smile_Labels)]"
      ],
      "metadata": {
        "id": "pmqBs6_QbDEL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MKizd4y0vmhP"
      },
      "outputs": [],
      "source": [
        "openface_ee_derived_dict['60'][get_moodTracking_datetime(1)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ec8SSaaF06ZQ"
      },
      "outputs": [],
      "source": [
        "opengraphau_ee_derived_dict['60'][get_moodTracking_datetime(1)]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yH3Cs6H61lan"
      },
      "source": [
        "### Overall Expressivity"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LOFYuIJL1qML"
      },
      "outputs": [],
      "source": [
        "def compute_oe_raw_vars(regular_tuple, lower_tuple, upper_tuple):\n",
        "    # Takes in 3 3-membered tuples, each of which should be hardSoftPres\n",
        "    # regular, lower, upper\n",
        "\n",
        "    # Outputs one df with the raw variables for overall expressivity\n",
        "\n",
        "    df_emo_inthard, df_emo_intsoft, df_emo_pres = regular_tuple\n",
        "    df_emo_inthard_lower, df_emo_intsoft_lower, df_emo_pres_lower = lower_tuple\n",
        "    df_emo_inthard_upper, df_emo_intsoft_upper, df_emo_pres_upper = upper_tuple\n",
        "\n",
        "    # Calculate the average values for emo_intsoft and emo_inthard across all frames\n",
        "    avg_emo_intsoft = df_emo_intsoft.mean(axis=1)\n",
        "    avg_emo_inthard = df_emo_inthard.mean(axis=1)\n",
        "\n",
        "    # Calculate lower and upper averages across all frames\n",
        "    avg_emo_intsoft_lower = df_emo_intsoft_lower.mean(axis=1)\n",
        "    avg_emo_inthard_lower = df_emo_inthard_lower.mean(axis=1)\n",
        "    avg_emo_intsoft_upper = df_emo_intsoft_upper.mean(axis=1)\n",
        "    avg_emo_inthard_upper = df_emo_inthard_upper.mean(axis=1)\n",
        "\n",
        "    # Create a new dataframe with the computed statistics\n",
        "    stats_df = pd.DataFrame({'comintsoft': avg_emo_intsoft, 'cominthard': avg_emo_inthard,\n",
        "                             'comlowintsoft': avg_emo_intsoft_lower, 'comlowinthard': avg_emo_inthard_lower,\n",
        "                             'comuppintsoft': avg_emo_intsoft_upper, 'comuppinthard': avg_emo_inthard_upper,})\n",
        "\n",
        "    return stats_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jH1M_yel8kWa"
      },
      "outputs": [],
      "source": [
        "def apply_function_to_dict_three(d1, d2, d3, func, **kwargs):\n",
        "    \"\"\"\n",
        "    Apply a function that takes in 3 dfs and return a modified dictionary\n",
        "\n",
        "    Args:\n",
        "        d1, d2, d3: The dictionaries containing DataFrames.\n",
        "        func (function): The function to apply to each DataFrame.\n",
        "        **kwargs: Additional keyword arguments to pass to the function.\n",
        "\n",
        "    Returns:\n",
        "        dict_final: A modified copy of the dictionary with the function applied to each DataFrame.\n",
        "    \"\"\"\n",
        "    dict_final = {}\n",
        "    for key in d1.keys():\n",
        "      dict_final[key] = func(d1[key], d2[key], d3[key], **kwargs)\n",
        "\n",
        "    return dict_final"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QhzigaGI8X_g"
      },
      "outputs": [],
      "source": [
        "# Raw Variables for Overall Expressivity!\n",
        "\n",
        "#openface_oe_raw = apply_function_to_dict_three(openface_emoHardSoftPres, openface_lowerHardSoftPres, openface_upperHardSoftPres, compute_oe_raw_vars)\n",
        "#opengraphau_oe_raw = apply_function_to_dict_three(opengraphau_emoHardSoftPres, opengraphau_lowerHardSoftPres, opengraphau_upperHardSoftPres, compute_oe_raw_vars)\n",
        "\n",
        "\n",
        "openface_oe_raw_dict = {}\n",
        "\n",
        "\n",
        "# Loop through the dictionaries and sample one item from each with the same key\n",
        "for key in openface_emoHardSoftPres_dict.keys():\n",
        "    openface_emo = openface_emoHardSoftPres_dict[key]\n",
        "    openface_lower = openface_lowerHardSoftPres_dict[key]\n",
        "    openface_upper = openface_upperHardSoftPres_dict[key]\n",
        "\n",
        "    # Call the compute_oe_raw_vars function with the sampled items\n",
        "    openface_oe_raw_dict[key] = apply_function_to_dict_three(openface_emo, openface_lower, openface_upper, compute_oe_raw_vars)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Can't do this anymore! Probabilities are NOT intensities!\n",
        "\n",
        "opengraphau_oe_raw_dict = {}\n",
        "\n",
        "for key in opengraphau_emoHardSoftPres_dict.keys():\n",
        "    opengraphau_emo = opengraphau_emoHardSoftPres_dict[key]\n",
        "    opengraphau_lower = opengraphau_lowerHardSoftPres_dict[key]\n",
        "    opengraphau_upper = opengraphau_upperHardSoftPres_dict[key]\n",
        "\n",
        "    # Call the compute_oe_raw_vars function with the sampled items\n",
        "    opengraphau_oe_raw_dict[key] = apply_function_to_dict_three(opengraphau_emo, opengraphau_lower, opengraphau_upper, compute_oe_raw_vars)"
      ],
      "metadata": {
        "id": "XFZd82J0B1pt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QdGvPot19i4K"
      },
      "outputs": [],
      "source": [
        "openface_oe_raw_dict['60'][get_moodTracking_datetime(1)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ig8iYi3v_KxG"
      },
      "outputs": [],
      "source": [
        "def calculate_oe_summary_statistics(df):\n",
        "    # Compute comintsoft_pct\n",
        "    comintsoft_pct = (df['comintsoft'] > 0).mean() * 100\n",
        "\n",
        "    # Compute comintsoft_mean and comintsoft_std\n",
        "    comintsoft_mean = df['comintsoft'].mean()\n",
        "    comintsoft_std = df['comintsoft'].std()\n",
        "\n",
        "    # Compute cominthard_mean and cominthard_std\n",
        "    cominthard_mean = df['cominthard'].mean()\n",
        "    cominthard_std = df['cominthard'].std()\n",
        "\n",
        "    # Compute comlowintsoft_pct\n",
        "    comlowintsoft_pct = (df['comlowintsoft'] > 0).mean() * 100\n",
        "\n",
        "    # Compute comlowintsoft_mean and comlowintsoft_std\n",
        "    comlowintsoft_mean = df['comlowintsoft'].mean()\n",
        "    comlowintsoft_std = df['comlowintsoft'].std()\n",
        "\n",
        "    # Compute comuppinthard_mean and comuppinthard_std\n",
        "    comuppinthard_mean = df['comuppinthard'].mean()\n",
        "    comuppinthard_std = df['comuppinthard'].std()\n",
        "\n",
        "    # Create a new DataFrame with the summary statistics\n",
        "    summary_df = pd.DataFrame({\n",
        "        'comintsoft_pct': [comintsoft_pct],\n",
        "        'comintsoft_mean': [comintsoft_mean],\n",
        "        'comintsoft_std': [comintsoft_std],\n",
        "        'cominthard_mean': [cominthard_mean],\n",
        "        'cominthard_std': [cominthard_std],\n",
        "        'comlowintsoft_pct': [comlowintsoft_pct],\n",
        "        'comlowintsoft_mean': [comlowintsoft_mean],\n",
        "        'comlowintsoft_std': [comlowintsoft_std],\n",
        "        'comuppinthard_mean': [comuppinthard_mean],\n",
        "        'comuppinthard_std': [comuppinthard_std]\n",
        "    })\n",
        "\n",
        "    return summary_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zOTxb6GJBWfs"
      },
      "outputs": [],
      "source": [
        "# Derived Variables for Overall Expressivity!\n",
        "\n",
        "openface_oe_derived_dict = {}\n",
        "\n",
        "for time_radius, openface_oe_raw_now in openface_oe_raw_dict.items():\n",
        "  openface_oe_derived_dict[time_radius] = apply_function_to_dict(openface_oe_raw_now, calculate_oe_summary_statistics)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Can't do this anymore since probabilities are not intensities!\n",
        "\n",
        "opengraphau_oe_derived_dict = {}\n",
        "\n",
        "for time_radius, opengraphau_oe_raw_now in opengraphau_oe_raw_dict.items():\n",
        "  opengraphau_oe_derived_dict[time_radius] = apply_function_to_dict(opengraphau_oe_raw_now, calculate_oe_summary_statistics)\n"
      ],
      "metadata": {
        "id": "jETLTmXEB-8t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S7LKJPZyCFNx"
      },
      "outputs": [],
      "source": [
        "openface_oe_derived_dict['60'][get_moodTracking_datetime(1)]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZkWAvj5BQrmC"
      },
      "source": [
        "# Feature Extraction 2.0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qUF7aUsFee6l"
      },
      "source": [
        "## Convert AU to Emotion"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_emotions(df, threshold=0.6):\n",
        "    # Make a copy of the DataFrame\n",
        "    new_df = df.copy()\n",
        "\n",
        "    # Calculate emotion scores using vectorized operations\n",
        "    if EMO_FEATURE_SETTING == 0:\n",
        "\n",
        "        new_df['Pain_Raw'] = (new_df['AU4'] + np.maximum(new_df['AU6'], new_df['AU7']) + np.maximum(new_df['AU9'], new_df['AU10']) + np.maximum(new_df['AU25'], new_df['AU26'], new_df['AU27'])) / 4\n",
        "        new_df['Happy_Raw'] = (new_df['AU6'] + np.maximum(new_df['AU12'], new_df['AU13'], new_df['AU14']) + new_df['AU25']) / 3\n",
        "        new_df['Sad_Raw'] = (np.maximum(new_df['AU1'], new_df['AU4']) + np.maximum(new_df['AU15'], new_df['AU17'])) / 2\n",
        "        new_df['Anger_Raw'] = (np.maximum(new_df['AU9'], new_df['AU10']) + new_df['AU16'] + new_df['AU22']) / 3\n",
        "        new_df['Disgust_Raw'] = (np.maximum(new_df['AU9'], new_df['AU10']) + new_df['AU15'] + new_df['AU16']) / 3\n",
        "        new_df['Fear_Raw'] = (new_df['AU4'] + new_df['AU5'] + new_df['AU20']) / 3\n",
        "        new_df['Surprise_Raw'] = (new_df['AU1'] + new_df['AU2'] + new_df['AU5'] + np.maximum(new_df['AU26'], new_df['AU27'])) / 4\n",
        "        new_df['Amusement_Raw'] = (new_df['AU6'] + new_df['AU7'] + new_df['AU12'] + new_df['AU16'] + np.maximum(new_df['AU26'], new_df['AU27'])) / 5\n",
        "        new_df['Contempt_Raw'] = (new_df['AU12'] + new_df['AU14']) / 2\n",
        "        new_df['Awe_Raw'] = (new_df['AU1'] + new_df['AU2'] + np.maximum(new_df['AU4'], new_df['AU5']) + new_df['AU20'] + np.maximum(new_df['AU25'], new_df['AU26'])) / 5\n",
        "        new_df['Embarrassment_Raw'] = (new_df['AU1'] + new_df['AU2'] + new_df['AU4'] + new_df['AU5'] + new_df['AU7'] + new_df['AU20'] + np.maximum(new_df['AU25'], new_df['AU26'])) / 7\n",
        "        new_df['Interest_Raw'] = (new_df['AU1'] + new_df['AU2'] + new_df['AU12']) / 3\n",
        "        new_df['Desire_Raw'] = (np.maximum(new_df['AU6'], new_df['AU7']) + new_df['AU12'] + new_df['AU25']) / 3\n",
        "\n",
        "    elif EMO_FEATURE_SETTING == 1:\n",
        "        new_df['Happy_Raw'] = (new_df['AU6'] + np.maximum(new_df['AU12'], new_df['AU13'], new_df['AU14']) + new_df['AU25']) / 3\n",
        "        new_df['Sad_Raw'] = (np.maximum(new_df['AU1'], new_df['AU4']) + np.maximum(new_df['AU15'], new_df['AU17'])) / 2\n",
        "        new_df['Anger_Raw'] = (np.maximum(new_df['AU9'], new_df['AU10']) + new_df['AU16'] + new_df['AU22']) / 3\n",
        "        new_df['Disgust_Raw'] = (np.maximum(new_df['AU9'], new_df['AU10']) + new_df['AU15'] + new_df['AU16']) / 3\n",
        "        new_df['Fear_Raw'] = (new_df['AU4'] + new_df['AU5'] + new_df['AU20']) / 3\n",
        "        new_df['Surprise_Raw'] = (new_df['AU1'] + new_df['AU2'] + new_df['AU5'] + np.maximum(new_df['AU26'], new_df['AU27'])) / 4\n",
        "        new_df['Contempt_Raw'] = (new_df['AU12'] + new_df['AU14']) / 2\n",
        "\n",
        "    elif EMO_FEATURE_SETTING == 2:\n",
        "        new_df['Happy_Raw'] = (new_df['AU6'] + new_df['AU12']) / 2\n",
        "        new_df['Sad_Raw'] = (new_df['AU1'] + new_df['AU4'] + new_df['AU15']) / 3\n",
        "        new_df['Anger_Raw'] = (new_df['AU4'] + new_df['AU5'] + new_df['AU7'] + new_df['AU23']) / 4\n",
        "        new_df['Disgust_Raw'] = (new_df['AU9'] + new_df['AU15'] + new_df['AU16']) / 3\n",
        "        new_df['Fear_Raw'] = (new_df['AU1'] + new_df['AU2'] + new_df['AU4'] + new_df['AU5'] + new_df['AU7'] + new_df['AU20'] + new_df['AU26']) / 7\n",
        "        new_df['Surprise_Raw'] = (new_df['AU1'] + new_df['AU2'] + new_df['AU5'] + new_df['AU26']) / 4\n",
        "        new_df['Contempt_Raw'] = (new_df['AU12'] + new_df['AU14']) / 2\n",
        "\n",
        "\n",
        "    # Calculate binary values\n",
        "    emotion_cols = [col for col in new_df.columns if col.endswith('_Raw')]\n",
        "    for col in emotion_cols:\n",
        "        binary_col = col.replace('_Raw', '_Binary')\n",
        "        new_df[binary_col] = (new_df[col] >= threshold).astype(int)\n",
        "\n",
        "    # Drop AU columns\n",
        "    au_columns = [col for col in new_df.columns if col.startswith('AU')]\n",
        "    new_df.drop(columns=au_columns, inplace=True)\n",
        "\n",
        "    # Filter out frames where success = 0\n",
        "    new_df = new_df[new_df['success'] == 1]\n",
        "\n",
        "    return new_df"
      ],
      "metadata": {
        "id": "4n-e0NJLI7Xw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rM5I8kJdee6x"
      },
      "outputs": [],
      "source": [
        "# Raw Variables for Emotional Expressivity!\n",
        "\n",
        "openface_emo_dict = {}\n",
        "\n",
        "for time_radius, openface_radius_now in openface_radius_dict.items():\n",
        "  print('Time Radius: ', time_radius)\n",
        "  if NORMALIZE_DATA == 0:\n",
        "    THRESHOLD = 0.5\n",
        "  elif NORMALIZE_DATA == 1:\n",
        "    THRESHOLD = 2.5\n",
        "  openface_emo_dict[time_radius] = apply_function_to_dict(openface_radius_now, compute_emotions, threshold=THRESHOLD)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save variable\n",
        "\n",
        "save_var(openface_emo_dict, forced_name=f'openface_emo_dict_{PAT_SHORT_NAME}')"
      ],
      "metadata": {
        "id": "-UVrGCK3qWDh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load variable\n",
        "\n",
        "openface_emo_dict = load_var(f'openface_emo_dict_{PAT_SHORT_NAME}')"
      ],
      "metadata": {
        "id": "g92WbG0GqWGT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "opengraphau_emo_dict = {}\n",
        "\n",
        "for time_radius, opengraphau_radius_now in opengraphau_radius_dict.items():\n",
        "  print('Time Radius: ', time_radius)\n",
        "  if NORMALIZE_DATA == 0:\n",
        "    THRESHOLD = 0.4\n",
        "  elif NORMALIZE_DATA == 1:\n",
        "    THRESHOLD = 2.5\n",
        "  opengraphau_emo_dict[time_radius] = apply_function_to_dict(opengraphau_radius_now, compute_emotions, threshold=THRESHOLD)\n"
      ],
      "metadata": {
        "id": "Mcn5YgICee6y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gneOt-s3QrmF"
      },
      "source": [
        "## Emotion Processing Core"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FGCl95VtQrmF"
      },
      "outputs": [],
      "source": [
        "from scipy.stats import skew, kurtosis\n",
        "from statsmodels.tsa.stattools import acf\n",
        "\n",
        "def binarize_cols(df, threshold=0.5):\n",
        "  new_df = df.copy()\n",
        "  emotions = [col for col in new_df.columns if col not in ['frame', 'success', 'timestamp']]\n",
        "\n",
        "  for emotion in emotions:\n",
        "      new_df[f'{emotion}_Raw'] = new_df[emotion]\n",
        "      new_df[f'{emotion}_Binary'] = (new_df[f'{emotion}_Raw'] >= threshold).astype(int)\n",
        "\n",
        "  new_df = new_df.drop(columns=emotions, inplace=False)\n",
        "\n",
        "  return new_df\n",
        "\n",
        "\n",
        "def fill_empty_dfs(dictionary):\n",
        "  # when we do emotion processing, some dfs will have ZERO successful frames,\n",
        "  # leading to ZERO events, and an empty df.\n",
        "  # we need to fill the empty dfs with a df with all 0s\n",
        "\n",
        "  non_empty_dfs = [df for df in dictionary.values() if not df.empty]\n",
        "\n",
        "  if not non_empty_dfs:\n",
        "      return dictionary  # Return the original dictionary if all DataFrames are empty\n",
        "\n",
        "  non_empty_df = non_empty_dfs[0]  # Choose the first non-empty DataFrame as replacement\n",
        "\n",
        "  modified_dictionary = {}\n",
        "  for key, df in dictionary.items():\n",
        "      if df.empty:\n",
        "          modified_df = pd.DataFrame(0, index=non_empty_df.index, columns=non_empty_df.columns)\n",
        "          # Preserve string columns from non-empty DataFrame\n",
        "          for column in non_empty_df.columns:\n",
        "              if non_empty_df[column].dtype == object:\n",
        "                  modified_df[column] = non_empty_df[column]\n",
        "      else:\n",
        "          modified_df = df.copy()\n",
        "\n",
        "      modified_dictionary[key] = modified_df\n",
        "\n",
        "  return modified_dictionary\n",
        "\n",
        "def analyze_emotion_events_v2(df, max_frame_gap=10, event_minimum_num_frames=1, method='HSE'):\n",
        "    # Emotions to analyze\n",
        "    emotions_raw = [col for col in df.columns if col not in ['frame', 'success', 'timestamp']]\n",
        "    # Removing \"_Raw\" or \"_Binary\" from each string\n",
        "    processed_strings = [s.replace(\"_Raw\", \"\").replace(\"_Binary\", \"\") for s in emotions_raw]\n",
        "    # Eliminating duplicates\n",
        "    emotions = list(set(processed_strings))\n",
        "\n",
        "    # Create DataFrame for results\n",
        "    if STATS_FEATURE_SETTING == 0:\n",
        "        results_df = pd.DataFrame(index=['avg_event_length', 'avg_event_duration', 'total_num_events', 'avg_probability', 'std', 'skewness', 'kurtosis', 'autocorrelation', 'pres_pct'])\n",
        "    elif STATS_FEATURE_SETTING == 1 or (STATS_FEATURE_SETTING == 3 and method == 'HSE'):\n",
        "        results_df = pd.DataFrame(index=['avg_event_length', 'total_num_events', 'avg_probability', 'std', 'pres_pct'])\n",
        "    elif STATS_FEATURE_SETTING == 2:\n",
        "        results_df = pd.DataFrame(index=['pres_pct'])\n",
        "    elif STATS_FEATURE_SETTING == 3 and (method == 'OGAU' or method=='OF'):\n",
        "        results_df = pd.DataFrame(index=['pres_pct', 'total_num_events'])\n",
        "\n",
        "\n",
        "    def detect_events(emotion_binary_col):\n",
        "        probThreshold = 0.5 # irrelevant because it's a binary column\n",
        "        minInterval = max_frame_gap\n",
        "        minDuration = event_minimum_num_frames\n",
        "\n",
        "        probBinary = emotion_binary_col > probThreshold\n",
        "\n",
        "        # Using np.diff to find changes in the binary array\n",
        "        changes = np.diff(probBinary.astype(int))\n",
        "\n",
        "        # Identify start (1) and stop (-1) points\n",
        "        starts = np.where(changes == 1)[0] + 1  # +1 to correct the index shift caused by diff\n",
        "        stops = np.where(changes == -1)[0] + 1\n",
        "\n",
        "        # Adjust for edge cases\n",
        "        if probBinary.iloc[0]:\n",
        "            starts = np.insert(starts, 0, 0)\n",
        "        if probBinary.iloc[-1]:\n",
        "            stops = np.append(stops, len(probBinary))\n",
        "\n",
        "        # Merge close events and filter by duration\n",
        "        events = []\n",
        "        for start, stop in zip(starts, stops):\n",
        "\n",
        "            # Construct the event considering only indices where probBinary is 1\n",
        "            event = np.arange(start, stop)[probBinary[start:stop].values]\n",
        "\n",
        "            # Check if there is a previous event to potentially merge with\n",
        "            if events and event.size > 0 and events[-1][-1] >= start - minInterval:\n",
        "                # Merge with the previous event\n",
        "                events[-1] = np.unique(np.concatenate([events[-1], event]))\n",
        "            elif event.size >= event_minimum_num_frames:\n",
        "                events.append(event)\n",
        "\n",
        "        # Filter events by minimum duration\n",
        "        valid_events = [event for event in events if len(event) >= minDuration]\n",
        "\n",
        "        return valid_events\n",
        "\n",
        "    for emotion in emotions:\n",
        "        # Identify events\n",
        "        emotion_binary_col = df[f'{emotion}_Binary']\n",
        "        emotion_presence = df[f'{emotion}_Binary'].sum()\n",
        "        pres_pct = emotion_presence / len(df) * 100  # Percentage of frames where emotion is present\n",
        "        events = detect_events(emotion_binary_col)\n",
        "\n",
        "        if not(STATS_FEATURE_SETTING == 2):\n",
        "            # Calculate features for each event\n",
        "            if events:\n",
        "                event_lengths = [len(event) for event in events]\n",
        "                event_durations = [event[-1] - event[0] + 1 for event in events]\n",
        "                probabilities = [df.loc[event, f'{emotion}_Raw'].values for event in events]\n",
        "                probabilities_flattened = np.concatenate(probabilities)\n",
        "\n",
        "                avg_event_length = np.mean(event_lengths)\n",
        "                avg_event_duration = np.mean(event_durations)\n",
        "                total_num_events = len(events)\n",
        "                avg_probability = np.mean(probabilities_flattened)\n",
        "                std_dev = np.std(probabilities_flattened)\n",
        "                skewness_val = skew(probabilities_flattened)\n",
        "                kurtosis_val = kurtosis(probabilities_flattened)\n",
        "                autocorr = acf(probabilities_flattened, fft=True, nlags=1)[1] if len(probabilities_flattened) > 1 else 0\n",
        "            else:\n",
        "                avg_event_length = 0\n",
        "                avg_event_duration = 0\n",
        "                total_num_events = 0\n",
        "                avg_probability = 0\n",
        "                std_dev = 0\n",
        "                skewness_val = 0\n",
        "                kurtosis_val = 0\n",
        "                autocorr = 0\n",
        "\n",
        "        # Add results to the DataFrame\n",
        "        if STATS_FEATURE_SETTING == 0:\n",
        "            results_df[emotion] = [avg_event_length, avg_event_duration, total_num_events, avg_probability, std_dev, skewness_val, kurtosis_val, autocorr, pres_pct]\n",
        "        elif STATS_FEATURE_SETTING == 1 or (STATS_FEATURE_SETTING == 3 and method == 'HSE'):\n",
        "            results_df[emotion] = [avg_event_length, total_num_events, avg_probability, std_dev, pres_pct]\n",
        "        elif STATS_FEATURE_SETTING == 2:\n",
        "            results_df[emotion] = [pres_pct]\n",
        "        elif STATS_FEATURE_SETTING == 3 and (method == 'OGAU' or method=='OF'):\n",
        "            results_df[emotion] = [pres_pct, total_num_events]\n",
        "\n",
        "    # Replace NaN values with 0\n",
        "    results_df.fillna(0, inplace=True)\n",
        "\n",
        "    return results_df\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4EU7WhJIQrmG"
      },
      "outputs": [],
      "source": [
        "# dictionary to store results from each different time window we test!\n",
        "hsemotion_emo_stats_dict = {}\n",
        "\n",
        "for time_radius, hsemotion_radius_now in hsemotion_radius_dict.items():\n",
        "  print('Time Radius: ', time_radius)\n",
        "  if NORMALIZE_DATA == 0:\n",
        "    THRESHOLD = 0.4\n",
        "  elif NORMALIZE_DATA == 1:\n",
        "    THRESHOLD = 2.5\n",
        "  hsemotion_radius_binarized = apply_function_to_dict(hsemotion_radius_now, binarize_cols, threshold=THRESHOLD)\n",
        "  hsemotion_emo_stats = apply_function_to_dict(hsemotion_radius_binarized, analyze_emotion_events_v2, max_frame_gap=10, event_minimum_num_frames=12, method='HSE')\n",
        "  hsemotion_emo_stats_fixed = fill_empty_dfs(hsemotion_emo_stats)\n",
        "  hsemotion_emo_stats_dict[time_radius] = hsemotion_emo_stats_fixed"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save variable\n",
        "\n",
        "save_var(hsemotion_emo_stats_dict, forced_name=f'hsemotion_emo_stats_dict_{PAT_SHORT_NAME}')"
      ],
      "metadata": {
        "id": "prcQtTFdQrmG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load variable\n",
        "\n",
        "hsemotion_emo_stats_dict = load_var(f'hsemotion_emo_stats_dict_{PAT_SHORT_NAME}')"
      ],
      "metadata": {
        "id": "YfbRyuFnfpAD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5bmzxikXet1j"
      },
      "outputs": [],
      "source": [
        "# OPENGRAPHAU EMOTION EVENTS\n",
        "\n",
        "# dictionary to store results from each different time window we test!\n",
        "opengraphau_emo_stats_dict = {}\n",
        "\n",
        "for time_radius, opengraphau_radius_now in opengraphau_emo_dict.items():\n",
        "  print('Time Radius: ', time_radius)\n",
        "  opengraphau_emo_stats = apply_function_to_dict(opengraphau_radius_now, analyze_emotion_events_v2, max_frame_gap=10, event_minimum_num_frames=12, method='OGAU')\n",
        "  opengraphau_emo_stats_fixed = fill_empty_dfs(opengraphau_emo_stats)\n",
        "  opengraphau_emo_stats_dict[time_radius] = opengraphau_emo_stats_fixed\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X2tanh4Get1k"
      },
      "outputs": [],
      "source": [
        "# SAVE opengraphau_emo_stats_dict\n",
        "\n",
        "save_var(opengraphau_emo_stats_dict, forced_name=f'opengraphau_emo_stats_dict_{PAT_SHORT_NAME}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mTI7bJ_Qet1k"
      },
      "outputs": [],
      "source": [
        "# LOAD opengraphau_emo_stats_dict\n",
        "\n",
        "opengraphau_emo_stats_dict = load_var(f'opengraphau_emo_stats_dict_{PAT_SHORT_NAME}')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# OPENGRAPHAU AU EVENTS\n",
        "\n",
        "# dictionary to store results from each different time window we test!\n",
        "opengraphau_au_events_stats_dict = {}\n",
        "\n",
        "for time_radius, opengraphau_radius_now in opengraphau_radius_dict.items():\n",
        "  print('Time Radius: ', time_radius)\n",
        "  opengraphau_radius_binarized = apply_function_to_dict(opengraphau_radius_now, binarize_cols, threshold=THRESHOLD)\n",
        "  opengraphau_au_events_stats = apply_function_to_dict(opengraphau_radius_binarized, analyze_emotion_events_v2, max_frame_gap=10, event_minimum_num_frames=12, method='OGAU')\n",
        "  opengraphau_au_events_stats_fixed = fill_empty_dfs(opengraphau_au_events_stats)\n",
        "  opengraphau_au_events_stats_dict[time_radius] = opengraphau_au_events_stats_fixed\n"
      ],
      "metadata": {
        "id": "4lx43Ki9MAI0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# SAVE opengraphau_au_events_stats_dict\n",
        "\n",
        "save_var(opengraphau_au_events_stats_dict, forced_name=f'opengraphau_au_events_stats_dict_{PAT_SHORT_NAME}')"
      ],
      "metadata": {
        "id": "PYusdazZWwuz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# LOAD opengraphau_au_events_stats_dict\n",
        "\n",
        "opengraphau_au_events_stats_dict = load_var(f'opengraphau_au_events_stats_dict_{PAT_SHORT_NAME}')"
      ],
      "metadata": {
        "id": "6zvRjzcDWwzr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# OPENFACE\n",
        "\n",
        "# dictionary to store results from each different time window we test!\n",
        "openface_emo_stats_dict = {}\n",
        "\n",
        "for time_radius, openface_radius_now in openface_emo_dict.items():\n",
        "  print('Time Radius: ', time_radius)\n",
        "  openface_emo_stats = apply_function_to_dict(openface_radius_now, analyze_emotion_events_v2, max_frame_gap=10, event_minimum_num_frames=12, method='OF')\n",
        "  openface_emo_stats_fixed = fill_empty_dfs(openface_emo_stats)\n",
        "  openface_emo_stats_dict[time_radius] = openface_emo_stats_fixed\n"
      ],
      "metadata": {
        "id": "9DJxcuE4hhMv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# SAVE openface_emo_stats_dict\n",
        "\n",
        "save_var(openface_emo_stats_dict, forced_name=f'openface_emo_stats_dict_{PAT_SHORT_NAME}')"
      ],
      "metadata": {
        "id": "esj1ebUAhhPJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# LOAD openface_emo_stats_dict\n",
        "\n",
        "openface_emo_stats_dict = load_var(f'openface_emo_stats_dict_{PAT_SHORT_NAME}')"
      ],
      "metadata": {
        "id": "bHwbEbVahhRT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p_sFEy1JQrmL"
      },
      "source": [
        "## Action Units"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from scipy.stats import kurtosis, skew\n",
        "from statsmodels.tsa.stattools import acf\n",
        "\n",
        "def calculate_AU_statistics(df):\n",
        "    # Initialize an empty dictionary to store the computed statistics\n",
        "\n",
        "    if STATS_FEATURE_SETTING == 0:\n",
        "        stats = {\n",
        "            'AU': [],\n",
        "            'pres_pct': [],\n",
        "            'mean': [],\n",
        "            'variance': [],\n",
        "            'kurtosis': [],\n",
        "            'median': [],\n",
        "            'skewness': [],\n",
        "            'autocorrelation': []\n",
        "        }\n",
        "    elif STATS_FEATURE_SETTING == 1 or STATS_FEATURE_SETTING == 3:\n",
        "        stats = {\n",
        "            'AU': [],\n",
        "            'pres_pct': [],\n",
        "            'mean': [],\n",
        "            'variance': [],\n",
        "            'median': []\n",
        "        }\n",
        "    elif STATS_FEATURE_SETTING == 2:\n",
        "        stats = {\n",
        "            'AU': [],\n",
        "            'pres_pct': []\n",
        "        }\n",
        "\n",
        "    # Iterate over the AU columns\n",
        "    au_cols = [col for col in df.columns if col not in ['success', 'frame', 'timestamp'] and '_Binary' in col]\n",
        "    for col in au_cols:\n",
        "\n",
        "        # Filter to frames where AU is present\n",
        "        present_df = df[df[col] == 1]\n",
        "\n",
        "        # Calculate the percentage of frames where AU is present\n",
        "        pres_pct = present_df.shape[0] / df.shape[0] * 100\n",
        "\n",
        "        # Calculate statistics for the intensity where AU is present\n",
        "        if STATS_FEATURE_SETTING < 3:\n",
        "          intensity_col = f\"{col.split('_')[0]}_Raw\"\n",
        "          mean_intensity = present_df[intensity_col].mean()\n",
        "          variance_intensity = present_df[intensity_col].var()\n",
        "          kurtosis_intensity = kurtosis(present_df[intensity_col], nan_policy='omit')\n",
        "          median_intensity = present_df[intensity_col].median()\n",
        "          skewness_intensity = skew(present_df[intensity_col], nan_policy='omit')\n",
        "          autocorr_intensity = acf(present_df[intensity_col], fft=True, nlags=1)[1] if len(present_df) > 1 else 0\n",
        "        else:\n",
        "          intensity_col = f\"{col.split('_')[0]}_Raw\"\n",
        "          mean_intensity = df[intensity_col].mean()\n",
        "          variance_intensity = df[intensity_col].var()\n",
        "          kurtosis_intensity = kurtosis(df[intensity_col], nan_policy='omit')\n",
        "          median_intensity = df[intensity_col].median()\n",
        "          skewness_intensity = skew(df[intensity_col], nan_policy='omit')\n",
        "          autocorr_intensity = acf(df[intensity_col], fft=True, nlags=1)[1] if len(df) > 1 else 0\n",
        "\n",
        "\n",
        "        # Extract the AU number\n",
        "        AU = int(col.split('_')[0][2:])\n",
        "\n",
        "        # Add the statistics to the dictionary\n",
        "        if STATS_FEATURE_SETTING == 0:\n",
        "            stats['kurtosis'].append(kurtosis_intensity)\n",
        "            stats['skewness'].append(skewness_intensity)\n",
        "            stats['autocorrelation'].append(autocorr_intensity)\n",
        "            stats['AU'].append(AU)\n",
        "            stats['pres_pct'].append(pres_pct)\n",
        "            stats['mean'].append(mean_intensity)\n",
        "            stats['variance'].append(variance_intensity)\n",
        "            stats['median'].append(median_intensity)\n",
        "        elif STATS_FEATURE_SETTING == 1 or STATS_FEATURE_SETTING == 3:\n",
        "            stats['AU'].append(AU)\n",
        "            stats['pres_pct'].append(pres_pct)\n",
        "            stats['mean'].append(mean_intensity)\n",
        "            stats['variance'].append(variance_intensity)\n",
        "            stats['median'].append(median_intensity)\n",
        "        elif STATS_FEATURE_SETTING == 2:\n",
        "            stats['AU'].append(AU)\n",
        "            stats['pres_pct'].append(pres_pct)\n",
        "\n",
        "    # Create a DataFrame from the dictionary of statistics\n",
        "    stats_df = pd.DataFrame(stats)\n",
        "\n",
        "    # Replace NaN values with 0\n",
        "    stats_df.fillna(0, inplace=True)\n",
        "\n",
        "    return stats_df"
      ],
      "metadata": {
        "id": "Z44gNcWWkQfh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ThSTg4LMQrmM"
      },
      "outputs": [],
      "source": [
        "# OPENFACE\n",
        "\n",
        "openface_au_derived_dict = {}\n",
        "\n",
        "for time_radius, openface_radius_now in openface_radius_dict.items():\n",
        "  print('Time Radius: ', time_radius)\n",
        "  if NORMALIZE_DATA == 0:\n",
        "    THRESHOLD = 0.4\n",
        "  elif NORMALIZE_DATA == 1:\n",
        "    THRESHOLD = 2.5\n",
        "  openface_au_binarized = apply_function_to_dict(openface_radius_now, binarize_cols, threshold=THRESHOLD)\n",
        "  openface_au_derived_dict[time_radius] = apply_function_to_dict(openface_au_binarized, calculate_AU_statistics)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# OPENGRAPHAU\n",
        "\n",
        "opengraphau_au_derived_dict = {}\n",
        "\n",
        "for time_radius, opengraphau_radius_now in opengraphau_radius_dict.items():\n",
        "  print('Time Radius: ', time_radius)\n",
        "  if NORMALIZE_DATA == 0:\n",
        "    THRESHOLD = 0.4\n",
        "  elif NORMALIZE_DATA == 1:\n",
        "    THRESHOLD = 2.5\n",
        "  opengraphau_au_binarized = apply_function_to_dict(opengraphau_radius_now, binarize_cols, threshold=THRESHOLD)\n",
        "  opengraphau_au_derived_dict[time_radius] = apply_function_to_dict(opengraphau_au_binarized, calculate_AU_statistics)"
      ],
      "metadata": {
        "id": "BsyVywHlQrmM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pkcRVBK7CZaJ"
      },
      "source": [
        "# Make Vectors for Each Timestamp"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SFkY8uARYsGL"
      },
      "source": [
        "## Vectors for AU and emotion classifiers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1afeC95tCzgK"
      },
      "outputs": [],
      "source": [
        "## Dictionary of list of relevant dictionaries\n",
        "openface_dict_list_dict = {}\n",
        "\n",
        "for key in openface_au_derived_dict.keys():\n",
        "  openface_dict_list_dict[key] = [openface_au_derived_dict[key], openface_emo_stats_dict[key], openface_ee_derived_dict[key], openface_oe_derived_dict[key]]\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "opengraphau_dict_list_dict = {}\n",
        "\n",
        "for key in opengraphau_au_events_stats_dict.keys():\n",
        "  #opengraphau_dict_list_dict[key] = [opengraphau_au_derived_dict[key], opengraphau_ee_derived_dict[key]]\n",
        "  opengraphau_dict_list_dict[key] = [opengraphau_au_events_stats_dict[key]]\n"
      ],
      "metadata": {
        "id": "xa9VoJpoIz1A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "hsemotion_dict_list_dict = {}\n",
        "\n",
        "for key in hsemotion_emo_stats_dict.keys():\n",
        "  hsemotion_dict_list_dict[key] = [hsemotion_emo_stats_dict[key]]\n",
        "  #hsemotion_dict_list_dict[key] = [hsemotion_emo_stats_dict[key], hsemotion_ee_derived_dict[key]]"
      ],
      "metadata": {
        "id": "eG7PC1CcGoRp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def partial_combine_dictionaries(dict1, dict2):\n",
        "    # Takes element one (i.e. the AU matrix) from dict1, and all of dict2 (i.e. HSEmotion)\n",
        "    combined_dict = {}\n",
        "\n",
        "    for key in dict1:\n",
        "        combined_dict[key] = [dict1[key][0]] + dict2[key]\n",
        "\n",
        "    return combined_dict\n",
        "\n",
        "def full_combine_dictionaries(dict_list):\n",
        "    combined_dict = {}\n",
        "\n",
        "    for key in dict_list[0]:\n",
        "        combined_dict[key] = []\n",
        "        for j in dict_list:\n",
        "          combined_dict[key] = combined_dict[key] + j[key]\n",
        "\n",
        "    return combined_dict"
      ],
      "metadata": {
        "id": "w4DmMSlLa_GC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#ofauhsemotion_dict_list_dict = partial_combine_dictionaries(openface_dict_list_dict, hsemotion_dict_list_dict)\n",
        "\n",
        "ogauhsemotion_dict_list_dict = partial_combine_dictionaries(opengraphau_dict_list_dict, hsemotion_dict_list_dict)\n"
      ],
      "metadata": {
        "id": "1GNy0xOKbEBj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "all_dict_list_dict = full_combine_dictionaries([openface_dict_list_dict, opengraphau_dict_list_dict, hsemotion_dict_list_dict])"
      ],
      "metadata": {
        "id": "k53vTvAQcMAf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# SAVE VARIABLES - EMOTION & AFFECT\n",
        "\n",
        "save_var(openface_dict_list_dict, forced_name=f'openface_dict_list_dict_{PAT_SHORT_NAME}')\n",
        "\n",
        "save_var(opengraphau_dict_list_dict, forced_name=f'opengraphau_dict_list_dict_{PAT_SHORT_NAME}')\n",
        "\n",
        "save_var(hsemotion_dict_list_dict, forced_name=f'hsemotion_dict_list_dict_{PAT_SHORT_NAME}')"
      ],
      "metadata": {
        "id": "ZRuy_1Y9JAqd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# SAVE VARIABLES - EMOTION & AFFECT\n",
        "# NEW FEATURES\n",
        "\n",
        "#save_var(openface_dict_list_dict, forced_name=f'openface_dict_list_dict_f2_{PAT_SHORT_NAME}')\n",
        "\n",
        "save_var(opengraphau_dict_list_dict, forced_name=f'opengraphau_dict_list_dict_f2_{PAT_SHORT_NAME}')\n",
        "\n",
        "save_var(hsemotion_dict_list_dict, forced_name=f'hsemotion_dict_list_dict_f2_{PAT_SHORT_NAME}')"
      ],
      "metadata": {
        "id": "5DXzgTaPrH2P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# SAVE VARIABLES - EMOTION & AFFECT\n",
        "\n",
        "save_var(ofauhsemotion_dict_list_dict, forced_name=f'ofauhsemotion_dict_list_dict_{PAT_SHORT_NAME}')\n",
        "\n",
        "save_var(ogauhsemotion_dict_list_dict, forced_name=f'ogauhsemotion_dict_list_dict_{PAT_SHORT_NAME}')\n",
        "\n",
        "save_var(all_dict_list_dict, forced_name=f'all_dict_list_dict_{PAT_SHORT_NAME}')"
      ],
      "metadata": {
        "id": "gASR49RVbmwj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xmHYCC9OBxzq"
      },
      "outputs": [],
      "source": [
        "# LOAD VARIABLES - EMOTION & AFFECT\n",
        "\n",
        "openface_dict_list_dict = load_var(f'openface_dict_list_dict_{PAT_SHORT_NAME}')\n",
        "\n",
        "opengraphau_dict_list_dict = load_var(f'opengraphau_dict_list_dict_{PAT_SHORT_NAME}')\n",
        "\n",
        "hsemotion_dict_list_dict = load_var(f'hsemotion_dict_list_dict_{PAT_SHORT_NAME}')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# LOAD VARIABLES - EMOTION & AFFECT\n",
        "# NEW FEATURES\n",
        "\n",
        "openface_dict_list_dict = load_var(f'openface_dict_list_dict_f2_{PAT_SHORT_NAME}')\n",
        "\n",
        "opengraphau_dict_list_dict = load_var(f'opengraphau_dict_list_dict_f2_{PAT_SHORT_NAME}')\n",
        "\n",
        "hsemotion_dict_list_dict = load_var(f'hsemotion_dict_list_dict_f2_{PAT_SHORT_NAME}')"
      ],
      "metadata": {
        "id": "OXBvDJO8rMaH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# LOAD VARIABLES - EMOTION & AFFECT\n",
        "\n",
        "#ofauhsemotion_dict_list_dict = load_var(f'ofauhsemotion_dict_list_dict_{PAT_SHORT_NAME}')\n",
        "\n",
        "ogauhsemotion_dict_list_dict = load_var(f'ogauhsemotion_dict_list_dict_{PAT_SHORT_NAME}')\n",
        "\n",
        "#all_dict_list_dict = load_var(f'all_dict_list_dict_{PAT_SHORT_NAME}')"
      ],
      "metadata": {
        "id": "enGGAIcNbqmo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OIA7CNhWBu5u"
      },
      "outputs": [],
      "source": [
        "# SAVE VARIABLES - SMILE\n",
        "\n",
        "save_var(openface_dict_list_dict, forced_name='openface_dict_list_dict_smile_3')\n",
        "\n",
        "save_var(opengraphau_dict_list_dict, forced_name='opengraphau_dict_list_dict_smile_3')\n",
        "\n",
        "save_var(hsemotion_dict_list_dict, forced_name='hsemotion_dict_list_dict_smile_3')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# SAVE VARIABLES - SMILE\n",
        "\n",
        "save_var(ofauhsemotion_dict_list_dict, forced_name='ofauhsemotion_dict_list_dict_smile_3')\n",
        "\n",
        "save_var(ogauhsemotion_dict_list_dict, forced_name='ogauhsemotion_dict_list_dict_smile_3')\n",
        "\n",
        "save_var(all_dict_list_dict, forced_name='all_dict_list_dict_smile_3')"
      ],
      "metadata": {
        "id": "ieHpHYZ8JEel"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# SMILE ONLY\n",
        "# Pick just some features!\n",
        "# For now, we are just taking: AU6 stats, AU12 stats,\n",
        "\n",
        "def limit_features_of(df_dict_list_dict):\n",
        "  df_new_dict_list_dict = {}\n",
        "  for key in df_dict_list_dict.keys():\n",
        "    one_list = df_dict_list_dict[key]\n",
        "    new_list = []\n",
        "    building_df_1 = {} # AUs go here\n",
        "    building_df_2 = {} # Everything else goes here\n",
        "    for key_in in one_list[0].keys():\n",
        "      current_element_0 = one_list[0][key_in] # AU stats\n",
        "      current_element_2 = one_list[2][key_in] # EE stats\n",
        "      # extracts AU6 and AU12\n",
        "      combined_df_1 = pd.concat([current_element_0[4:5], current_element_0[8:9]], ignore_index=True)\n",
        "\n",
        "      # extracts Happiness (ee stats)\n",
        "      combined_df_2 = pd.concat([current_element_2[0:1]], ignore_index=True)\n",
        "\n",
        "      building_df_1[key_in] = combined_df_1\n",
        "      building_df_2[key_in] = combined_df_2\n",
        "\n",
        "    new_list.append(building_df_1)\n",
        "    new_list.append(building_df_2)\n",
        "    df_new_dict_list_dict[key] = new_list\n",
        "\n",
        "  return df_new_dict_list_dict\n",
        "\n",
        "def limit_features_og(df_dict_list_dict):\n",
        "  df_new_dict_list_dict = {}\n",
        "  for key in df_dict_list_dict.keys():\n",
        "    one_list = df_dict_list_dict[key]\n",
        "    new_list = []\n",
        "    building_df_1 = {} # AUs go here\n",
        "    building_df_2 = {} # Everything else goes here\n",
        "    for key_in in one_list[0].keys():\n",
        "      current_element_0 = one_list[0][key_in] # AU stats\n",
        "      current_element_1 = one_list[1][key_in] # EE stats\n",
        "      # extracts AU6 and AU12\n",
        "      combined_df_1 = pd.concat([current_element_0[4:5], current_element_0[9:10]], ignore_index=True)\n",
        "\n",
        "      # extracts Happiness (ee stats)\n",
        "      combined_df_2 = pd.concat([current_element_1[0:1]], ignore_index=True)\n",
        "\n",
        "      building_df_1[key_in] = combined_df_1\n",
        "      building_df_2[key_in] = combined_df_2\n",
        "\n",
        "    new_list.append(building_df_1)\n",
        "    new_list.append(building_df_2)\n",
        "    df_new_dict_list_dict[key] = new_list\n",
        "\n",
        "  return df_new_dict_list_dict\n",
        "\n",
        "\n",
        "def limit_features_hse(df_dict_list_dict):\n",
        "  df_new_dict_list_dict = {}\n",
        "  for key in df_dict_list_dict.keys():\n",
        "    one_list = df_dict_list_dict[key]\n",
        "    new_list = []\n",
        "    building_df = {}\n",
        "    for key_in in one_list[0].keys():\n",
        "      current_element_1 = one_list[1][key_in] # EE stats\n",
        "      # extracts Happiness ee stats\n",
        "      combined_df = current_element_1[3:4]\n",
        "      building_df[key_in] = combined_df\n",
        "\n",
        "    new_list.append(building_df)\n",
        "    df_new_dict_list_dict[key] = new_list\n",
        "\n",
        "  return df_new_dict_list_dict\n",
        "\n"
      ],
      "metadata": {
        "id": "oTUKU80xKf_i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# SMILE ONLY\n",
        "openface_dict_list_dict_limited = limit_features_of(openface_dict_list_dict)\n",
        "opengraphau_dict_list_dict_limited = limit_features_og(opengraphau_dict_list_dict)\n",
        "hsemotion_dict_list_dict_limited = limit_features_hse(hsemotion_dict_list_dict)"
      ],
      "metadata": {
        "id": "nVb60GdmKgCv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# SMILE ONLY\n",
        "ofauhsemotion_dict_list_dict_limited = partial_combine_dictionaries(openface_dict_list_dict_limited, hsemotion_dict_list_dict_limited)\n",
        "ogauhsemotion_dict_list_dict_limited = partial_combine_dictionaries(opengraphau_dict_list_dict_limited, hsemotion_dict_list_dict_limited)\n",
        "all_dict_list_dict_limited = full_combine_dictionaries([openface_dict_list_dict_limited, opengraphau_dict_list_dict_limited, hsemotion_dict_list_dict_limited])\n"
      ],
      "metadata": {
        "id": "MEp_UMr2CNPQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rcZea69MJ9Lw"
      },
      "outputs": [],
      "source": [
        "def flatten_dataframes_dict(dataframes_list):\n",
        "    # Initialize an empty dictionary to store the flattened data for each key\n",
        "    flattened_data_dict = {}\n",
        "\n",
        "    # Define the columns to ignore\n",
        "    ignore_columns = ['success', 'timestamp', 'AU', 'emotion']\n",
        "\n",
        "    for dataframes_dict in dataframes_list:\n",
        "       for key, df in dataframes_dict.items():\n",
        "          # Filter out the columns to be ignored\n",
        "          filtered_df = df.drop(columns=[col for col in ignore_columns if col in df.columns])\n",
        "\n",
        "          # Flatten the data by converting each DataFrame into a 1D array\n",
        "          flattened_array = filtered_df.select_dtypes(include=[np.number, int, float, complex, \\\n",
        "                                                                pd.Int64Dtype(), pd.Float64Dtype(), pd.Int32Dtype(), \\\n",
        "                                                                pd.Float32Dtype()]).values.flatten()\n",
        "\n",
        "          # Convert the flattened array to NumPy array and store it in the dictionary\n",
        "          if key in flattened_data_dict:\n",
        "              flattened_data_dict[key] = np.concatenate((flattened_data_dict[key], flattened_array))\n",
        "          else:\n",
        "              flattened_data_dict[key] = np.array(flattened_array)\n",
        "\n",
        "    return flattened_data_dict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1_kZiz0dKDcm"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "openface_vectors_dict = {}\n",
        "\n",
        "for key, openface_dict_list_now in openface_dict_list_dict.items():\n",
        "  openface_vectors_dict[key] = flatten_dataframes_dict(openface_dict_list_now)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "opengraphau_vectors_dict = {}\n",
        "\n",
        "for key, opengraphau_dict_list_now in opengraphau_dict_list_dict.items():\n",
        "  opengraphau_vectors_dict[key] = flatten_dataframes_dict(opengraphau_dict_list_now)\n"
      ],
      "metadata": {
        "id": "L2P1ntu5JF9A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "hsemotion_vectors_dict = {}\n",
        "\n",
        "for key, hsemotion_dict_list_now in hsemotion_dict_list_dict.items():\n",
        "  hsemotion_vectors_dict[key] = flatten_dataframes_dict(hsemotion_dict_list_now)\n"
      ],
      "metadata": {
        "id": "IEBJtszEJGPD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ofauhsemotion_vectors_dict = {}\n",
        "\n",
        "for key, ofauhsemotion_dict_list_now in ofauhsemotion_dict_list_dict.items():\n",
        "  ofauhsemotion_vectors_dict[key] = flatten_dataframes_dict(ofauhsemotion_dict_list_now)\n"
      ],
      "metadata": {
        "id": "YJQe4v4abTIe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ogauhsemotion_vectors_dict = {}\n",
        "\n",
        "for key, ogauhsemotion_dict_list_now in ogauhsemotion_dict_list_dict.items():\n",
        "  ogauhsemotion_vectors_dict[key] = flatten_dataframes_dict(ogauhsemotion_dict_list_now)\n"
      ],
      "metadata": {
        "id": "3QhobZ1wbTL2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "all_vectors_dict = {}\n",
        "\n",
        "for key, all_dict_list_now in all_dict_list_dict.items():\n",
        "  all_vectors_dict[key] = flatten_dataframes_dict(all_dict_list_now)\n"
      ],
      "metadata": {
        "id": "dn_OpS2jcZnF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zeN1ukKDLHVo"
      },
      "outputs": [],
      "source": [
        "openface_vectors_dict['60'][get_moodTracking_datetime(0)].shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L60VuGulO29n"
      },
      "outputs": [],
      "source": [
        "opengraphau_vectors_dict['60'][get_moodTracking_datetime(0, df_moodTracking=df_moodTracking)].shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bKBfxsR8O4OI"
      },
      "outputs": [],
      "source": [
        "hsemotion_vectors_dict['60'][get_moodTracking_datetime(0, df_moodTracking=df_moodTracking)].shape"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ofauhsemotion_vectors_dict['60'][get_moodTracking_datetime(0)].shape"
      ],
      "metadata": {
        "id": "t2xNZSwmbfLM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ogauhsemotion_vectors_dict['60'][get_moodTracking_datetime(0, df_moodTracking=df_moodTracking)].shape"
      ],
      "metadata": {
        "id": "cuRt5B5GbfOi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "all_vectors_dict['60'][get_moodTracking_datetime(0)].shape"
      ],
      "metadata": {
        "id": "XduQPeAQce5X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "K9apyQQMfIso"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "So5hSPmHfIv7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# LIMITED FEATURES\n",
        "\n",
        "openface_vectors_dict = {}\n",
        "\n",
        "for key, openface_dict_list_now in openface_dict_list_dict_limited.items():\n",
        "  openface_vectors_dict[key] = flatten_dataframes_dict(openface_dict_list_now)\n",
        "\n",
        "opengraphau_vectors_dict = {}\n",
        "\n",
        "for key, opengraphau_dict_list_now in opengraphau_dict_list_dict_limited.items():\n",
        "  opengraphau_vectors_dict[key] = flatten_dataframes_dict(opengraphau_dict_list_now)\n",
        "\n",
        "hsemotion_vectors_dict = {}\n",
        "\n",
        "for key, hsemotion_dict_list_now in hsemotion_dict_list_dict_limited.items():\n",
        "  hsemotion_vectors_dict[key] = flatten_dataframes_dict(hsemotion_dict_list_now)\n",
        "\n",
        "ofauhsemotion_vectors_dict = {}\n",
        "\n",
        "for key, ofauhsemotion_dict_list_now in ofauhsemotion_dict_list_dict_limited.items():\n",
        "  ofauhsemotion_vectors_dict[key] = flatten_dataframes_dict(ofauhsemotion_dict_list_now)\n",
        "\n",
        "ogauhsemotion_vectors_dict = {}\n",
        "\n",
        "for key, ogauhsemotion_dict_list_now in ogauhsemotion_dict_list_dict_limited.items():\n",
        "  ogauhsemotion_vectors_dict[key] = flatten_dataframes_dict(ogauhsemotion_dict_list_now)\n",
        "\n",
        "all_vectors_dict = {}\n",
        "\n",
        "for key, all_dict_list_now in all_dict_list_dict_limited.items():\n",
        "  all_vectors_dict[key] = flatten_dataframes_dict(all_dict_list_now)\n"
      ],
      "metadata": {
        "id": "9ozsDQcBfI1P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Experiment: SHUFFLING TIMESTAMPS OF DICTIONARIES\n",
        "# Should nullify performance\n",
        "\n",
        "import random\n",
        "\n",
        "def shuffle_dict_values(input_dict):\n",
        "    # Copy the original dictionary\n",
        "    shuffled_dict = input_dict.copy()\n",
        "\n",
        "    # Extract keys and values\n",
        "    keys = list(shuffled_dict.keys())\n",
        "    values = list(shuffled_dict.values())\n",
        "\n",
        "    # Shuffle the values\n",
        "    random.shuffle(values)\n",
        "\n",
        "    # Reassign the shuffled values to the keys\n",
        "    shuffled_dict = dict(zip(keys, values))\n",
        "\n",
        "    return shuffled_dict\n"
      ],
      "metadata": {
        "id": "NfyLZJpxxHCn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for key in opengraphau_dict_list_dict.keys():\n",
        "  #opengraphau_dict_list_dict[key] = [opengraphau_au_derived_dict[key], opengraphau_ee_derived_dict[key]]\n",
        "  opengraphau_dict_list_dict[key] = [shuffle_dict_values(opengraphau_dict_list_dict[key][0])]\n",
        "\n",
        "opengraphau_vectors_dict = {}\n",
        "\n",
        "for key, opengraphau_dict_list_now in opengraphau_dict_list_dict.items():\n",
        "  opengraphau_vectors_dict[key] = flatten_dataframes_dict(opengraphau_dict_list_now)\n"
      ],
      "metadata": {
        "id": "X80aZxb4xHGR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "fPj_JdcpxHKO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gx6_bCNQV6uD"
      },
      "source": [
        "## Labels - datetime conversion"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5hRicOaOQVtq"
      },
      "outputs": [],
      "source": [
        "def ts_to_str(timestamp):\n",
        "    return timestamp.strftime('%-m/%-d/%Y %H:%M:%S')\n",
        "\n",
        "def str_to_ts(string_now):\n",
        "  temp_var = pd.to_datetime(pd.to_datetime(string_now).strftime('%d-%b-%Y %H:%M:%S'))\n",
        "  return pd.Timestamp(temp_var)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3lwF8VpTv-oC"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NpvfE0TfXduU"
      },
      "outputs": [],
      "source": [
        "ts_to_str(list(openface_vectors_dict['60'].keys())[18])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oJvxb39jc9Pg"
      },
      "outputs": [],
      "source": [
        "str_to_ts('4/6/2023 20:30:00')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FLtMi6TUvm9K"
      },
      "source": [
        "## Save to excel"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HD95XHYFxLl9"
      },
      "outputs": [],
      "source": [
        "!pip install xlsxwriter -qq"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6Es85PqYzSht"
      },
      "outputs": [],
      "source": [
        "def ts_to_str_save(timestamp):\n",
        "    # shorter version bc xlsxwriter sheet name char limit\n",
        "    return timestamp.strftime('%-m_%-d %H_%M')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ntLtIcQow-03"
      },
      "outputs": [],
      "source": [
        "## Save our vectors to excel sheets!\n",
        "\n",
        "def get_dict_name(dictionary):\n",
        "    namespace = globals()\n",
        "    for name, obj in namespace.items():\n",
        "        if isinstance(obj, dict) and obj is dictionary:\n",
        "            return name\n",
        "    return None\n",
        "\n",
        "def save_dicts_to_excel(dict_list, output_path):\n",
        "  # Create an Excel writer object\n",
        "  writer = pd.ExcelWriter(output_path, engine='xlsxwriter')\n",
        "\n",
        "  # Iterate over the keys in the dictionaries\n",
        "  for key in dict_list[0].keys():\n",
        "      # Write each dataframe to a separate sheet with the corresponding key as the sheet name\n",
        "      for enum, dict_now in enumerate(dict_list):\n",
        "        name_var = f'Matrix_{enum}'\n",
        "        sheet_name_starter = f'{ts_to_str_save(key)}_{name_var}'\n",
        "        dict_now[key].to_excel(writer, sheet_name=sheet_name_starter[:31])\n",
        "\n",
        "  # Save the Excel file\n",
        "  writer.save()\n",
        "  return"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Multi-hour features"
      ],
      "metadata": {
        "id": "HtF5RndQv9qj"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2-zpJEZSyU2S"
      },
      "outputs": [],
      "source": [
        "\n",
        "os.makedirs(FEATURE_VIS_PATH, exist_ok=True)\n",
        "\n",
        "for i in opengraphau_dict_list_dict.keys():\n",
        "  #save_dicts_to_excel(openface_dict_list_dict[i], FEATURE_VIS_PATH + f'openface_{PAT_SHORT_NAME}_{int(i) / 60}_hours.xlsx')\n",
        "  save_dicts_to_excel(opengraphau_dict_list_dict[i], FEATURE_VIS_PATH + f'opengraphau_{PAT_SHORT_NAME}_{int(i) / 60}_hours.xlsx')\n",
        "  save_dicts_to_excel(hsemotion_dict_list_dict[i], FEATURE_VIS_PATH + f'hsemotion_{PAT_SHORT_NAME}_{int(i) / 60}_hours.xlsx')\n",
        "  save_dicts_to_excel(ogauhsemotion_dict_list_dict[i], FEATURE_VIS_PATH + f'ogauhse_{PAT_SHORT_NAME}_{int(i) / 60}_hours.xlsx')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Multi-second features"
      ],
      "metadata": {
        "id": "R36pia3ZwBu4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_readable_features_dfs(datetime_features_dict, column_names=[]):\n",
        "  # returns a dictionary mapping key (e.g. '0.08333' for 5 seconds)\n",
        "  # to a pandas df that is readable\n",
        "  converted_dfs = {}\n",
        "  for key in datetime_features_dict.keys():\n",
        "    # Convert datetime_features_dict to DataFrame\n",
        "    datetime_features_dict_now = datetime_features_dict[key]\n",
        "    feature_df = pd.DataFrame.from_dict(datetime_features_dict_now, orient='index')\n",
        "    feature_df.index.name = 'Datetime'\n",
        "\n",
        "    feature_df.columns = column_names\n",
        "\n",
        "    converted_dfs[key] = feature_df\n",
        "\n",
        "  return converted_dfs"
      ],
      "metadata": {
        "id": "YJ8mtbLkwDWc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "readable_openface = get_readable_features_dfs(openface_vectors_dict, column_names=['AU6 pres_pct', 'AU6 intsoft_mean', 'AU6 intsoft_std', 'AU12 pres_pct', 'AU12 intsoft_mean', 'AU12 intsoft_std', 'Happiness pres_pct', 'Happiness intsoft_mean', 'Happiness intsoft_std', 'Happiness inthard_mean'])\n",
        "readable_opengraphau = get_readable_features_dfs(opengraphau_vectors_dict, column_names=['AU6 pres_pct', 'AU12 pres_pct', 'Happiness pres_pct'])\n",
        "readable_hsemotion = get_readable_features_dfs(hsemotion_vectors_dict, column_names=['Happiness pres_pct', 'Happiness intsoft_mean', 'Happiness intsoft_std'])"
      ],
      "metadata": {
        "id": "6arZrRlPwGQT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def save_dfs_to_excel(df_dict, file_path=FEATURE_VIS_PATH, file_base='openface'):\n",
        "  for key, df in df_dict.items():\n",
        "      insert_num = round(float(key) * 60)\n",
        "      file_name = file_path+f\"{file_base}_{insert_num}_seconds.xlsx\"\n",
        "\n",
        "      with pd.ExcelWriter(file_name) as writer:\n",
        "          df.to_excel(writer, index=True)"
      ],
      "metadata": {
        "id": "C_ZY-EXiyipq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "save_dfs_to_excel(readable_openface, file_path=FEATURE_VIS_PATH+'SMILE/', file_base='openface')\n",
        "save_dfs_to_excel(readable_opengraphau, file_path=FEATURE_VIS_PATH+'SMILE/', file_base='opengraphau')\n",
        "save_dfs_to_excel(readable_hsemotion, file_path=FEATURE_VIS_PATH+'SMILE/', file_base='hsemotion')"
      ],
      "metadata": {
        "id": "iRjEBArRzF2A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Minimum for Debugging Mood"
      ],
      "metadata": {
        "id": "CNha_V6MAWJW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the numpy vector for the current column\n",
        "y = df_moodTracking['Mood'].values\n",
        "\n",
        "# Get the corresponding numpy vectors from the openface vectors dictionary\n",
        "X_1_hour = np.array([openface_vectors_dict['30'][str_to_ts(dt)] for dt in df_moodTracking['Datetime']])\n",
        "\n",
        "X_2_hour = np.array([openface_vectors_dict['60'][str_to_ts(dt)] for dt in df_moodTracking['Datetime']])\n",
        "\n",
        "X_3_hour = np.array([openface_vectors_dict['90'][str_to_ts(dt)] for dt in df_moodTracking['Datetime']])\n",
        "\n",
        "X_4_hour = np.array([openface_vectors_dict['120'][str_to_ts(dt)] for dt in df_moodTracking['Datetime']])\n",
        "\n",
        "\n",
        "# just valid indices (remove nans!)\n",
        "valid_indices = ~pd.isna(y)\n",
        "mood_y = y[valid_indices]\n",
        "mood_X_1_hour = X_1_hour[valid_indices]\n",
        "mood_X_2_hour = X_2_hour[valid_indices]\n",
        "mood_X_3_hour = X_3_hour[valid_indices]\n",
        "mood_X_4_hour = X_4_hour[valid_indices]\n",
        "\n"
      ],
      "metadata": {
        "id": "f4I2Heq4AnGU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mood_minimum_vars = {'mood_y': mood_y,\n",
        "                     'mood_X_1_hour': mood_X_1_hour,\n",
        "                     'mood_X_2_hour': mood_X_2_hour,\n",
        "                     'mood_X_3_hour': mood_X_3_hour,\n",
        "                     'mood_X_4_hour': mood_X_4_hour}\n"
      ],
      "metadata": {
        "id": "rJcg6uCNA83I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "save_var(mood_minimum_vars)"
      ],
      "metadata": {
        "id": "N230z2tbBQxf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Linear Regression\n",
        "\n"
      ],
      "metadata": {
        "id": "9v5twoysUh12"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Setup"
      ],
      "metadata": {
        "id": "8t1JM3aZYVaF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import random\n",
        "\n",
        "def set_seed(x=5):\n",
        "  np.random.seed(x)\n",
        "  random.seed(x)\n",
        "\n",
        "\n",
        "set_seed()"
      ],
      "metadata": {
        "id": "0QiQpmItUj02"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import cross_val_predict\n",
        "from sklearn.linear_model import LinearRegression\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.ticker as ticker\n",
        "from scipy.stats import pearsonr\n",
        "import seaborn as sns\n",
        "from sklearn.linear_model import Ridge\n",
        "from sklearn.linear_model import Lasso\n",
        "\n",
        "\n",
        "def linRegOneMetric(vectors_dict, y, randShuffle=False, do_lasso=False, do_ridge=False, alpha=1.0):\n",
        "  # runs simple linear regression via one-left-out\n",
        "  # vectors_dict -- dictionary mapping time radius (in minutes) to features\n",
        "  # y -- a numpy array with labels (self-reported metrics)\n",
        "  # randShuffle -- do we shuffle the self-report labels?\n",
        "  # if do_lasso, does lasso regression\n",
        "  # if do_ridge, does ridge regression. Overrides do_lasso\n",
        "  # alpha - this is the weighting of either lasso or ridge\n",
        "\n",
        "  # returns a dictionary with several results:\n",
        "  # scores -- dictionary mapping each time radius to list of MSEs from each one-left-out\n",
        "  # preds -- dictionary mapping each time radius to a list of each one-left-out model's prediction\n",
        "  # y -- returns y again for convenience\n",
        "  # models -- dictionary mapping each time radius to a list of each one-left-out trained model (simple linear regression)\n",
        "\n",
        "  scores = {}\n",
        "  preds = {}\n",
        "  models = {}\n",
        "\n",
        "  if randShuffle:\n",
        "    y_using = np.random.permutation(y)\n",
        "  else:\n",
        "    y_using = y\n",
        "\n",
        "  for i in vectors_dict.keys():\n",
        "    model = LinearRegression()\n",
        "    if do_lasso:\n",
        "      model = Lasso(alpha=alpha)\n",
        "    if do_ridge:\n",
        "      model = Ridge(alpha=alpha)\n",
        "\n",
        "    # Compute MSEs via scikitlearn cross_val_score\n",
        "    scores_temp = cross_val_score(model, vectors_dict[i], y_using, cv=vectors_dict[i].shape[0], scoring='neg_mean_squared_error')\n",
        "    scores[i] = -1 * scores_temp\n",
        "\n",
        "    # Predictions via cross_val_predict\n",
        "    preds[i] = cross_val_predict(model, vectors_dict[i], y_using, cv=vectors_dict[i].shape[0])\n",
        "\n",
        "    # Now we need to iterate through and actually save the models themselves, since cross_val_score doesn't let us do that!\n",
        "    models_i_building = []\n",
        "    for test_index in range(vectors_dict[i].shape[0]):\n",
        "\n",
        "      X_train = np.delete(vectors_dict[i], test_index, axis=0)\n",
        "\n",
        "      y_train = np.delete(y_using, test_index, axis=0)\n",
        "\n",
        "      model = LinearRegression()\n",
        "      if do_lasso:\n",
        "        model = Lasso(alpha=alpha)\n",
        "      if do_ridge:\n",
        "        model = Ridge(alpha=alpha)\n",
        "      model.fit(X_train, y_train)\n",
        "      models_i_building.append(model)\n",
        "\n",
        "    models[i] = models_i_building\n",
        "\n",
        "  return scores, preds, y, models\n",
        "\n",
        "\n",
        "\n",
        "def plot_predictions(y, y_pred, randShuffleR=None, ax=None, time_rad=None, metric=None):\n",
        "    # Makes one scatterplot with Pearson's R and p value on it\n",
        "    # give it the randShuffle Pearson's R\n",
        "    # if you want to display that on the plot\n",
        "\n",
        "    # Compute Pearson's R\n",
        "    pearson_corr, p_val = pearsonr(y, y_pred)\n",
        "\n",
        "    # Create the scatter plot on the specified axes\n",
        "    if ax is None:\n",
        "        ax_original = None\n",
        "        fig, ax = plt.subplots()\n",
        "        # adjust fonts!\n",
        "        text_font = 16\n",
        "    else:\n",
        "        ax_original = ax\n",
        "        text_font = 16\n",
        "\n",
        "\n",
        "    ax.scatter(y, y_pred, label='Predicted vs. True', s=24)\n",
        "\n",
        "\n",
        "\n",
        "    # Add the correlation coefficient and p-value on the plot\n",
        "    ax.text(0.05, 0.90, f'Pearson\\'s R: {pearson_corr:.2f}', transform=ax.transAxes, fontsize=text_font)\n",
        "    ax.text(0.05, 0.80, f'P Value: {p_val:.2f}', transform=ax.transAxes, fontsize=text_font)\n",
        "    if not(randShuffleR is None):\n",
        "      ax.text(0.05, 0.70, f'Random Shuffle R: {randShuffleR:.2f}', transform=ax.transAxes, fontsize=text_font)\n",
        "\n",
        "    # Set labels and title\n",
        "    ax.set_xlabel('Self-Reported Scores', fontsize=17)\n",
        "    ax.set_ylabel('Predicted Scores', fontsize=17)\n",
        "\n",
        "    if metric is None:\n",
        "      title_starter = 'Predicted vs. True'\n",
        "    else:\n",
        "      title_starter = metric\n",
        "\n",
        "    if time_rad is None:\n",
        "      ax.set_title(f'{title_starter} Scores', fontsize=17)\n",
        "    else:\n",
        "      num_hrs = int(time_rad) / 60\n",
        "      if num_hrs > 1:\n",
        "        ax.set_title(f'{title_starter}, Time Window = {num_hrs} Hours', fontsize=15)\n",
        "      else:\n",
        "        ax.set_title(f'{title_starter}, Time Window = {num_hrs} Hour', fontsize=15)\n",
        "\n",
        "\n",
        "    # Add the line of best fit\n",
        "    sns.regplot(x=y, y=y_pred, ax=ax, line_kws={'color': 'red', 'linestyle': '--'}, label='Line of Best Fit')\n",
        "\n",
        "    # Add the shaded region for the 95% confidence interval\n",
        "    #sns.regplot(x=y, y=y_pred, ax=ax, scatter=False, ci=95, color='gray', label='95% Confidence Interval')\n",
        "\n",
        "    # Adjust the font size of the tick labels on the axes\n",
        "    ax.tick_params(axis='both', labelsize=18)\n",
        "\n",
        "    ax.set_adjustable('box')\n",
        "\n",
        "    #set aspect ratio to 1\n",
        "    ratio = 1.0\n",
        "    x_left, x_right = ax.get_xlim()\n",
        "    y_low, y_high = ax.get_ylim()\n",
        "    ax.set_aspect(abs((x_right-x_left)/(y_low-y_high))*ratio)\n",
        "\n",
        "    if ax_original is None:\n",
        "        plt.show()\n",
        "        return pearson_corr, p_val, fig\n",
        "    else:\n",
        "        return pearson_corr, p_val\n",
        "\n",
        "\n",
        "\n",
        "def plot_scatterplots(preds_dict, y, overall_title, savepath, randShuffleR=None):\n",
        "\n",
        "    plt.rcParams['lines.markersize'] = 6\n",
        "    subplot_title_font = 16\n",
        "    full_title_font = 24\n",
        "\n",
        "    num_plots = len(list(preds_dict.keys()))\n",
        "    num_cols = 4\n",
        "    num_rows = (num_plots + num_cols - 1) // num_cols\n",
        "\n",
        "    r_list = []\n",
        "    p_list = []\n",
        "\n",
        "    # Calculate the desired figure size for larger plot\n",
        "    figsize = (28, 12)\n",
        "\n",
        "    # Create subplots with auto aspect ratio\n",
        "    fig, axes = plt.subplots(num_rows, num_cols, figsize=figsize)\n",
        "\n",
        "    #axes.set_adjustable('box')\n",
        "\n",
        "    if num_rows == 1:\n",
        "      axes = axes.reshape((1, num_cols))\n",
        "\n",
        "    # Flatten the axes array if necessary\n",
        "    if num_plots == 1:\n",
        "        fig, axes = plt.subplots(1, 1, figsize=figsize)\n",
        "        axes = np.array([axes]).reshape(1, 1)\n",
        "\n",
        "\n",
        "    # Loop through the dictionaries\n",
        "    for i, (key, y_preds) in enumerate(preds_dict.items()):\n",
        "        y_list = np.array(y).astype(float)\n",
        "        y_pred = np.array(y_preds).astype(float)\n",
        "        #y_pred = np.array([i[0] for i in y_pred])\n",
        "\n",
        "        # Get the subplot coordinates\n",
        "        row = i // num_cols\n",
        "        col = i % num_cols\n",
        "\n",
        "        # Plot predictions on the subplot\n",
        "        if randShuffleR is None:\n",
        "          pearson_corr, p_val = plot_predictions(y_list, y_pred, randShuffleR=randShuffleR, ax=axes[row, col])\n",
        "        else:\n",
        "          pearson_corr, p_val = plot_predictions(y_list, y_pred, randShuffleR=randShuffleR[i], ax=axes[row, col])\n",
        "        r_list.append(pearson_corr)\n",
        "        p_list.append(p_val)\n",
        "\n",
        "        num_hrs = int(key) / 60\n",
        "        if num_hrs > 1:\n",
        "          axes[row, col].set_title(f'Time Window = {num_hrs} Hours', fontsize=subplot_title_font)\n",
        "        else:\n",
        "          axes[row, col].set_title(f'Time Window = {num_hrs} Hour', fontsize=subplot_title_font)\n",
        "        #axes[row, col].set_aspect('equal')\n",
        "\n",
        "        # Remove x-axis and y-axis labels from subplots\n",
        "        axes[row, col].set_xlabel('')\n",
        "        axes[row, col].set_ylabel('')\n",
        "\n",
        "        #axes[row, col].set_adjustable('box')\n",
        "\n",
        "    # Add overall title\n",
        "    fig.suptitle(overall_title, fontsize=30, y=1)\n",
        "\n",
        "    # Set shared x-axis and y-axis labels\n",
        "    fig.text(0.5, 0.00, 'Self-Reported Scores', ha='center', fontsize=full_title_font)\n",
        "    fig.text(-0.01, 0.5, 'Predicted Scores', va='center', rotation='vertical', fontsize=full_title_font)\n",
        "\n",
        "    # Adjust spacing and layout\n",
        "    fig.tight_layout()\n",
        "\n",
        "    plt.savefig(savepath, bbox_inches='tight')\n",
        "\n",
        "    plt.show()\n",
        "\n",
        "    return r_list, p_list, fig\n",
        "\n",
        "\n",
        "def make_mse_boxplot(scores, metric, savepath, ax=None, method_now='OpenFace'):\n",
        "    # scores -- dictionary that maps time radius (mins) to list of MSEs from one-left-out\n",
        "    # metric - e.g. Mood or Anxiety\n",
        "\n",
        "    # Combine the data into a single array\n",
        "    data = [MSE_list for MSE_list in list(scores.values())]\n",
        "\n",
        "    # Set the font sizes\n",
        "    plt.rcParams.update({'font.size': 15})\n",
        "\n",
        "    if ax is None:\n",
        "        fig, ax = plt.subplots()\n",
        "    else:\n",
        "        fig = None\n",
        "\n",
        "    # Create a box plot of the data\n",
        "    labels_now = [f'{int(key) / 60}' for key in scores.keys()]\n",
        "\n",
        "    ax.boxplot(data, labels=labels_now, showmeans=True, meanprops={'marker': 'o', 'markerfacecolor': 'red', 'markersize': 10})\n",
        "\n",
        "    # Determine the highest 75th percentile value among the four entries\n",
        "    max_value = np.max([np.percentile(entry, 75) for entry in data])\n",
        "\n",
        "    # Set the y-axis range conditionally\n",
        "    if max_value > 100:\n",
        "        ax.set_ylim(0, 100)\n",
        "    else:\n",
        "        ax.set_ylim(0, max_value)\n",
        "\n",
        "    # Set the labels and title\n",
        "    ax.set_xlabel('Time Window (Hours)')\n",
        "    ax.set_ylabel('Mean Squared Error')\n",
        "    ax.set_title(f'{metric} Prediction via {method_now}', y=1.1)\n",
        "\n",
        "    plt.xticks(rotation=45)\n",
        "\n",
        "    plt.savefig(savepath, bbox_inches='tight')\n",
        "\n",
        "    # Show the plot if fig is None\n",
        "    if fig is None:\n",
        "        plt.show()\n",
        "    else:\n",
        "        return fig\n",
        "\n",
        "def make_r_barplot(r_list, time_radius_list, metric, savepath, ax=None, method_now='OpenFace'):\n",
        "    plt.rcParams.update({'font.size': 15})\n",
        "\n",
        "    x_labels = [f'{int(i) / 60}' for i in time_radius_list]\n",
        "\n",
        "    if ax is None:\n",
        "        original_ax = None\n",
        "        fig, ax = plt.subplots()\n",
        "    else:\n",
        "        original_ax = ax\n",
        "\n",
        "    ax.bar(x_labels, r_list)\n",
        "\n",
        "    # Set the y-axis range\n",
        "    ax.set_ylim(-0.5, 1)\n",
        "\n",
        "    # Set the labels and title\n",
        "    ax.set_xlabel('Time Window (Hours)')\n",
        "    ax.set_ylabel(\"Pearson's R\")\n",
        "    ax.set_title(f'{metric} Prediction via {method_now}', y=1.1)\n",
        "\n",
        "    plt.xticks(rotation=45)\n",
        "\n",
        "    plt.savefig(savepath, bbox_inches='tight')\n",
        "\n",
        "    # Show the plot if ax is None\n",
        "    if original_ax is None:\n",
        "        plt.show()\n",
        "        return fig\n",
        "\n",
        "# def get_label_from_index(index, spreadsheet_path=FEATURE_LABEL_PATH+'opengraphau_0.5_hours.xlsx'):\n",
        "#     if 'hsemotion' in spreadsheet_path:\n",
        "#       matrices = [\"Matrix_0\"]\n",
        "#       row_label_cols = [\"emotion\"]\n",
        "#     elif 'opengraphau' in spreadsheet_path:\n",
        "#       matrices = [\"Matrix_0\", \"Matrix_1\"]\n",
        "#       row_label_cols = [\"AU\", \"emotion\"]\n",
        "#     elif 'openface' in spreadsheet_path:\n",
        "#       matrices = [\"Matrix_0\", \"Matrix_1\"]\n",
        "#       row_label_cols = [\"AU\", \"emotion\"]\n",
        "#     elif 'ofauhse' in spreadsheet_path:\n",
        "#       matrices = [\"Matrix_0\", \"Matrix_1\"]\n",
        "#       row_label_cols = [\"AU\", \"emotion\"]\n",
        "#     elif 'ogauhse' in spreadsheet_path:\n",
        "#       matrices = [\"Matrix_0\", \"Matrix_1\"]\n",
        "#       row_label_cols = [\"AU\", \"emotion\"]\n",
        "#     elif 'all' in spreadsheet_path:\n",
        "#       matrices = [\"Matrix_0\", \"Matrix_1\", \"Matrix_2\", \"Matrix_3\", \"Matrix_4\"]\n",
        "#       row_label_cols = [\"AU\", \"emotion\", \"AU\", \"emotion\", \"emotion\"]\n",
        "#     else:\n",
        "#       print('BUG IN THE CODE! CHECK get_label_from_index')\n",
        "#       print('spreadsheet path is ', spreadsheet_path)\n",
        "\n",
        "\n",
        "#     xls = pd.ExcelFile(spreadsheet_path)\n",
        "\n",
        "#     for i, matrix in enumerate(matrices):\n",
        "#         # Find the sheet ending with the current matrix name\n",
        "#         sheet_name = next((s for s in xls.sheet_names if s.endswith(matrix)), None)\n",
        "#         if sheet_name is not None:\n",
        "#             # Load the sheet into a DataFrame, with the first row as column names\n",
        "#             if row_label_cols[i] == 'AU':\n",
        "#               df = pd.read_excel(spreadsheet_path, sheet_name=sheet_name, header=0, usecols=lambda x: x != 'Unnamed: 0')\n",
        "#             else:\n",
        "#               df = pd.read_excel(spreadsheet_path, sheet_name=sheet_name, header=0)\n",
        "\n",
        "#             # Get the column labels from the DataFrame\n",
        "#             col_labels = df.columns.tolist()\n",
        "#             col_labels = col_labels[1:]\n",
        "\n",
        "#             # Get the row labels and column labels based on the matrix type\n",
        "#             row_label_col = row_label_cols[i]\n",
        "#             row_labels = None\n",
        "\n",
        "#             if row_label_col in df.columns:\n",
        "#                 row_labels = df[row_label_col].tolist()\n",
        "#             else:\n",
        "#                 row_labels = df.iloc[:, 0]\n",
        "\n",
        "#             # Get the numerical entries in the sheet excluding columns \"AU\" and \"emotion\"\n",
        "#             numerical_entries = df.loc[:, ~df.columns.isin([\"AU\", \"emotion\"])].values.flatten()\n",
        "#             numerical_entries = numerical_entries[~pd.isnull(numerical_entries)]\n",
        "\n",
        "#             # Check if the index is within the range of numerical entries\n",
        "#             if index < len(numerical_entries):\n",
        "#                 # Find the label corresponding to the index\n",
        "#                 row_index, col_index = divmod(index, len(col_labels))\n",
        "\n",
        "#                 if row_labels is None:\n",
        "#                     return col_labels[col_index]\n",
        "#                 else:\n",
        "#                     if \"AU\" == row_label_cols[i]:\n",
        "#                       return f\"AU{row_labels[row_index]} {col_labels[col_index]}\"\n",
        "#                     else:\n",
        "#                       return f\"{col_labels[col_index]} {row_labels[row_index]}\"\n",
        "#             else:\n",
        "#                 index -= len(numerical_entries)\n",
        "\n",
        "#     # Return None if the index is out of range or no suitable sheets found\n",
        "#     print('BIG PROBLEM in get_label_from_index: no suitable sheets or index out of range')\n",
        "#     return None\n",
        "\n",
        "\n",
        "\n",
        "# def get_label_from_index(index, spreadsheet_path=FEATURE_LABEL_PATH+'openface_0.5_hours.xlsx'):\n",
        "#     if 'hsemotion' in spreadsheet_path:\n",
        "#       matrices = [\"Matrix_0\", \"Matrix_1\"]\n",
        "#       row_label_cols = [\"emotion\", \"emotion\"]\n",
        "#     elif 'opengraphau' in spreadsheet_path:\n",
        "#       matrices = [\"Matrix_0\", \"Matrix_1\"]\n",
        "#       row_label_cols = [\"AU\", \"emotion\"]\n",
        "#     elif 'openface' in spreadsheet_path:\n",
        "#       matrices = [\"Matrix_0\", \"Matrix_1\", \"Matrix_2\", \"Matrix_3\"]\n",
        "#       row_label_cols = [\"AU\", \"emotion\", \"emotion\", None]\n",
        "#     elif 'ofauhse' in spreadsheet_path:\n",
        "#       matrices = [\"Matrix_0\", \"Matrix_1\", \"Matrix_2\"]\n",
        "#       row_label_cols = [\"AU\", \"emotion\", \"emotion\"]\n",
        "#     elif 'ogauhse' in spreadsheet_path:\n",
        "#       matrices = [\"Matrix_0\", \"Matrix_1\", \"Matrix_2\"]\n",
        "#       row_label_cols = [\"AU\", \"emotion\", \"emotion\"]\n",
        "#     elif 'all' in spreadsheet_path:\n",
        "#       matrices = [\"Matrix_0\", \"Matrix_1\", \"Matrix_2\", \"Matrix_3\", \"Matrix_4\", \"Matrix_5\", \"Matrix_6\", \"Matrix_7\"]\n",
        "#       row_label_cols = [\"AU\", \"emotion\", \"emotion\", None, \"AU\", \"emotion\", \"emotion\", \"emotion\"]\n",
        "#     else:\n",
        "#       print('BUG IN THE CODE! CHECK get_label_from_index')\n",
        "#       print('spreadsheet path is ', spreadsheet_path)\n",
        "\n",
        "\n",
        "#     xls = pd.ExcelFile(spreadsheet_path)\n",
        "\n",
        "#     for i, matrix in enumerate(matrices):\n",
        "#         # Find the sheet ending with the current matrix name\n",
        "#         sheet_name = next((s for s in xls.sheet_names if s.endswith(matrix)), None)\n",
        "#         if sheet_name is not None:\n",
        "#             # Load the sheet into a DataFrame, with the first row as column names\n",
        "#             df = pd.read_excel(spreadsheet_path, sheet_name=sheet_name, header=0, usecols=lambda x: x != 'Unnamed: 0')\n",
        "\n",
        "#             # Get the column labels from the DataFrame\n",
        "#             col_labels = df.columns.tolist()\n",
        "#             if not(row_label_cols[i] is None):\n",
        "#               col_labels = col_labels[1:]\n",
        "\n",
        "#             # Check if it's Matrix_3 (single row)\n",
        "#             if i == 3 and (row_label_cols[i] is None):\n",
        "#                 if index < len(col_labels):\n",
        "#                     return col_labels[index]\n",
        "\n",
        "#             # Get the row labels and column labels based on the matrix type\n",
        "#             row_label_col = row_label_cols[i]\n",
        "#             row_labels = None\n",
        "\n",
        "#             if row_label_col is not None and row_label_col in df.columns:\n",
        "#                 row_labels = df[row_label_col].tolist()\n",
        "\n",
        "#             # Get the numerical entries in the sheet excluding columns \"AU\" and \"emotion\"\n",
        "#             numerical_entries = df.loc[:, ~df.columns.isin([\"AU\", \"emotion\"])].values.flatten()\n",
        "#             numerical_entries = numerical_entries[~pd.isnull(numerical_entries)]\n",
        "\n",
        "#             # Check if the index is within the range of numerical entries\n",
        "#             if index < len(numerical_entries):\n",
        "#                 # Find the label corresponding to the index\n",
        "#                 row_index, col_index = divmod(index, len(col_labels))\n",
        "\n",
        "#                 if row_labels is None:\n",
        "#                     return col_labels[col_index]\n",
        "#                 else:\n",
        "#                     if \"AU\" == row_label_cols[i]:\n",
        "#                       return f\"AU{row_labels[row_index]} {col_labels[col_index]}\"\n",
        "#                     else:\n",
        "#                       return f\"{row_labels[row_index]} {col_labels[col_index]}\"\n",
        "#             else:\n",
        "#                 index -= len(numerical_entries)\n",
        "\n",
        "#     # Return None if the index is out of range or no suitable sheets found\n",
        "#     print('BIG PROBLEM')\n",
        "#     return None\n",
        "\n",
        "\n",
        "def get_label_from_index(index, spreadsheet_path=FEATURE_LABEL_PATH+'openface_0.5_hours.xlsx'):\n",
        "    if 'hsemotion' in spreadsheet_path:\n",
        "      matrices = [\"Matrix_0\"]\n",
        "      row_label_cols = [\"emotion\"]\n",
        "    elif 'opengraphau' in spreadsheet_path:\n",
        "      matrices = [\"Matrix_0\"]\n",
        "      row_label_cols = [\"AU\"]\n",
        "    elif 'openface' in spreadsheet_path:\n",
        "      matrices = [\"Matrix_0\", \"Matrix_1\", \"Matrix_2\", \"Matrix_3\"]\n",
        "      row_label_cols = [\"AU\", \"emotion\", \"emotion\", None]\n",
        "    elif 'ofauhse' in spreadsheet_path:\n",
        "      matrices = [\"Matrix_0\", \"Matrix_1\"]\n",
        "      row_label_cols = [\"AU\", \"emotion\"]\n",
        "    elif 'ogauhse' in spreadsheet_path:\n",
        "      matrices = [\"Matrix_0\", \"Matrix_1\"]\n",
        "      row_label_cols = [\"AU\", \"emotion\"]\n",
        "    elif 'all' in spreadsheet_path:\n",
        "      matrices = [\"Matrix_0\", \"Matrix_1\", \"Matrix_2\", \"Matrix_3\", \"Matrix_4\", \"Matrix_5\"]\n",
        "      row_label_cols = [\"AU\", \"emotion\", \"emotion\", None, \"AU\", \"emotion\"]\n",
        "    else:\n",
        "      print('BUG IN THE CODE! CHECK get_label_from_index')\n",
        "      print('spreadsheet path is ', spreadsheet_path)\n",
        "\n",
        "\n",
        "    xls = pd.ExcelFile(spreadsheet_path)\n",
        "\n",
        "    for i, matrix in enumerate(matrices):\n",
        "        # Find the sheet ending with the current matrix name\n",
        "        sheet_name = next((s for s in xls.sheet_names if s.endswith(matrix)), None)\n",
        "        if sheet_name is not None:\n",
        "            # Load the sheet into a DataFrame, with the first row as column names\n",
        "            df = pd.read_excel(spreadsheet_path, sheet_name=sheet_name, header=0)\n",
        "\n",
        "            # Get the column labels from the DataFrame\n",
        "            col_labels = df.columns.tolist()[1:]\n",
        "\n",
        "            row_labels = df['Unnamed: 0'].tolist()\n",
        "\n",
        "            # Get the numerical entries in the sheet excluding columns \"AU\" and \"emotion\" and \"Unnamed: 0\"\n",
        "            numerical_entries = df.loc[:, ~df.columns.isin([\"AU\", \"emotion\", \"Unnamed: 0\"])].values.flatten()\n",
        "            numerical_entries = numerical_entries[~pd.isnull(numerical_entries)]\n",
        "\n",
        "            # Check if the index is within the range of numerical entries\n",
        "            if index < len(numerical_entries):\n",
        "                # Find the label corresponding to the index\n",
        "                row_index, col_index = divmod(index, len(col_labels))\n",
        "\n",
        "                return f\"{col_labels[col_index]} {row_labels[row_index]}\"\n",
        "\n",
        "            else:\n",
        "                index -= len(numerical_entries)\n",
        "\n",
        "    # Return None if the index is out of range or no suitable sheets found\n",
        "    print('BUG IN THE CODE! INDEX TOO LARGE! CHECK get_label_from_index')\n",
        "    print('spreadsheet path is ', spreadsheet_path)\n",
        "    return None\n",
        "\n",
        "def getTopFeaturesfromWeights(model_list, spreadsheet_path=FEATURE_LABEL_PATH+'openface_2.0_hours.xlsx'):\n",
        "  # given a list of linear regression models,\n",
        "  # returns their top 5 features (on average) from just weights!\n",
        "\n",
        "  coef_array = [model_now.coef_ for model_now in model_list]\n",
        "  coef_avg = np.mean(coef_array, axis=0)\n",
        "\n",
        "  top_5_features = np.argsort(np.abs(coef_avg))[::-1][:5]\n",
        "\n",
        "  top_5_english = [get_label_from_index(feat_ind, spreadsheet_path=spreadsheet_path) for feat_ind in top_5_features]\n",
        "\n",
        "  return top_5_english\n",
        "\n",
        "\n",
        "def featureAblate(vectors_array, y, do_lasso=False, do_ridge=False):\n",
        "  # runs one-left-out linear regression,\n",
        "  # deleting one feature at a time to determine most important features\n",
        "\n",
        "  # vectors_array -- numpy array of feature vectors\n",
        "  # y -- self-reported labels (e.g. for Mood, Anxiety, or something else)\n",
        "  # if do_lasso, does lasso regression\n",
        "  # if do_ridge, does ridge regression. Overrides do_lasso\n",
        "\n",
        "  # returns scores, prs\n",
        "  # scores -- (n_features, n_timestamps) numpy array of MSEs\n",
        "  # prs -- (n_features,) numpy vector of pearson's R\n",
        "\n",
        "  num_features = vectors_array.shape[1]\n",
        "  num_timestamps = vectors_array.shape[0]\n",
        "\n",
        "  scores = np.zeros((num_features, num_timestamps))\n",
        "  prs = np.zeros((num_features,))\n",
        "\n",
        "  # loop through each feature (for openface, 0 through 144) and delete just that\n",
        "  for deleteNow in range(num_features):\n",
        "    data = np.delete(vectors_array, deleteNow, axis=1)\n",
        "\n",
        "    # make into dictionary to feed into our lin reg function\n",
        "    data = {'placeholder': data}\n",
        "\n",
        "    scores_temp, preds, y, _ = linRegOneMetric(data, y, do_lasso=do_lasso, do_ridge=do_ridge)\n",
        "    scores_temp = scores_temp['placeholder']\n",
        "    preds = preds['placeholder']\n",
        "\n",
        "    # save MSEs\n",
        "    scores[deleteNow, :] =  scores_temp\n",
        "\n",
        "    # compute and save Pearson's R\n",
        "    pearson_corr, _ = pearsonr(y, preds)\n",
        "    prs[deleteNow] = pearson_corr\n",
        "\n",
        "  return scores, prs\n",
        "\n",
        "def featureAblate2D(vectors_array, y):\n",
        "  # runs one-left-out linear regression,\n",
        "  # deleting TWO features at a time to determine most important features\n",
        "\n",
        "  # vectors_array -- numpy array of feature vectors\n",
        "  # y -- self-reported labels (e.g. for Mood, Anxiety, or something else)\n",
        "\n",
        "  # returns prs\n",
        "  # prs -- (n_features, n_features) numpy vector of pearson's R\n",
        "  # Note: ALWAYS index into prs with first index LOWER than second!\n",
        "\n",
        "  num_features = vectors_array.shape[1]\n",
        "\n",
        "  prs = np.zeros((num_features,num_features))\n",
        "\n",
        "  # loop through each feature (for openface, 0 through 144) and delete just that\n",
        "  for deleteNow in range(num_features):\n",
        "    # delete a second one!\n",
        "    for secondDelete in range(deleteNow+1, num_features):\n",
        "      data = np.delete(vectors_array, [deleteNow, secondDelete], axis=1)\n",
        "\n",
        "      # make into dictionary to feed into our lin reg function\n",
        "      data = {'placeholder': data}\n",
        "\n",
        "      _, preds, _, _ = linRegOneMetric(data, y)\n",
        "      preds = preds['placeholder']\n",
        "\n",
        "      # compute and save Pearson's R\n",
        "      pearson_corr, _ = pearsonr(y, preds)\n",
        "      prs[deleteNow, secondDelete] = pearson_corr\n",
        "\n",
        "  return prs\n",
        "\n",
        "def featureAblate3D(vectors_array, y):\n",
        "  # runs one-left-out linear regression,\n",
        "  # deleting THREE features at a time to determine most important features\n",
        "\n",
        "  # vectors_array -- numpy array of feature vectors\n",
        "  # y -- self-reported labels (e.g. for Mood, Anxiety, or something else)\n",
        "\n",
        "  # returns prs\n",
        "  # prs -- (n_features, n_features, n_features) numpy vector of pearson's R\n",
        "  # Note: ALWAYS index into prs with earlier indices LOWER than subsequent ones.\n",
        "\n",
        "  num_features = vectors_array.shape[1]\n",
        "\n",
        "  prs = np.zeros((num_features, num_features, num_features))\n",
        "\n",
        "  # loop through each feature (for openface, 0 through 144) and delete just that\n",
        "  for deleteNow in range(num_features):\n",
        "    # delete a second one!\n",
        "    for secondDelete in range(deleteNow+1, num_features):\n",
        "      # delete a third one!\n",
        "      for thirdDelete in range(secondDelete+1, num_features):\n",
        "        data = np.delete(vectors_array, [deleteNow, secondDelete, thirdDelete], axis=1)\n",
        "\n",
        "        # make into dictionary to feed into our lin reg function\n",
        "        data = {'placeholder': data}\n",
        "\n",
        "        _, preds, _, _ = linRegOneMetric(data, y)\n",
        "        preds = preds['placeholder']\n",
        "\n",
        "        # compute and save Pearson's R\n",
        "        pearson_corr, _ = pearsonr(y, preds)\n",
        "        prs[deleteNow, secondDelete, thirdDelete] = pearson_corr\n",
        "\n",
        "  return prs\n",
        "\n",
        "def plotFeatAbMSEs(feat_ab_scores, original_mse_list, metric, time_radius, savepath, top_n=5, ax=None, spreadsheet_path=FEATURE_LABEL_PATH+'openface_2.0_hours.xlsx'):\n",
        "  # takes feat_ab_scores, a numpy array (n_features, n_timestamps) of MSEs\n",
        "  # outputs box and whisker plot of top_n features for the model\n",
        "\n",
        "  # procedure: get the top_n features with lowest mse averaged across timestamps\n",
        "  # make a box and whisker plot with each feature on x axis and MSEs on y axis\n",
        "  # for x axis labels, convert the index of each feature to english label\n",
        "  # by calling get_label_from_index(feat_ind)\n",
        "\n",
        "\n",
        "  # Get the average MSE across timestamps for each feature\n",
        "  avg_mses = np.mean(feat_ab_scores, axis=1)\n",
        "\n",
        "  # avg MSEs minus original_avg_MSE (make it difference!)\n",
        "  avg_mses = avg_mses - np.mean(original_mse_list)\n",
        "\n",
        "  # Get the indices of the top_n features with the highest difference in MSEs from original\n",
        "  top_indices = np.argsort(avg_mses)[-top_n:]\n",
        "  top_indices = top_indices[::-1]\n",
        "\n",
        "  # Get the English labels for the top_n features\n",
        "  top_labels = [get_label_from_index(ind, spreadsheet_path=spreadsheet_path) for ind in top_indices]\n",
        "\n",
        "  # Get the MSE values for the top_n features\n",
        "  top_mses = feat_ab_scores[top_indices]\n",
        "\n",
        "  # Adjust so it's top mses minus original\n",
        "  original_list_repeated = np.repeat(np.array(original_mse_list).reshape(1, -1), top_n, axis=0)\n",
        "  top_mses = top_mses - original_list_repeated\n",
        "\n",
        "  # Create a box and whisker plot\n",
        "  if ax is None:\n",
        "      original_ax = None\n",
        "      fig, ax = plt.subplots()\n",
        "  else:\n",
        "      original_ax = ax\n",
        "  ax.boxplot(top_mses.T, labels=top_labels, showmeans=True, meanprops={'marker': 'o', 'markerfacecolor': 'red', 'markersize': 10})\n",
        "\n",
        "  # Rotate x-axis labels by 45 degrees\n",
        "  ax.set_xticklabels(top_labels, rotation=45)\n",
        "\n",
        "  # Set the axis labels\n",
        "  ax.set_xlabel('Features')\n",
        "  ax.set_ylabel('Ablated - Original MSEs')\n",
        "\n",
        "  # Set the title\n",
        "  num_hrs = int(time_radius) / 60\n",
        "  if num_hrs > 1:\n",
        "      ax.set_title(f'Top {top_n} Features: {metric}, Time Window = {num_hrs} Hours')\n",
        "  else:\n",
        "      ax.set_title(f'Top {top_n} Features: {metric}, Time Window = {num_hrs} Hour')\n",
        "\n",
        "  plt.savefig(savepath, bbox_inches='tight')\n",
        "\n",
        "  # Show the plot if ax is None\n",
        "  if original_ax is None:\n",
        "      plt.show()\n",
        "\n",
        "\n",
        "  return top_indices, fig\n",
        "\n",
        "def plotFeatAbPRs(feat_ab_prs, original_r_val, metric, time_radius, savepath, top_n=5, ax=None, spreadsheet_path=FEATURE_LABEL_PATH+'openface_2.0_hours.xlsx'):\n",
        "  # takes feat_ab_prs, a numpy array (n_features, ) of Pearson's R vals post-ablation\n",
        "  # outputs bar plot of top_n features TO REMOVE for the model\n",
        "\n",
        "  # procedure: get the top_n features with highest pearson's R\n",
        "  # make a bar plot with each feature on x axis and pearson's R from feat_ab_prs on y axis\n",
        "  # for x axis labels, convert the index of each feature to english label\n",
        "  # by calling get_label_from_index(feat_ind)\n",
        "\n",
        "  # if ax is given, plot on ax. If ax=None, make new fig, ax\n",
        "\n",
        "\n",
        "  # Get the top_n features with highest Pearson's R values\n",
        "  top_features_indices = np.argsort(feat_ab_prs)[-top_n:]\n",
        "  top_features_indices = top_features_indices[::-1]\n",
        "\n",
        "  # Get the labels for the top_n features\n",
        "  top_features_labels = [get_label_from_index(index, spreadsheet_path=spreadsheet_path) for index in top_features_indices]\n",
        "\n",
        "  # Get the corresponding Pearson's R values for the top_n features\n",
        "  top_features_prs = feat_ab_prs[top_features_indices]\n",
        "\n",
        "  # Plot the bar plot\n",
        "  if ax is None:\n",
        "      fig, ax = plt.subplots()\n",
        "  ax.bar(top_features_labels, top_features_prs)\n",
        "\n",
        "  # Rotate x-axis labels by 45 degrees\n",
        "  ax.set_xticklabels(top_features_labels, rotation=45)\n",
        "\n",
        "  # Set plot title and axis labels\n",
        "  # Set the title\n",
        "  num_hrs = int(time_radius) / 60\n",
        "  if num_hrs > 1:\n",
        "      ax.set_title(f'Top {top_n} Features to Remove: {metric}, Time Window = {num_hrs} Hours')\n",
        "  else:\n",
        "      ax.set_title(f'Top {top_n} Features to Remove: {metric}, Time Window = {num_hrs} Hour')\n",
        "\n",
        "  ax.set_xlabel(\"Features\")\n",
        "  ax.set_ylabel(f\"Pearson's R (Original={round(original_r_val, 2)})\")\n",
        "\n",
        "  # Save the plot\n",
        "  plt.savefig(savepath, bbox_inches='tight')\n",
        "\n",
        "  # Show the plot if ax=None\n",
        "  if ax is None:\n",
        "      plt.show()\n",
        "\n",
        "def find_max_indices(array, top_n):\n",
        "    # Flatten the 2D array into a 1D array\n",
        "    flattened_array = array.flatten()\n",
        "\n",
        "    # Find the indices of the top n maximum values in the flattened array\n",
        "    max_indices = np.argsort(flattened_array)[-top_n:][::-1]\n",
        "\n",
        "    # Convert the flattened indices to the corresponding row and column indices in the original array\n",
        "    row_indices, col_indices = np.unravel_index(max_indices, array.shape)\n",
        "\n",
        "    # Combine the row and column indices into pairs\n",
        "    index_combinations = list(zip(row_indices, col_indices))\n",
        "\n",
        "    return index_combinations\n",
        "\n",
        "def plot_feat_scatterplots(vectors_array, y, feat_ind_list, metric, savepath, spreadsheet_path=FEATURE_LABEL_PATH+'openface_2.0_hours.xlsx'):\n",
        "    # for each feature, plot feature on x axis and self-report score on y axis\n",
        "    # vectors_array is the array of feature vectors for ONE time radius\n",
        "    # y - self-reports\n",
        "    # feat_ind_list - list of the indices of the top features\n",
        "    # metric -- e.g. Mood or Anxiety\n",
        "    # savepath - where to save the figure\n",
        "\n",
        "    plt.rcParams['lines.markersize'] = 15\n",
        "\n",
        "    num_plots = len(feat_ind_list)\n",
        "    num_cols = min([len(feat_ind_list), 4])\n",
        "    num_rows = (num_plots + num_cols - 1) // num_cols\n",
        "\n",
        "    r_list = []\n",
        "    p_list = []\n",
        "\n",
        "    # Calculate the desired figure size for larger plot\n",
        "    figsize = (28, 12)\n",
        "\n",
        "    # Create subplots with auto aspect ratio\n",
        "    fig, axes = plt.subplots(num_rows, num_cols, figsize=figsize)\n",
        "\n",
        "    #axes.set_adjustable('box')\n",
        "\n",
        "    if num_rows == 1:\n",
        "      axes = axes.reshape((1, num_cols))\n",
        "\n",
        "    # Flatten the axes array if necessary\n",
        "    if num_plots == 1:\n",
        "        fig, axes = plt.subplots(1, 1, figsize=figsize)\n",
        "        axes = np.array([axes]).reshape(1, 1)\n",
        "\n",
        "\n",
        "    # Loop through the dictionaries\n",
        "    for enum, i in enumerate(feat_ind_list):\n",
        "        x_list = vectors_array[:, i].astype(float)\n",
        "        y_list = np.array(y).astype(float)\n",
        "\n",
        "        #y_pred = np.array([i[0] for i in y_pred])\n",
        "\n",
        "        # Get the subplot coordinates\n",
        "        row = enum // num_cols\n",
        "        col = enum % num_cols\n",
        "\n",
        "        # Plot predictions on the subplot\n",
        "        pearson_corr, p_val = plot_predictions(x_list, y_list, randShuffleR=None, ax=axes[row, col])\n",
        "\n",
        "\n",
        "        axes[row, col].set_title(f'{metric} vs. {get_label_from_index(i, spreadsheet_path=spreadsheet_path)}', fontsize=24)\n",
        "\n",
        "\n",
        "        # Redo x-axis and y-axis labels for subplot\n",
        "        axes[row, col].set_xlabel(get_label_from_index(i, spreadsheet_path=spreadsheet_path), fontsize=24)\n",
        "        axes[row, col].set_ylabel('')\n",
        "\n",
        "        #axes[row, col].set_adjustable('box')\n",
        "\n",
        "    # Add overall title\n",
        "    fig.suptitle(f'Top {num_plots} Features for {metric}', fontsize=30, y=1.05)\n",
        "\n",
        "    # Set shared y-axis label\n",
        "    #fig.text(0.5, 0, f'Self-Reported {metric} Scores', ha='center', fontsize=24)\n",
        "    fig.text(-0.01, 0.5, f'Self-Reported {metric} Scores', va='center', rotation='vertical', fontsize=24)\n",
        "\n",
        "    # Adjust spacing and layout\n",
        "    fig.tight_layout()\n",
        "\n",
        "    plt.savefig(savepath, bbox_inches='tight')\n",
        "\n",
        "    plt.show()\n",
        "\n",
        "    return r_list, p_list, fig\n",
        "\n",
        "\n",
        "def extractOneMetric(metric, vectors_now, df_moodTracking=df_moodTracking, remove_outliers=False):\n",
        "  # extracts the vectors needed for linear regression\n",
        "  # e.g. Mood only, for all time windows\n",
        "  # metric -- a string that is a self-report metric (ex. 'Mood' or 'Pain')\n",
        "  # vectors_now -- our feature vectors (all)\n",
        "  # df_moodTracking -- load in and pre-process self-report google sheet\n",
        "\n",
        "  # returns vectors_return and y\n",
        "  # vectors_return -- a dictionary mapping time radius (in minutes) to features\n",
        "  # y -- a numpy array with labels (self-reported metrics)\n",
        "\n",
        "\n",
        "  y = df_moodTracking[metric].values.astype(float)\n",
        "\n",
        "  # # just valid indices (remove nan self-reports!)\n",
        "  # valid_indices = ~pd.isna(y)\n",
        "  # y = y[valid_indices]\n",
        "\n",
        "  # Initially, set valid_indices to include all indices\n",
        "  valid_indices = np.arange(len(y))\n",
        "\n",
        "  # Step 1: Remove NaN values\n",
        "  nan_mask = ~pd.isna(y)\n",
        "  y = y[nan_mask]\n",
        "  valid_indices = valid_indices[nan_mask]\n",
        "\n",
        "\n",
        "  if remove_outliers:\n",
        "    # Step 2: Remove outliers\n",
        "    mean_y = np.mean(y)\n",
        "    std_y = np.std(y)\n",
        "    outlier_mask = (y >= mean_y - 2 * std_y) & (y <= mean_y + 2 * std_y)\n",
        "    y = y[outlier_mask]\n",
        "    valid_indices = valid_indices[outlier_mask]\n",
        "\n",
        "\n",
        "\n",
        "  vectors_return = {}\n",
        "\n",
        "  # We will delete indices of self-reports where at least one timestamp doesn't have ANY data at all!\n",
        "  indices_to_delete = []\n",
        "\n",
        "  # loop through the timestamps\n",
        "  # Determine which timestamps to delete (indices_to_delete)\n",
        "  for i in vectors_now.keys():\n",
        "\n",
        "    vectors_one_timestamp = np.array([vectors_now[i][str_to_ts(dt)] for dt in df_moodTracking['Datetime']])\n",
        "\n",
        "    # we want just the valid features (where self-report is not nan)\n",
        "    vectors_one_timestamp = vectors_one_timestamp[valid_indices]\n",
        "\n",
        "    # Figure out the correct size of the vector and delete all others\n",
        "    correct_vector_dim = 0\n",
        "    for enum_num, vector in enumerate(vectors_one_timestamp):\n",
        "        if vector.size == 0:\n",
        "            indices_to_delete.append(enum_num)\n",
        "        elif vector.shape[0] > correct_vector_dim:\n",
        "          correct_vector_dim = vector.shape[0]\n",
        "    for enum_num, vector in enumerate(vectors_one_timestamp):\n",
        "        if vector.size > 0 and vector.shape[0] < correct_vector_dim:\n",
        "            indices_to_delete.append(enum_num)\n",
        "\n",
        "\n",
        "  # Delete those indices from all timestamps\n",
        "  for i in vectors_now.keys():\n",
        "\n",
        "    vectors_one_timestamp = np.array([vectors_now[i][str_to_ts(dt)] for dt in df_moodTracking['Datetime']])\n",
        "\n",
        "    # we want just the valid features (where self-report is not nan)\n",
        "    vectors_one_timestamp = vectors_one_timestamp[valid_indices]\n",
        "\n",
        "    # Delete indices from the full previous loop\n",
        "    vectors_one_timestamp = np.delete(vectors_one_timestamp, indices_to_delete, axis=0)\n",
        "\n",
        "    if vectors_one_timestamp.ndim == 1:\n",
        "      print(f'WARNING: NEEDED TO RESHAPE FOR TIME WINDOW {i}')\n",
        "      # Stack the arrays along a new axis to get a 2D array\n",
        "      vectors_one_timestamp = np.stack(vectors_one_timestamp, axis=0)\n",
        "\n",
        "\n",
        "\n",
        "    vectors_return[i] = vectors_one_timestamp\n",
        "\n",
        "  y = np.delete(y, indices_to_delete, axis=0)\n",
        "\n",
        "  # Make sure we get the right 2D shape for each time window\n",
        "  for i in vectors_return.keys():\n",
        "\n",
        "    vectors_one_timestamp = vectors_return[i]\n",
        "\n",
        "    # If it's still 1d, then let's force the right 2D shape\n",
        "    if vectors_one_timestamp.ndim == 1:\n",
        "      print(f'WARNING: NEEDED TO DOUBLE RESHAPE FOR TIME WINDOW {i}')\n",
        "      vectors_return[i] = vectors_one_timestamp.reshape(y.shape[0], -1)\n",
        "\n",
        "\n",
        "  return vectors_return, y\n",
        "\n",
        "\n",
        "def plot_pearsons_r_vs_alpha(pearson_r_list, ALPHAS_FOR_SEARCH, method, save_path):\n",
        "    \"\"\"\n",
        "    Plots Pearson's R values against Alphas and saves the plot to the specified path.\n",
        "\n",
        "    :param pearson_r_list: List of Pearson's R values.\n",
        "    :param ALPHAS_FOR_SEARCH: List of Alpha values.\n",
        "    :param method: The method used (string).\n",
        "    :param save_path: File path to save the plot.\n",
        "    \"\"\"\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    plt.plot(ALPHAS_FOR_SEARCH, pearson_r_list, marker='o')\n",
        "    plt.title(f'LASSO: Alpha Search {method}')\n",
        "    plt.xlabel('Alpha')\n",
        "    plt.ylabel(\"Pearson's R\")\n",
        "    plt.grid(True)\n",
        "    plt.savefig(save_path, bbox_inches='tight')\n",
        "    plt.close()\n",
        "\n"
      ],
      "metadata": {
        "id": "v9pC29y3V5vc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Alpha Search"
      ],
      "metadata": {
        "id": "ECLHmN7qYYiy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ALPHA PARAMETER SEARCH FOR LASSO - RUN THIS FIRST!\n",
        "\n",
        "all_metrics = [col for col in df_moodTracking.columns if col != 'Datetime']\n",
        "\n",
        "FILE_ENDING = '.png'\n",
        "\n",
        "# We are just searching using lasso regression\n",
        "#RESULTS_PREFIX_LIST = ['OF_L_', 'OGAU_L_', 'OFAUHSE_L_', 'OGAUHSE_L_', 'HSE_L_', 'ALL_L_']\n",
        "RESULTS_PREFIX_LIST = ['OGAU_L_', 'OGAUHSE_L_', 'HSE_L_']\n",
        "#RESULTS_PREFIX_LIST = ['OGAUHSE_L_']\n",
        "\n",
        "\n",
        "EMOTIONS_FOR_SEARCH = ['Mood'] # We are just searching on Mood\n",
        "TIME_WINDOW_FOR_SEARCH = '180' # We are just searching 3 hours\n",
        "\n",
        "# List of alpha values to search through\n",
        "#ALPHAS_FOR_SEARCH = np.arange(0, 1.6, 0.1)\n",
        "ALPHAS_FOR_SEARCH = np.arange(0, 5, 0.2)\n",
        "#ALPHAS_FOR_SEARCH = np.arange(0, 10, 0.2)\n",
        "\n",
        "# This will populate with the best alphas for each prefix in RESULTS_PREFIX_LIST\n",
        "best_alphas_lasso = {}\n",
        "\n",
        "for RESULTS_PREFIX in RESULTS_PREFIX_LIST:\n",
        "  do_lasso = False\n",
        "  do_ridge = False\n",
        "\n",
        "  if '_L_' in RESULTS_PREFIX:\n",
        "    do_lasso = True\n",
        "\n",
        "  if '_R_' in RESULTS_PREFIX:\n",
        "    do_ridge = True\n",
        "\n",
        "\n",
        "  if 'OF_' in RESULTS_PREFIX:\n",
        "    spreadsheet_path = FEATURE_LABEL_PATH+f'openface_0.5_hours.xlsx'\n",
        "    vectors_now = openface_vectors_dict\n",
        "    method_now = 'OpenFace'\n",
        "\n",
        "  elif 'OGAU_' in RESULTS_PREFIX:\n",
        "    spreadsheet_path = FEATURE_LABEL_PATH+'opengraphau_0.5_hours.xlsx'\n",
        "    vectors_now = opengraphau_vectors_dict\n",
        "    method_now = 'OpenGraphAU'\n",
        "\n",
        "  elif 'OFAUHSE_' in RESULTS_PREFIX:\n",
        "    spreadsheet_path = FEATURE_LABEL_PATH+'ofauhse_0.5_hours.xlsx'\n",
        "    vectors_now = ofauhsemotion_vectors_dict\n",
        "    method_now = 'OFAU+HSE'\n",
        "\n",
        "  elif 'OGAUHSE_' in RESULTS_PREFIX:\n",
        "    spreadsheet_path = FEATURE_LABEL_PATH+'ogauhse_0.5_hours.xlsx'\n",
        "    vectors_now = ogauhsemotion_vectors_dict\n",
        "    method_now = 'OGAU+HSE'\n",
        "\n",
        "  elif 'HSE_' in RESULTS_PREFIX:\n",
        "    spreadsheet_path = FEATURE_LABEL_PATH+'hsemotion_0.5_hours.xlsx'\n",
        "    vectors_now = hsemotion_vectors_dict\n",
        "    method_now = 'HSEmotion'\n",
        "\n",
        "  elif 'ALL_' in RESULTS_PREFIX:\n",
        "    spreadsheet_path = FEATURE_LABEL_PATH+'all_0.5_hours.xlsx'\n",
        "    vectors_now = all_vectors_dict\n",
        "    method_now = 'ALL(OF+OG+HSE)'\n",
        "\n",
        "\n",
        "  # Let's put each setting in its own folder!\n",
        "  os.makedirs(RESULTS_PATH_BASE + 'SEARCH_Alpha_Lasso/' + RESULTS_PREFIX, exist_ok=True)\n",
        "  results_prefix_unmodified = RESULTS_PREFIX\n",
        "  RESULTS_PREFIX = 'SEARCH_Alpha_Lasso/' + RESULTS_PREFIX + '/' + RESULTS_PREFIX\n",
        "\n",
        "  # This will store the best R, averaged across all metrics we're testing, for each alpha\n",
        "  pearson_r_list = []\n",
        "\n",
        "  for alpha_now in ALPHAS_FOR_SEARCH:\n",
        "\n",
        "    avg_best_R = 0\n",
        "\n",
        "    # Loop through EMOTIONS_FOR_SEARCH\n",
        "    for metric in EMOTIONS_FOR_SEARCH:\n",
        "      print('METRIC NOW: ', metric)\n",
        "      vectors_return, y = extractOneMetric(metric, vectors_now=vectors_now)\n",
        "\n",
        "      # Limit to just one time window for alpha search\n",
        "      tmp_vectors = vectors_return\n",
        "      vectors_return = {}\n",
        "      vectors_return[TIME_WINDOW_FOR_SEARCH] = tmp_vectors[TIME_WINDOW_FOR_SEARCH]\n",
        "      del tmp_vectors\n",
        "\n",
        "      scores, preds, y, models = linRegOneMetric(vectors_return, y, do_lasso=do_lasso, do_ridge=do_ridge, alpha=alpha_now)\n",
        "      scores_r, preds_r, _, models_r = linRegOneMetric(vectors_return, y, randShuffle=True, alpha=alpha_now)\n",
        "\n",
        "      # make scatterplots\n",
        "      randShuffleR, _, _ = plot_scatterplots(preds_r, y, f'{metric} Random Shuffle', RESULTS_PATH_BASE + f'{RESULTS_PREFIX}{metric}_linReg_scatterRand_{alpha_now}{FILE_ENDING}')\n",
        "      r_list, p_list, scatterFig = plot_scatterplots(preds, y, metric, RESULTS_PATH_BASE + f'{RESULTS_PREFIX}{metric}_linReg_scatterplots_{alpha_now}{FILE_ENDING}', randShuffleR=randShuffleR)\n",
        "\n",
        "      # Determine our best time radius for this metric based on Pearson's R\n",
        "      best_time_radius = list(scores.keys())[np.argmax(r_list)]\n",
        "      best_mse_list = scores[best_time_radius]\n",
        "      best_avg_mse = np.mean(scores[best_time_radius])\n",
        "      best_pearson_r = r_list[np.argmax(r_list)]\n",
        "\n",
        "      # Add to our avg best R\n",
        "      avg_best_R = avg_best_R + best_pearson_r\n",
        "\n",
        "      # bar plot for pearson r\n",
        "      rPlotFig = make_r_barplot(r_list, list(scores.keys()), metric, RESULTS_PATH_BASE + f'{RESULTS_PREFIX}{metric}_linReg_R_{alpha_now}{FILE_ENDING}', method_now=method_now)\n",
        "\n",
        "      # make MSE plot\n",
        "      MSEPlotFig = make_mse_boxplot(scores, metric, RESULTS_PATH_BASE + f'{RESULTS_PREFIX}{metric}_linReg_MSE_{alpha_now}{FILE_ENDING}', method_now=method_now)\n",
        "\n",
        "    # Add one R value for this alpha value to pearson_r_list\n",
        "    avg_best_R = avg_best_R / len(EMOTIONS_FOR_SEARCH)\n",
        "    pearson_r_list.append(avg_best_R)\n",
        "\n",
        "  # Plot R vs. alpha for this setting\n",
        "  plot_pearsons_r_vs_alpha(pearson_r_list=pearson_r_list, ALPHAS_FOR_SEARCH=ALPHAS_FOR_SEARCH, method=method_now, save_path=RESULTS_PATH_BASE + f'{RESULTS_PREFIX}{metric}_Alpha_Search{FILE_ENDING}')\n",
        "\n",
        "  # Find best alpha for this setting\n",
        "  best_index_of_alpha = np.argmax(pearson_r_list)\n",
        "  best_alpha_value = ALPHAS_FOR_SEARCH[best_index_of_alpha]\n",
        "  best_alphas_lasso[results_prefix_unmodified] = best_alpha_value\n"
      ],
      "metadata": {
        "id": "kfmB3Np39WyJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ALPHA PARAMETER SEARCH FOR RIDGE - RUN THIS FIRST!\n",
        "\n",
        "all_metrics = [col for col in df_moodTracking.columns if col != 'Datetime']\n",
        "\n",
        "FILE_ENDING = '.png'\n",
        "\n",
        "# We are just searching using ridge regression\n",
        "RESULTS_PREFIX_LIST = ['OF_R_', 'OGAU_R_', 'OFAUHSE_R_', 'OGAUHSE_R_', 'HSE_R_', 'ALL_R_']\n",
        "\n",
        "EMOTIONS_FOR_SEARCH = ['Mood'] # We are just searching on Mood\n",
        "TIME_WINDOW_FOR_SEARCH = '180' # We are just searching 3 hours\n",
        "\n",
        "# List of alpha values to search through\n",
        "ALPHAS_FOR_SEARCH = np.arange(0, 1.6, 0.1)\n",
        "\n",
        "# This will populate with the best alphas for each prefix in RESULTS_PREFIX_LIST\n",
        "best_alphas_ridge = {}\n",
        "\n",
        "for RESULTS_PREFIX in RESULTS_PREFIX_LIST:\n",
        "  do_lasso = False\n",
        "  do_ridge = False\n",
        "\n",
        "  if '_L_' in RESULTS_PREFIX:\n",
        "    do_lasso = True\n",
        "\n",
        "  if '_R_' in RESULTS_PREFIX:\n",
        "    do_ridge = True\n",
        "\n",
        "\n",
        "  if 'OF_' in RESULTS_PREFIX:\n",
        "    spreadsheet_path = FEATURE_LABEL_PATH+f'openface_2.0_hours.xlsx'\n",
        "    vectors_now = openface_vectors_dict\n",
        "    method_now = 'OpenFace'\n",
        "\n",
        "  elif 'OGAU_' in RESULTS_PREFIX:\n",
        "    spreadsheet_path = FEATURE_LABEL_PATH+'opengraphau_2.0_hours.xlsx'\n",
        "    vectors_now = opengraphau_vectors_dict\n",
        "    method_now = 'OpenGraphAU'\n",
        "\n",
        "  elif 'OFAUHSE_' in RESULTS_PREFIX:\n",
        "    spreadsheet_path = FEATURE_LABEL_PATH+'ofauhse_2.0_hours.xlsx'\n",
        "    vectors_now = ofauhsemotion_vectors_dict\n",
        "    method_now = 'OFAU+HSE'\n",
        "\n",
        "  elif 'OGAUHSE_' in RESULTS_PREFIX:\n",
        "    spreadsheet_path = FEATURE_LABEL_PATH+'ogauhse_2.0_hours.xlsx'\n",
        "    vectors_now = ogauhsemotion_vectors_dict\n",
        "    method_now = 'OGAU+HSE'\n",
        "\n",
        "  elif 'HSE_' in RESULTS_PREFIX:\n",
        "    spreadsheet_path = FEATURE_LABEL_PATH+'hsemotion_2.0_hours.xlsx'\n",
        "    vectors_now = hsemotion_vectors_dict\n",
        "    method_now = 'HSEmotion'\n",
        "\n",
        "  elif 'ALL_' in RESULTS_PREFIX:\n",
        "    spreadsheet_path = FEATURE_LABEL_PATH+'all_2.0_hours.xlsx'\n",
        "    vectors_now = all_vectors_dict\n",
        "    method_now = 'ALL(OF+OG+HSE)'\n",
        "\n",
        "\n",
        "  # Let's put each setting in its own folder!\n",
        "  os.makedirs(RESULTS_PATH_BASE + 'SEARCH_Alpha_Ridge/' + RESULTS_PREFIX, exist_ok=True)\n",
        "  results_prefix_unmodified = RESULTS_PREFIX\n",
        "  RESULTS_PREFIX = 'SEARCH_Alpha_Ridge/' + RESULTS_PREFIX + '/' + RESULTS_PREFIX\n",
        "\n",
        "  # This will store the best R, averaged across all metrics we're testing, for each alpha\n",
        "  pearson_r_list = []\n",
        "\n",
        "  for alpha_now in ALPHAS_FOR_SEARCH:\n",
        "\n",
        "    avg_best_R = 0\n",
        "\n",
        "    # Loop through EMOTIONS_FOR_SEARCH\n",
        "    for metric in EMOTIONS_FOR_SEARCH:\n",
        "      print('METRIC NOW: ', metric)\n",
        "      vectors_return, y = extractOneMetric(metric, vectors_now=vectors_now)\n",
        "\n",
        "      # Limit to just one time window for alpha search\n",
        "      tmp_vectors = vectors_return\n",
        "      vectors_return = {}\n",
        "      vectors_return[TIME_WINDOW_FOR_SEARCH] = tmp_vectors[TIME_WINDOW_FOR_SEARCH]\n",
        "      del tmp_vectors\n",
        "\n",
        "      scores, preds, y, models = linRegOneMetric(vectors_return, y, do_lasso=do_lasso, do_ridge=do_ridge, alpha=alpha_now)\n",
        "      scores_r, preds_r, _, models_r = linRegOneMetric(vectors_return, y, randShuffle=True, alpha=alpha_now)\n",
        "\n",
        "      # make scatterplots\n",
        "      randShuffleR, _, _ = plot_scatterplots(preds_r, y, f'{metric} Random Shuffle', RESULTS_PATH_BASE + f'{RESULTS_PREFIX}{metric}_linReg_scatterRand_{alpha_now}{FILE_ENDING}')\n",
        "      r_list, p_list, scatterFig = plot_scatterplots(preds, y, metric, RESULTS_PATH_BASE + f'{RESULTS_PREFIX}{metric}_linReg_scatterplots_{alpha_now}{FILE_ENDING}', randShuffleR=randShuffleR)\n",
        "\n",
        "      # Determine our best time radius for this metric based on Pearson's R\n",
        "      best_time_radius = list(scores.keys())[np.argmax(r_list)]\n",
        "      best_mse_list = scores[best_time_radius]\n",
        "      best_avg_mse = np.mean(scores[best_time_radius])\n",
        "      best_pearson_r = r_list[np.argmax(r_list)]\n",
        "\n",
        "      # Add to our avg best R\n",
        "      avg_best_R = avg_best_R + best_pearson_r\n",
        "\n",
        "      # bar plot for pearson r\n",
        "      rPlotFig = make_r_barplot(r_list, list(scores.keys()), metric, RESULTS_PATH_BASE + f'{RESULTS_PREFIX}{metric}_linReg_R_{alpha_now}{FILE_ENDING}', method_now=method_now)\n",
        "\n",
        "      # make MSE plot\n",
        "      MSEPlotFig = make_mse_boxplot(scores, metric, RESULTS_PATH_BASE + f'{RESULTS_PREFIX}{metric}_linReg_MSE_{alpha_now}{FILE_ENDING}', method_now=method_now)\n",
        "\n",
        "    # Add one R value for this alpha value to pearson_r_list\n",
        "    avg_best_R = avg_best_R / len(EMOTIONS_FOR_SEARCH)\n",
        "    pearson_r_list.append(avg_best_R)\n",
        "\n",
        "  # Find best alpha for this setting\n",
        "  best_index_of_alpha = np.argmax(pearson_r_list)\n",
        "  best_alpha_value = ALPHAS_FOR_SEARCH[best_index_of_alpha]\n",
        "  best_alphas_ridge[results_prefix_unmodified] = best_alpha_value\n"
      ],
      "metadata": {
        "id": "5_kuIrRlJGZX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# SAVE VARIABLES\n",
        "\n",
        "save_var(best_alphas_lasso, forced_name=f'best_alphas_lasso_{PAT_SHORT_NAME}')\n",
        "\n",
        "#save_var(best_alphas_ridge, forced_name=f'best_alphas_ridge_{PAT_SHORT_NAME}')\n"
      ],
      "metadata": {
        "id": "IR_M44vjPnVf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# LOAD VARIABLES\n",
        "\n",
        "best_alphas_lasso = load_var(f'best_alphas_lasso_{PAT_SHORT_NAME}')\n",
        "\n",
        "#best_alphas_ridge = load_var(f'best_alphas_ridge_{PAT_SHORT_NAME}')\n",
        "\n"
      ],
      "metadata": {
        "id": "uVIn5cW7P1in"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Core Plots"
      ],
      "metadata": {
        "id": "LbrmWuiEYghJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# GENERATE ALL PLOTS! ONE CODE BLOCK\n",
        "\n",
        "if 'best_alphas_lasso' not in globals():\n",
        "    raise NameError(\"GO RUN THE LASSO ALPHA PARAMETER SEARCH BLOCK FIRST!\")\n",
        "\n",
        "# if 'best_alphas_ridge' not in globals():\n",
        "#     raise NameError(\"GO RUN THE RIDGE ALPHA PARAMETER SEARCH BLOCK FIRST!\")\n",
        "\n",
        "\n",
        "#all_metrics = [col for col in df_moodTracking.columns if col != 'Datetime']\n",
        "#all_metrics = ['Mood', 'Anxiety', 'Hunger']\n",
        "all_metrics = ['Mood']\n",
        "\n",
        "\n",
        "FILE_ENDING = '.png'\n",
        "# RESULTS_PREFIX_LIST = ['OF_', 'OGAU_', 'OFAUHSE_', 'OGAUHSE_', 'HSE_', 'ALL_',\n",
        "#                        'OF_L_', 'OGAU_L_', 'OFAUHSE_L_', 'OGAUHSE_L_', 'HSE_L_', 'ALL_L_',\n",
        "#                        'OF_R_', 'OGAU_R_', 'OFAUHSE_R_', 'OGAUHSE_R_', 'HSE_R_', 'ALL_R_']\n",
        "\n",
        "# RESULTS_PREFIX_LIST = ['OF_L_', 'OGAUHSE_L_', 'OGAU_L_', 'OFAUHSE_L_', 'HSE_L_', 'ALL_L_']\n",
        "\n",
        "RESULTS_PREFIX_LIST = ['OGAU_L_', 'OGAUHSE_L_', 'HSE_L_']\n",
        "\n",
        "#RESULTS_PREFIX_LIST = ['OGAUHSE_L_']\n",
        "\n",
        "# Do we remove ground truth labels that are over 2 standard deviations from the mean?\n",
        "REMOVE_OUTLIERS = False\n",
        "\n",
        "\n",
        "for RESULTS_PREFIX in RESULTS_PREFIX_LIST:\n",
        "  do_lasso = False\n",
        "  do_ridge = False\n",
        "\n",
        "  if '_L_' in RESULTS_PREFIX:\n",
        "    do_lasso = True\n",
        "\n",
        "  if '_R_' in RESULTS_PREFIX:\n",
        "    do_ridge = True\n",
        "\n",
        "\n",
        "  if 'OF_' in RESULTS_PREFIX:\n",
        "    spreadsheet_path = FEATURE_LABEL_PATH+f'openface_0.5_hours.xlsx'\n",
        "    vectors_now = openface_vectors_dict\n",
        "    method_now = 'OpenFace'\n",
        "\n",
        "  elif 'OGAU_' in RESULTS_PREFIX:\n",
        "    spreadsheet_path = FEATURE_LABEL_PATH+'opengraphau_0.5_hours.xlsx'\n",
        "    vectors_now = opengraphau_vectors_dict\n",
        "    method_now = 'OpenGraphAU'\n",
        "\n",
        "  elif 'OFAUHSE_' in RESULTS_PREFIX:\n",
        "    spreadsheet_path = FEATURE_LABEL_PATH+'ofauhse_0.5_hours.xlsx'\n",
        "    vectors_now = ofauhsemotion_vectors_dict\n",
        "    method_now = 'OFAU+HSE'\n",
        "\n",
        "  elif 'OGAUHSE_' in RESULTS_PREFIX:\n",
        "    spreadsheet_path = FEATURE_LABEL_PATH+'ogauhse_0.5_hours.xlsx'\n",
        "    vectors_now = ogauhsemotion_vectors_dict\n",
        "    method_now = 'OGAU+HSE'\n",
        "\n",
        "  elif 'HSE_' in RESULTS_PREFIX:\n",
        "    spreadsheet_path = FEATURE_LABEL_PATH+'hsemotion_0.5_hours.xlsx'\n",
        "    vectors_now = hsemotion_vectors_dict\n",
        "    method_now = 'HSEmotion'\n",
        "\n",
        "  elif 'ALL_' in RESULTS_PREFIX:\n",
        "    spreadsheet_path = FEATURE_LABEL_PATH+'all_0.5_hours.xlsx'\n",
        "    vectors_now = all_vectors_dict\n",
        "    method_now = 'ALL(OF+OG+HSE)'\n",
        "\n",
        "\n",
        "  # Let's put each setting in its own folder!\n",
        "  os.makedirs(RESULTS_PATH_BASE + RESULTS_PREFIX, exist_ok=True)\n",
        "  results_prefix_unmodified = RESULTS_PREFIX\n",
        "  RESULTS_PREFIX = RESULTS_PREFIX + '/' + RESULTS_PREFIX\n",
        "\n",
        "\n",
        "  # Loop through metrics (Anxiety, Depression, Mood, etc.)\n",
        "  for metric in all_metrics:\n",
        "    print('METRIC NOW: ', metric)\n",
        "    if do_lasso:\n",
        "      alpha_now = best_alphas_lasso[results_prefix_unmodified]\n",
        "    elif do_ridge:\n",
        "      alpha_now = best_alphas_ridge[results_prefix_unmodified]\n",
        "    else:\n",
        "      # Neither lasso nor ridge, so alpha is irrelevant\n",
        "      alpha_now = 1.0\n",
        "\n",
        "    vectors_return, y = extractOneMetric(metric, vectors_now=vectors_now, remove_outliers=REMOVE_OUTLIERS)\n",
        "    scores, preds, y, models = linRegOneMetric(vectors_return, y, do_lasso=do_lasso, do_ridge=do_ridge, alpha=alpha_now)\n",
        "    scores_r, preds_r, _, models_r = linRegOneMetric(vectors_return, y, randShuffle=True, alpha=alpha_now)\n",
        "\n",
        "    # make scatterplots\n",
        "    randShuffleR, _, _ = plot_scatterplots(preds_r, y, f'{metric} Random Shuffle', RESULTS_PATH_BASE + f'{RESULTS_PREFIX}{metric}_linReg_scatterRand{FILE_ENDING}')\n",
        "    r_list, p_list, scatterFig = plot_scatterplots(preds, y, metric, RESULTS_PATH_BASE + f'{RESULTS_PREFIX}{metric}_linReg_scatterplots{FILE_ENDING}', randShuffleR=randShuffleR)\n",
        "\n",
        "    # Determine our best time radius for this metric based on Pearson's R\n",
        "    best_time_radius = list(scores.keys())[np.argmax(r_list)]\n",
        "    best_mse_list = scores[best_time_radius]\n",
        "    best_avg_mse = np.mean(scores[best_time_radius])\n",
        "    best_pearson_r = r_list[np.argmax(r_list)]\n",
        "\n",
        "    # bar plot for pearson r\n",
        "    rPlotFig = make_r_barplot(r_list, list(scores.keys()), metric, RESULTS_PATH_BASE + f'{RESULTS_PREFIX}{metric}_linReg_R{FILE_ENDING}', method_now=method_now)\n",
        "\n",
        "    # make MSE plot\n",
        "    MSEPlotFig = make_mse_boxplot(scores, metric, RESULTS_PATH_BASE + f'{RESULTS_PREFIX}{metric}_linReg_MSE{FILE_ENDING}', method_now=method_now)\n",
        "\n",
        "    # Feature ablation\n",
        "    feat_ab_scores, feat_ab_prs = featureAblate(vectors_return[best_time_radius], y, do_lasso=do_lasso, do_ridge=do_ridge)\n",
        "\n",
        "    top_indices, featAbMSEFig = plotFeatAbMSEs(feat_ab_scores, best_mse_list, metric, best_time_radius, savepath=RESULTS_PATH_BASE + f'{RESULTS_PREFIX}{metric}_featAblate_MSEs{FILE_ENDING}', spreadsheet_path=spreadsheet_path)\n",
        "    plotFeatAbPRs(feat_ab_prs, best_pearson_r, metric, best_time_radius, savepath=RESULTS_PATH_BASE + f'{RESULTS_PREFIX}{metric}_featAblate_R{FILE_ENDING}', spreadsheet_path=spreadsheet_path)\n",
        "\n",
        "    # extract just ONE scatterplot (the best pearson's R) and save it individually\n",
        "    plt.rcParams['lines.markersize'] = 9\n",
        "    _, _, bestScatterFig = plot_predictions(y, preds[best_time_radius], randShuffleR=randShuffleR[np.argmax(r_list)], ax=None, time_rad=best_time_radius, metric=metric)\n",
        "    bestScatterFig.savefig(RESULTS_PATH_BASE + f'{RESULTS_PREFIX}{metric}_linReg_bestScatter{FILE_ENDING}', bbox_inches='tight')\n",
        "\n",
        "    # Plot top n features vs. self-reported scores\n",
        "    PLOT_NOW = 3\n",
        "    plot_feat_scatterplots(vectors_array=vectors_return[best_time_radius], y=y, feat_ind_list=top_indices[:PLOT_NOW], metric=metric, savepath=RESULTS_PATH_BASE + f'{RESULTS_PREFIX}{metric}_topFeats{FILE_ENDING}', spreadsheet_path=spreadsheet_path)\n"
      ],
      "metadata": {
        "id": "EXn-zIhdEGk0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Combine 4 Figures to One"
      ],
      "metadata": {
        "id": "JsjC2imS8sN2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# paths\n",
        "RESULTS_PREFIX = 'OF_'\n",
        "FILE_ENDING = '.png'\n",
        "metric = 'Mood'\n",
        "path_a = RESULTS_PATH_BASE + f'{metric}_linReg_bestScatter{FILE_ENDING}'\n",
        "path_b = RESULTS_PATH_BASE + f'{metric}_linReg_MSE{FILE_ENDING}'\n",
        "path_c = RESULTS_PATH_BASE + f'{metric}_linReg_R{FILE_ENDING}'\n",
        "path_d = RESULTS_PATH_BASE + f'{metric}_featAblate_MSEs{FILE_ENDING}'\n",
        "\n",
        "# Define the desired dimensions for each panel\n",
        "panel_width = 1000  # Adjust as needed\n",
        "panel_height = 1000  # Adjust as needed\n",
        "\n",
        "# Open and resize the images\n",
        "image_a = Image.open(path_a)\n",
        "#resize((panel_width, panel_height), Image.ANTIALIAS)\n",
        "image_b = Image.open(path_b).resize((panel_width, panel_height), Image.ANTIALIAS)\n",
        "image_c = Image.open(path_c).resize((panel_width, panel_height), Image.ANTIALIAS)\n",
        "image_d = Image.open(path_d).resize((panel_width, panel_height), Image.ANTIALIAS)\n",
        "\n",
        "# Create a new blank image for the combined figure\n",
        "combined_width = 2 * panel_width\n",
        "combined_height = 2 * panel_height\n",
        "combined_image = Image.new(\"RGB\", (combined_width, combined_height))\n",
        "\n",
        "# Paste the images onto the combined image\n",
        "combined_image.paste(image_a, (0, 0))\n",
        "combined_image.paste(image_b, (panel_width, 0))\n",
        "combined_image.paste(image_c, (0, panel_height))\n",
        "combined_image.paste(image_d, (panel_width, panel_height))\n",
        "\n",
        "# Display the combined image\n",
        "plt.imshow(combined_image)\n",
        "plt.axis('off')  # Hide the axis\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "xBxLMEZM90ZG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "40IS0u3OCDmz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Remove Feature = Better Performance?"
      ],
      "metadata": {
        "id": "NgPjqGH08p2E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "all_metrics"
      ],
      "metadata": {
        "id": "OYjchlS-ep5v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "get_label_from_index(99)"
      ],
      "metadata": {
        "id": "wmZh6eJZf1MN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.where(feat_ab_prs > 0.81)"
      ],
      "metadata": {
        "id": "WNgbibuNbLSg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "metric = 'Mood'\n",
        "vectors_return, y = extractOneMetric(metric)\n",
        "X_120 = vectors_return['120']\n",
        "X_120_59 = np.delete(X_120, 59, axis=1)\n",
        "X_120_99 = np.delete(X_120, 99, axis=1)\n",
        "X_120_59_99 = np.delete(X_120, [59, 99], axis=1)\n",
        "\n",
        "X_120_140 = np.delete(X_120, 140, axis=1)\n",
        "\n",
        "scores, preds, y, models = linRegOneMetric({'120': X_120_140}, y)\n",
        "r_list, p_list, scatterFig = plot_scatterplots(preds, y, metric, f'/content/{metric}_140.png')\n"
      ],
      "metadata": {
        "id": "H9LUm0dmbao6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def find_highly_correlated_features(X):\n",
        "    # Compute the correlation matrix\n",
        "    correlation_matrix = np.corrcoef(X, rowvar=False)\n",
        "\n",
        "    # Get the absolute correlation values\n",
        "    abs_correlation = np.abs(correlation_matrix)\n",
        "\n",
        "    # Set diagonal elements to 0 to avoid self-correlation\n",
        "    np.fill_diagonal(abs_correlation, 0)\n",
        "\n",
        "    # Find the indices of the maximum correlation values\n",
        "    indices = np.unravel_index(abs_correlation.argsort(axis=None)[-3:], abs_correlation.shape)\n",
        "\n",
        "    # Get the most highly correlated feature pairs\n",
        "    feature_pairs = [(indices[0][i], indices[1][i]) for i in range(3)]\n",
        "\n",
        "    return feature_pairs"
      ],
      "metadata": {
        "id": "zZvf1uq2g8j8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "find_highly_correlated_features(X_120)"
      ],
      "metadata": {
        "id": "sRhoUPG0g91J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prs_2d_mood_90 = featureAblate2D(vectors_return[best_time_radius], y)"
      ],
      "metadata": {
        "id": "bdlQudz1FTfR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def find_max_indices(array, top_n):\n",
        "    # Flatten the 2D array into a 1D array\n",
        "    flattened_array = array.flatten()\n",
        "\n",
        "    # Find the indices of the top n maximum values in the flattened array\n",
        "    max_indices = np.argsort(flattened_array)[-top_n:][::-1]\n",
        "\n",
        "    # Convert the flattened indices to the corresponding row and column indices in the original array\n",
        "    row_indices, col_indices = np.unravel_index(max_indices, array.shape)\n",
        "\n",
        "    # Combine the row and column indices into pairs\n",
        "    index_combinations = list(zip(row_indices, col_indices))\n",
        "\n",
        "    return index_combinations\n"
      ],
      "metadata": {
        "id": "i79gNTZNvT_g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "find_max_indices(prs_2d_mood_90, 5)"
      ],
      "metadata": {
        "id": "xuFWn_qgvUB4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prs_2d_mood_90[3, 59]"
      ],
      "metadata": {
        "id": "qSR0pWaBviU_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "metric = 'Mood'\n",
        "vectors_return, y = extractOneMetric(metric)\n",
        "X_120 = vectors_return['120']\n",
        "X_120_59 = np.delete(X_120, 59, axis=1)\n",
        "X_120_99 = np.delete(X_120, 99, axis=1)\n",
        "X_120_51_59 = np.delete(X_120, [51, 59], axis=1)\n",
        "\n",
        "X_120_140 = np.delete(X_120, 140, axis=1)\n",
        "\n",
        "scores, preds, y, models = linRegOneMetric({'120': X_120_51_59}, y)\n",
        "r_list, p_list, scatterFig = plot_scatterplots(preds, y, metric, f'/content/{metric}_51_59.png')\n"
      ],
      "metadata": {
        "id": "NILzULervrgO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "jzPrxm8Nqk27"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Binary Classification (Smile, Yawn, etc.)\n",
        "\n",
        "Note: this is code for using the longer windows (e.g. 4 hours) to detect smile, yawn, and other short-term behaviors. We are no longer using this! Make sure to use the LogReg Mapping section above instead."
      ],
      "metadata": {
        "id": "kgTxVzgzgoI2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import roc_curve, roc_auc_score, confusion_matrix\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "def plot_roc(model, X_test, y_test, save_path, title='Receiver Operating Characteristic (ROC) Curve', verbose=False):\n",
        "    # Predict probabilities for the positive class\n",
        "    y_prob = model.predict_proba(X_test)[:, 1]\n",
        "\n",
        "    # Compute false positive rate, true positive rate, and thresholds\n",
        "    fpr, tpr, thresholds = roc_curve(y_test, y_prob)\n",
        "\n",
        "    # Plot the ROC curve\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    plt.plot(fpr, tpr, label='ROC Curve')\n",
        "    plt.plot([0, 1], [0, 1], linestyle='--', color='r', label='Random Chance')\n",
        "    plt.xlabel('False Positive Rate')\n",
        "    plt.ylabel('True Positive Rate')\n",
        "    plt.title(title)\n",
        "    plt.savefig(save_path, bbox_inches='tight')\n",
        "    if verbose:\n",
        "      plt.show()\n",
        "\n",
        "    # Compute AUROC (Area Under the ROC Curve)\n",
        "    auroc = roc_auc_score(y_test, y_prob)\n",
        "    if verbose:\n",
        "      print('AUROC: {:.4f}'.format(auroc))\n",
        "\n",
        "    # Compute confusion matrix\n",
        "    y_pred = model.predict(X_test)\n",
        "    tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
        "\n",
        "    # Compute specificity and sensitivity\n",
        "    specificity = tn / (tn + fp)\n",
        "    sensitivity = tp / (tp + fn)\n",
        "    if verbose:\n",
        "      print('Specificity: {:.4f}'.format(specificity))\n",
        "      print('Sensitivity: {:.4f}'.format(sensitivity))\n",
        "\n",
        "    return auroc, specificity, sensitivity\n",
        "\n",
        "\n",
        "def prepare_data(datetime_features_dict, df):\n",
        "    # Convert datetime_features_dict to DataFrame\n",
        "    feature_df = pd.DataFrame.from_dict(datetime_features_dict, orient='index')\n",
        "    feature_df.index.name = 'Datetime'\n",
        "\n",
        "    # Convert Datetime column in df to datetime type\n",
        "    df['Datetime'] = pd.to_datetime(df['Datetime'])\n",
        "\n",
        "    # Concatenate feature DataFrame with df\n",
        "    merged_df = pd.concat([df.set_index('Datetime'), feature_df], axis=1, join='inner')\n",
        "\n",
        "    # Separate features and target variable\n",
        "    X = merged_df.drop(['EventDetected'], axis=1)\n",
        "    y = merged_df['EventDetected']\n",
        "\n",
        "    y = y.astype(int)\n",
        "\n",
        "\n",
        "    # Split the data into training and testing sets\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=25)\n",
        "\n",
        "    return X_train, X_test, y_train, y_test\n",
        "\n",
        "def get_metrics_binClass(vectors_dict, labels_df, save_path, title, verbose=False):\n",
        "  auroc_dict = {}\n",
        "  acc_dict = {}\n",
        "\n",
        "  for key in vectors_dict.keys():\n",
        "    num_seconds = round(float(key)*60)\n",
        "    if verbose:\n",
        "      print(f'CURRENT WINDOW: {num_seconds} seconds')\n",
        "    X_train, X_test, y_train, y_test = prepare_data(vectors_dict[key], labels_df)\n",
        "\n",
        "    # Get the indices of missing values in X_train\n",
        "    missing_indices_train = X_train[X_train.isnull().any(axis=1)].index\n",
        "\n",
        "    # Get the indices of missing values in X_test\n",
        "    missing_indices_test = X_test[X_test.isnull().any(axis=1)].index\n",
        "\n",
        "    # Remove NaN values from X_train and X_test\n",
        "    X_train = X_train.dropna()\n",
        "    X_test = X_test.dropna()\n",
        "\n",
        "    # Remove corresponding indices from y_train and y_test\n",
        "    y_train = y_train.drop(missing_indices_train)\n",
        "    y_test = y_test.drop(missing_indices_test)\n",
        "\n",
        "    # Train Logistic Regression model\n",
        "    logreg_model = LogisticRegression()\n",
        "    logreg_model.fit(X_train, y_train)\n",
        "\n",
        "    # Evalute model\n",
        "    auroc, specificity, sensitivity = plot_roc(logreg_model, X_test, y_test, save_path=save_path[:-4] + f'_{num_seconds}.png', title=title + f', Window = {num_seconds} s', verbose=verbose)\n",
        "    model_acc = calculate_accuracy(logreg_model, X_test, y_test)\n",
        "\n",
        "    auroc_dict[key] = auroc\n",
        "    acc_dict[key] = model_acc\n",
        "\n",
        "  return auroc_dict, acc_dict\n",
        "\n",
        "def plot_auroc_dict(auroc_dict, save_path, title_prefix, verbose=False):\n",
        "    plt.figure(figsize=(8, 6))  # Create a new figure\n",
        "    time_windows = []\n",
        "    aurocs = []\n",
        "\n",
        "    # Convert time window from minutes to seconds and collect the data\n",
        "    for window, auroc in auroc_dict.items():\n",
        "        time_windows.append(float(window) * 60)  # Convert minutes to seconds\n",
        "        aurocs.append(auroc)\n",
        "\n",
        "    # Plot the data\n",
        "    plt.plot(time_windows, aurocs, marker='o')\n",
        "    plt.xlabel('Time Window (seconds)')\n",
        "    plt.ylabel('AUROC')\n",
        "    plt.title(f'{title_prefix}: AUROC vs. Time Window')\n",
        "    plt.savefig(save_path, bbox_inches='tight')\n",
        "    if verbose:\n",
        "      plt.show()\n",
        "\n",
        "\n",
        "def plot_acc_dict(acc_dict, save_path, title_prefix, verbose=False):\n",
        "    plt.figure(figsize=(8, 6))  # Create a new figure\n",
        "    time_windows = []\n",
        "    accs = []\n",
        "\n",
        "    # Convert time window from minutes to seconds and collect the data\n",
        "    for window, auroc in acc_dict.items():\n",
        "        time_windows.append(float(window) * 60)  # Convert minutes to seconds\n",
        "        accs.append(auroc)\n",
        "\n",
        "    # Plot the data\n",
        "    plt.plot(time_windows, accs, marker='o')\n",
        "    plt.xlabel('Time Window (seconds)')\n",
        "    plt.ylabel('Test Set Accuracy')\n",
        "    plt.title(f'{title_prefix}: Accuracy vs. Time Window')\n",
        "    plt.savefig(save_path, bbox_inches='tight')\n",
        "    if verbose:\n",
        "      plt.show()\n",
        "\n",
        "def calculate_accuracy(model, X_test, y_test):\n",
        "    # Make predictions on the test set\n",
        "    y_pred = model.predict(X_test)\n",
        "\n",
        "    # Calculate accuracy\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "\n",
        "    return accuracy"
      ],
      "metadata": {
        "id": "0Wcz3A-wgp7o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "pipeline_dict = {\n",
        "    'HSE': (hsemotion_vectors_dict, 'HSE_metrics.png', 'HSEmotion'),\n",
        "    'OFAU': (openface_vectors_dict, 'OFAU_metrics.png', 'OpenFace'),\n",
        "    'OGAU': (opengraphau_vectors_dict, 'OGAU_metrics.png', 'OpenGraphAU'),\n",
        "    'OFAUHSE': (ofauhsemotion_vectors_dict, 'OFAUHSE_metrics.png', 'OFAU + HSE'),\n",
        "    'OGAUHSE': (ogauhsemotion_vectors_dict, 'OGAUHSE_metrics.png', 'OGAU + HSE'),\n",
        "    'ALL': (all_vectors_dict, 'ALL_metrics.png', 'ALL (OF + OG + HSE)')\n",
        "}\n",
        "\n",
        "for pipeline_label, (vectors_dict, save_file, title_prefix) in pipeline_dict.items():\n",
        "  auroc_dict, acc_dict = get_metrics_binClass(vectors_dict, Final_Smile_Labels, save_path=RESULTS_PATH_BASE + \"SMILE/\" + save_file, title=f'{title_prefix}: Automated Smile Detection', verbose=False)\n",
        "  plot_auroc_dict(auroc_dict, save_path=RESULTS_PATH_BASE + \"SMILE/\" + save_file, title_prefix=title_prefix, verbose=True)\n",
        "  plot_acc_dict(acc_dict, save_path=RESULTS_PATH_BASE + \"SMILE/\" + save_file[:-4] + '_acc.png', title_prefix=title_prefix, verbose=True)"
      ],
      "metadata": {
        "id": "aHeuj256pt9O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4vR5lPJpbqKS"
      },
      "source": [
        "# OLD Linear Regression (with and without dim reduction)\n",
        "\n",
        "There is a data leak somewhere - see the new code above. Keeping this here just for reference.\n",
        "\n",
        "Dimensionality reduction fails here, especially for CEBRA. Seems to create a model that maps every feature vector to the same point (yielding a straight line on the scattplot)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install cebra -qq\n",
        "#!pip install --upgrade umap-learn -qq # not using umap anymore"
      ],
      "metadata": {
        "id": "5qbIidqjJMpJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fxQ1yT0saw5s"
      },
      "outputs": [],
      "source": [
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.decomposition import PCA\n",
        "# import umap.umap_ as umap\n",
        "from sklearn.manifold import LocallyLinearEmbedding\n",
        "from sklearn.linear_model import Lasso\n",
        "from sklearn.linear_model import Ridge\n",
        "import cebra\n",
        "\n",
        "import numpy as np\n",
        "import random\n",
        "\n",
        "def set_seed(x=5):\n",
        "  np.random.seed(x)\n",
        "  random.seed(x)\n",
        "\n",
        "\n",
        "set_seed()\n",
        "\n",
        "# ensure you have loaded df_moodTracking already! Check the \"Mood Tracking Sheet\" header\n",
        "\n",
        "def runLinReg(VECTORS_NOW, N_COMPONENTS, verbose=True, random_shuffle=False, random_generate=False):\n",
        "    # Trains linear regression models via one-left-out learning.\n",
        "    # Accesses df_moodTracking for each self-report metric\n",
        "\n",
        "    \"\"\"\n",
        "    Models currently included: basic linear regression, PCA + linReg, LLE + linReg,\n",
        "    CEBRA-Time + linReg, Ridge (L2 regularizer linReg), PCA + Ridge, LLE + Ridge,\n",
        "    CEBRA-Time + Ridge\n",
        "    \"\"\"\n",
        "\n",
        "\n",
        "    \"\"\"\n",
        "    INPUTS:\n",
        "    VECTORS_NOW -- The feature vectors from the pipeline we are testing now.\n",
        "    Format should be a dictionary with datetimes as keys, and flattened numpy arrays as values\n",
        "\n",
        "    N_COMPONENTS -- Number of components to do dimensionality reduction to\n",
        "\n",
        "    verbose -- At the end, do you want to print the average MSE for each model and self-report metric?\n",
        "\n",
        "    random_shuffle -- yes/no should we randomly shuffle the real labels for each self-report metric\n",
        "\n",
        "    random_generate -- yes/no should we randomly generate labels from 0 to 1 for each self-report metric\n",
        "    In place of the real labels. If random_generate = True, it overrides random_shuffle.\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "\n",
        "    \"\"\"\n",
        "    Outputs several dictionaries: models_dict, mse_dict, transforms_dict, best_dict\n",
        "\n",
        "    See the bottom of this function for a list of keys to each dictionary.\n",
        "\n",
        "    Here's an example value broken down: Within models_dict is 'models_pca'\n",
        "    This has keys that are datetimes, and values that are dictionaries.\n",
        "    Each of these dictionaries has keys that are emotions, and values that are models.\n",
        "    Thus, you can find the model from the combination of any given datetime + self-report metric\n",
        "    Where the datetime key is the one metric left out in the model's training.\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "\n",
        "    models = {}\n",
        "    models_pca = {}\n",
        "    #models_umap = {}\n",
        "    models_lle = {}\n",
        "    models_cebra = {}\n",
        "    models_ridge = {}\n",
        "    models_ridge_pca = {}\n",
        "    models_ridge_lle = {}\n",
        "    models_ridge_cebra = {}\n",
        "    best_models = {}\n",
        "\n",
        "    mse_scores = {}\n",
        "    mse_scores_pca = {}\n",
        "    #mse_scores_umap = {}\n",
        "    mse_scores_lle = {}\n",
        "    mse_scores_cebra = {}\n",
        "    mse_scores_ridge = {}\n",
        "    mse_scores_ridge_pca = {}\n",
        "    mse_scores_ridge_lle = {}\n",
        "    mse_scores_ridge_cebra = {}\n",
        "    best_mse_scores = {}\n",
        "\n",
        "    transforms = {}\n",
        "    transforms_pca = {}\n",
        "    #transforms_umap = {}\n",
        "    transforms_lle = {}\n",
        "    transforms_cebra = {}\n",
        "    transforms_ridge = {}\n",
        "    transforms_ridge_pca = {}\n",
        "    transforms_ridge_lle = {}\n",
        "    transforms_ridge_cebra = {}\n",
        "    best_transforms = {}\n",
        "\n",
        "    best_X = {}\n",
        "    best_y = {}\n",
        "    untransformed_X = {}\n",
        "\n",
        "\n",
        "\n",
        "    for col in df_moodTracking.columns:\n",
        "        if col != 'Datetime':\n",
        "        #if col == 'Mood':\n",
        "            # Get the numpy vector for the current column\n",
        "            y = df_moodTracking[col].values\n",
        "\n",
        "            # Get the corresponding numpy vectors from the VECTORS_NOW dictionary\n",
        "            X = np.array([VECTORS_NOW[str_to_ts(dt)] for dt in df_moodTracking['Datetime']])\n",
        "\n",
        "            datetime_values = df_moodTracking['Datetime'].values\n",
        "\n",
        "            # just valid indices (remove nans!)\n",
        "            valid_indices = ~pd.isna(y)\n",
        "            y = y[valid_indices]\n",
        "            X = X[valid_indices]\n",
        "            dt_valid = datetime_values[valid_indices]\n",
        "\n",
        "            # random shuffle existing labels\n",
        "            if random_shuffle:\n",
        "              y = np.random.permutation(y)\n",
        "\n",
        "            # random generate new labels\n",
        "            if random_generate:\n",
        "              y = np.random.rand(*y.shape)\n",
        "\n",
        "            mse_scores[col] = []\n",
        "            mse_scores_pca[col] = []\n",
        "            #mse_scores_umap[col] = []\n",
        "            mse_scores_lle[col] = []\n",
        "            mse_scores_cebra[col] = []\n",
        "\n",
        "            mse_scores_ridge[col] = []\n",
        "            mse_scores_ridge_pca[col] = []\n",
        "            mse_scores_ridge_lle[col] = []\n",
        "            mse_scores_ridge_cebra[col] = []\n",
        "            best_mse_scores[col] = []\n",
        "\n",
        "            # Perform one-left-out prediction\n",
        "            for i in range(len(y)):\n",
        "                # Filter out the data for the current datetime\n",
        "                # That one datapoint is not included in training set!\n",
        "                y_train = np.delete(y, i)\n",
        "                X_train = np.delete(X, i, axis=0)\n",
        "\n",
        "                if dt_valid[i] not in transforms:\n",
        "                    transforms[dt_valid[i]] = {}\n",
        "                transforms[dt_valid[i]][col] = None\n",
        "\n",
        "                if dt_valid[i] not in transforms_ridge:\n",
        "                    transforms_ridge[dt_valid[i]] = {}\n",
        "                transforms_ridge[dt_valid[i]][col] = None\n",
        "\n",
        "                # Perform PCA on only training set\n",
        "                pca = PCA(n_components=min(N_COMPONENTS, X_train.shape[0] - 1))\n",
        "                X_pca = pca.fit_transform(X_train)\n",
        "\n",
        "                # PCA transform (not fit_transform) on the test example\n",
        "                X_pca_test = pca.transform(X[i].reshape(1, -1))\n",
        "                if dt_valid[i] not in transforms_pca:\n",
        "                    transforms_pca[dt_valid[i]] = {}\n",
        "                transforms_pca[dt_valid[i]][col] = pca\n",
        "\n",
        "\n",
        "                if dt_valid[i] not in transforms_ridge_pca:\n",
        "                    transforms_ridge_pca[dt_valid[i]] = {}\n",
        "                transforms_ridge_pca[dt_valid[i]][col] = pca\n",
        "\n",
        "                # # Perform UMAP on only training set\n",
        "                # umap_emb = umap.UMAP(n_components=N_COMPONENTS, init='random')\n",
        "                # X_umap = umap_emb.fit_transform(X_train)\n",
        "                # X_umap_test = umap_emb.transform(X[i].reshape(1, -1))\n",
        "\n",
        "                # LLE on only training set\n",
        "                lle = LocallyLinearEmbedding(n_components=min(N_COMPONENTS, X_train.shape[0] - 1))\n",
        "                X_lle = lle.fit_transform(X_train)\n",
        "\n",
        "                # LLE transform (not fit_transform) on test example\n",
        "                X_lle_test = lle.transform(X[i].reshape(1, -1))\n",
        "                if dt_valid[i] not in transforms_lle:\n",
        "                    transforms_lle[dt_valid[i]] = {}\n",
        "                transforms_lle[dt_valid[i]][col] = lle\n",
        "\n",
        "\n",
        "                if dt_valid[i] not in transforms_ridge_lle:\n",
        "                    transforms_ridge_lle[dt_valid[i]] = {}\n",
        "                transforms_ridge_lle[dt_valid[i]][col] = lle\n",
        "\n",
        "                # CEBRA on only training set\n",
        "                single_cebra_model = cebra.CEBRA(batch_size=5,\n",
        "                                 output_dimension=N_COMPONENTS,\n",
        "                                 max_iterations=10,\n",
        "                                 max_adapt_iterations=10)\n",
        "                X_cebra = single_cebra_model.fit_transform(X_train)\n",
        "\n",
        "                # CEBRA transform (not fit_transform) on the single test example\n",
        "                X_cebra_test = single_cebra_model.transform(X[i].reshape(1, -1))\n",
        "\n",
        "                if dt_valid[i] not in transforms_cebra:\n",
        "                    transforms_cebra[dt_valid[i]] = {}\n",
        "                transforms_cebra[dt_valid[i]][col] = single_cebra_model\n",
        "\n",
        "                if dt_valid[i] not in transforms_ridge_cebra:\n",
        "                    transforms_ridge_cebra[dt_valid[i]] = {}\n",
        "                transforms_ridge_cebra[dt_valid[i]][col] = single_cebra_model\n",
        "\n",
        "\n",
        "                # Train each on only training set!\n",
        "                model = LinearRegression()\n",
        "                model.fit(X_train, y_train)\n",
        "\n",
        "                model_pca = LinearRegression()\n",
        "                model_pca.fit(X_pca, y_train)\n",
        "\n",
        "                # model_umap = LinearRegression()\n",
        "                # model_umap.fit(X_umap, y_train)\n",
        "\n",
        "                model_lle = LinearRegression()\n",
        "                model_lle.fit(X_lle, y_train)\n",
        "\n",
        "                model_cebra = LinearRegression()\n",
        "                model_cebra.fit(X_cebra, y_train)\n",
        "\n",
        "                # Ridge (L2 Regularized)\n",
        "                model_ridge = Ridge(alpha=1.0)\n",
        "                model_ridge.fit(X_train, y_train)\n",
        "\n",
        "                # Ridge PCA (L2 Regularized)\n",
        "                model_ridge_pca = Ridge(alpha=1.0)\n",
        "                model_ridge_pca.fit(X_pca, y_train)\n",
        "\n",
        "                model_ridge_lle = Ridge(alpha=1.0)\n",
        "                model_ridge_lle.fit(X_lle, y_train)\n",
        "\n",
        "                model_ridge_cebra = Ridge(alpha=1.0)\n",
        "                model_ridge_cebra.fit(X_cebra, y_train)\n",
        "\n",
        "\n",
        "                # Store the trained model in the dictionary with the datetime as the key\n",
        "                if dt_valid[i] not in models:\n",
        "                    models[dt_valid[i]] = {}\n",
        "                models[dt_valid[i]][col] = model\n",
        "\n",
        "                if dt_valid[i] not in models_pca:\n",
        "                    models_pca[dt_valid[i]] = {}\n",
        "                models_pca[dt_valid[i]][col] = model_pca\n",
        "\n",
        "                # if dt_valid[i] not in models_umap:\n",
        "                #     models_umap[dt_valid[i]] = {}\n",
        "                # models_umap[dt_valid[i]][col] = model_umap\n",
        "\n",
        "                if dt_valid[i] not in models_lle:\n",
        "                    models_lle[dt_valid[i]] = {}\n",
        "                models_lle[dt_valid[i]][col] = model_lle\n",
        "\n",
        "                if dt_valid[i] not in models_cebra:\n",
        "                    models_cebra[dt_valid[i]] = {}\n",
        "                models_cebra[dt_valid[i]][col] = model_cebra\n",
        "\n",
        "                # Store Ridge trained model\n",
        "                if dt_valid[i] not in models_ridge:\n",
        "                    models_ridge[dt_valid[i]] = {}\n",
        "                models_ridge[dt_valid[i]][col] = model_ridge\n",
        "\n",
        "                if dt_valid[i] not in models_ridge_pca:\n",
        "                    models_ridge_pca[dt_valid[i]] = {}\n",
        "                models_ridge_pca[dt_valid[i]][col] = model_ridge_pca\n",
        "\n",
        "                if dt_valid[i] not in models_ridge_lle:\n",
        "                    models_ridge_lle[dt_valid[i]] = {}\n",
        "                models_ridge_lle[dt_valid[i]][col] = model_ridge_lle\n",
        "\n",
        "                if dt_valid[i] not in models_ridge_cebra:\n",
        "                    models_ridge_cebra[dt_valid[i]] = {}\n",
        "                models_ridge_cebra[dt_valid[i]][col] = model_ridge_cebra\n",
        "\n",
        "\n",
        "                # Make predictions for the left-out datetime (not included in training set)\n",
        "                y_pred = model.predict(X[i].reshape(1, -1))\n",
        "\n",
        "                y_pred_pca = model_pca.predict(X_pca_test.reshape(1, -1))\n",
        "                #y_pred_umap = model_umap.predict(X_umap_test.reshape(1, -1))\n",
        "                y_pred_lle = model_lle.predict(X_lle_test.reshape(1, -1))\n",
        "                y_pred_cebra = model_cebra.predict(X_cebra_test.reshape(1, -1))\n",
        "\n",
        "                y_pred_ridge = model_ridge.predict(X[i].reshape(1, -1))\n",
        "                y_pred_ridge_pca = model_ridge_pca.predict(X_pca_test.reshape(1, -1))\n",
        "                y_pred_ridge_lle = model_ridge_lle.predict(X_lle_test.reshape(1, -1))\n",
        "                y_pred_ridge_cebra = model_ridge_cebra.predict(X_cebra_test.reshape(1, -1))\n",
        "\n",
        "                # Convert y[i] and y_pred to numeric values if they are not already\n",
        "                y_i = pd.to_numeric(y[i])\n",
        "                y_pred = pd.to_numeric(y_pred)\n",
        "                y_pred_pca = pd.to_numeric(y_pred_pca)\n",
        "                #y_pred_umap = pd.to_numeric(y_pred_umap)\n",
        "                y_pred_lle = pd.to_numeric(y_pred_lle)\n",
        "                y_pred_cebra = pd.to_numeric(y_pred_cebra)\n",
        "\n",
        "                y_pred_ridge = pd.to_numeric(y_pred_ridge)\n",
        "                y_pred_ridge_pca = pd.to_numeric(y_pred_ridge_pca)\n",
        "                y_pred_ridge_lle = pd.to_numeric(y_pred_ridge_lle)\n",
        "                y_pred_ridge_cebra = pd.to_numeric(y_pred_ridge_cebra)\n",
        "\n",
        "\n",
        "                # Compute the mean squared error\n",
        "                mse = np.mean((y_i - y_pred) ** 2)\n",
        "                mse_scores[col].append(mse)\n",
        "\n",
        "                mse_pca = np.mean((y_i - y_pred_pca) ** 2)\n",
        "                mse_scores_pca[col].append(mse_pca)\n",
        "\n",
        "                # mse_umap = np.mean((y_i - y_pred_umap) ** 2)\n",
        "                # mse_scores_umap[col].append(mse_umap)\n",
        "\n",
        "                mse_lle = np.mean((y_i - y_pred_lle) ** 2)\n",
        "                mse_scores_lle[col].append(mse_lle)\n",
        "\n",
        "                mse_cebra = np.mean((y_i - y_pred_cebra) ** 2)\n",
        "                mse_scores_cebra[col].append(mse_cebra)\n",
        "\n",
        "                mse_ridge = np.mean((y_i - y_pred_ridge) ** 2)\n",
        "                mse_scores_ridge[col].append(mse_ridge)\n",
        "\n",
        "                mse_ridge_pca = np.mean((y_i - y_pred_ridge_pca) ** 2)\n",
        "                mse_scores_ridge_pca[col].append(mse_ridge_pca)\n",
        "\n",
        "                mse_ridge_lle = np.mean((y_i - y_pred_ridge_lle) ** 2)\n",
        "                mse_scores_ridge_lle[col].append(mse_ridge_lle)\n",
        "\n",
        "                mse_ridge_cebra = np.mean((y_i - y_pred_ridge_cebra) ** 2)\n",
        "                mse_scores_ridge_cebra[col].append(mse_ridge_cebra)\n",
        "\n",
        "\n",
        "\n",
        "                ## BEST models, mse, transforms, X, and y for given timestamp/emotion combo\n",
        "\n",
        "                # find the best mse_score\n",
        "                all_mse_scores = [mse, mse_pca, mse_lle, mse_cebra, mse_ridge, \\\n",
        "                                  mse_ridge_pca, mse_ridge_lle, mse_ridge_cebra]\n",
        "                best_regimen_index = np.argmin(np.array(all_mse_scores))\n",
        "                best_mse_scores[col].append(all_mse_scores[best_regimen_index])\n",
        "\n",
        "                # best model\n",
        "                all_models = [model, model_pca, model_lle, model_cebra, model_ridge, \\\n",
        "                              model_ridge_pca, model_ridge_lle, model_ridge_cebra]\n",
        "                if dt_valid[i] not in best_models:\n",
        "                    best_models[dt_valid[i]] = {}\n",
        "                best_models[dt_valid[i]][col] = all_models[best_regimen_index]\n",
        "\n",
        "                # best transform\n",
        "                all_transforms = [None, pca, lle, single_cebra_model, None, \\\n",
        "                                  pca, lle, single_cebra_model]\n",
        "                if dt_valid[i] not in best_transforms:\n",
        "                    best_transforms[dt_valid[i]] = {}\n",
        "                best_transforms[dt_valid[i]][col] = all_transforms[best_regimen_index]\n",
        "\n",
        "                # best X\n",
        "                all_X = [X[i], X_pca_test, X_lle_test, X_cebra_test, X[i], \\\n",
        "                              X_pca_test, X_lle_test, X_cebra_test]\n",
        "                if dt_valid[i] not in best_X:\n",
        "                    best_X[dt_valid[i]] = {}\n",
        "                best_X[dt_valid[i]][col] = all_X[best_regimen_index].reshape(1, -1)\n",
        "\n",
        "                # best y\n",
        "                if dt_valid[i] not in best_y:\n",
        "                    best_y[dt_valid[i]] = {}\n",
        "                best_y[dt_valid[i]][col] = y_i\n",
        "\n",
        "                # untransformed X\n",
        "                if dt_valid[i] not in untransformed_X:\n",
        "                    untransformed_X[dt_valid[i]] = {}\n",
        "                untransformed_X[dt_valid[i]][col] = X[i].reshape(1, -1)\n",
        "\n",
        "\n",
        "    # Compute and print the average MSE for each column\n",
        "    if verbose:\n",
        "      for col in mse_scores.keys():\n",
        "          avg_mse = np.mean(mse_scores[col])\n",
        "          print(f\"Average MSE for {col}: {avg_mse}\")\n",
        "\n",
        "          avg_mse_pca = np.mean(mse_scores_pca[col])\n",
        "          print(f\"Average MSE for {col} with PCA: {avg_mse_pca}\")\n",
        "\n",
        "          # avg_mse_umap = np.mean(mse_scores_umap[col])\n",
        "          # print(f\"Average MSE for {col} with UMAP: {avg_mse_umap}\")\n",
        "\n",
        "          avg_mse_lle = np.mean(mse_scores_lle[col])\n",
        "          print(f\"Average MSE for {col} with LLE: {avg_mse_lle}\")\n",
        "\n",
        "          avg_mse_cebra = np.mean(mse_scores_cebra[col])\n",
        "          print(f\"Average MSE for {col} with CEBRA: {avg_mse_cebra}\")\n",
        "\n",
        "          avg_mse_ridge = np.mean(mse_scores_ridge[col])\n",
        "          print(f\"Average MSE for {col} with Ridge: {avg_mse_ridge}\")\n",
        "\n",
        "          avg_mse_ridge_pca = np.mean(mse_scores_ridge_pca[col])\n",
        "          print(f\"Average MSE for {col} with Ridge, PCA: {avg_mse_ridge_pca}\")\n",
        "\n",
        "          avg_mse_ridge_lle = np.mean(mse_scores_ridge_lle[col])\n",
        "          print(f\"Average MSE for {col} with Ridge, LLE: {avg_mse_ridge_lle}\")\n",
        "\n",
        "          avg_mse_ridge_cebra = np.mean(mse_scores_ridge_cebra[col])\n",
        "          print(f\"Average MSE for {col} with Ridge, CEBRA: {avg_mse_ridge_cebra}\")\n",
        "\n",
        "\n",
        "    ## RETURN\n",
        "\n",
        "    models_dict = {'models': models,\n",
        "                   'models_pca': models_pca,\n",
        "                   #'models_umap': models_umap,\n",
        "                   'models_lle': models_lle,\n",
        "                   'models_cebra': models_cebra,\n",
        "                   'models_ridge': models_ridge,\n",
        "                   'models_ridge_pca': models_ridge_pca,\n",
        "                   'models_ridge_lle': models_ridge_lle,\n",
        "                   'models_ridge_cebra': models_ridge_cebra}\n",
        "\n",
        "    mse_dict = {'mse_scores': mse_scores,\n",
        "                'mse_scores_pca': mse_scores_pca,\n",
        "                #'mse_scores_umap': mse_scores_umap,\n",
        "                'mse_scores_lle': mse_scores_lle,\n",
        "                'mse_scores_cebra': mse_scores_cebra,\n",
        "                'mse_scores_ridge': mse_scores_ridge,\n",
        "                'mse_scores_ridge_pca': mse_scores_ridge_pca,\n",
        "                'mse_scores_ridge_lle': mse_scores_ridge_lle,\n",
        "                'mse_scores_ridge_cebra': mse_scores_ridge_cebra}\n",
        "\n",
        "    transforms_dict = {'transforms': transforms,\n",
        "                       'transforms_pca': transforms_pca,\n",
        "                       #'transforms_umap': transforms_umap,\n",
        "                       'transforms_lle': transforms_lle,\n",
        "                       'transforms_cebra': transforms_cebra,\n",
        "                       'transforms_ridge': transforms_ridge,\n",
        "                       'transforms_ridge_pca': transforms_ridge_pca,\n",
        "                       'transforms_ridge_lle': transforms_ridge_lle,\n",
        "                       'transforms_ridge_cebra': transforms_ridge_cebra}\n",
        "\n",
        "    best_dict = {'best_models': best_models,\n",
        "                 'best_mse_scores': best_mse_scores,\n",
        "                 'best_transforms': best_transforms,\n",
        "                 'best_X': best_X,\n",
        "                 'best_y': best_y,\n",
        "                 'untransformed_X': untransformed_X}\n",
        "\n",
        "\n",
        "    return models_dict, mse_dict, transforms_dict, best_dict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M0kiir99OlZk"
      },
      "outputs": [],
      "source": [
        "openface_model_mse_transforms_best_dict = apply_function_to_dict(openface_vectors_dict, runLinReg, N_COMPONENTS=15, random_shuffle=False, random_generate=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9-LyjGY-VRz8"
      },
      "outputs": [],
      "source": [
        "save_var(openface_model_mse_transforms_best_dict, RUNTIME_VAR_PATH)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "save_var(openface_model_mse_transforms_best_dict_rand, RUNTIME_VAR_PATH)"
      ],
      "metadata": {
        "id": "EF60SjIDXuyl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d_wgOR5Jbrgg"
      },
      "outputs": [],
      "source": [
        "openface_model_mse_transforms_best_dict = load_var('openface_model_mse_transforms_best_dict')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "raLlql8E93lP"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.ticker as ticker\n",
        "\n",
        "\n",
        "\n",
        "def plot_linReg_results(mse_dict, time_radius, savepath, add_heights=False):\n",
        "  # Extract the column names from any of the dictionaries\n",
        "  columns = list(mse_dict['mse_scores'].keys())\n",
        "\n",
        "  # Set the position of the bars on the x-axis\n",
        "  x = np.arange(len(columns))\n",
        "  width = 0.1  # Width of each bar\n",
        "\n",
        "  # Get the average values and standard deviations for each column\n",
        "  averages = {\n",
        "      'mse_scores': [np.mean(mse_dict['mse_scores'][col]) for col in columns],\n",
        "      'mse_scores_pca': [np.mean(mse_dict['mse_scores_pca'][col]) for col in columns],\n",
        "      #'mse_scores_umap': [np.mean(mse_dict['mse_scores_umap'][col]) for col in columns],\n",
        "      'mse_scores_lle': [np.mean(mse_dict['mse_scores_lle'][col]) for col in columns],\n",
        "      #'mse_scores_cebra': [np.mean(mse_dict['mse_scores_cebra'][col]) for col in columns],\n",
        "      'mse_scores_ridge': [np.mean(mse_dict['mse_scores_ridge'][col]) for col in columns],\n",
        "      'mse_scores_ridge_pca': [np.mean(mse_dict['mse_scores_ridge_pca'][col]) for col in columns],\n",
        "      'mse_scores_ridge_lle': [np.mean(mse_dict['mse_scores_ridge_lle'][col]) for col in columns],\n",
        "      'mse_scores_ridge_cebra': [np.mean(mse_dict['mse_scores_ridge_cebra'][col]) for col in columns]\n",
        "  }\n",
        "\n",
        "  std_devs = {\n",
        "      'mse_scores': [np.std(mse_dict['mse_scores'][col]) for col in columns],\n",
        "      'mse_scores_pca': [np.std(mse_dict['mse_scores_pca'][col]) for col in columns],\n",
        "      #'mse_scores_umap': [np.std(mse_dict['mse_scores_umap'][col]) for col in columns],\n",
        "      'mse_scores_lle': [np.mean(mse_dict['mse_scores_lle'][col]) for col in columns],\n",
        "      #'mse_scores_cebra': [np.mean(mse_dict['mse_scores_cebra'][col]) for col in columns],\n",
        "      'mse_scores_ridge': [np.mean(mse_dict['mse_scores_ridge'][col]) for col in columns],\n",
        "      'mse_scores_ridge_pca': [np.mean(mse_dict['mse_scores_ridge_pca'][col]) for col in columns],\n",
        "      'mse_scores_ridge_lle': [np.mean(mse_dict['mse_scores_ridge_lle'][col]) for col in columns],\n",
        "      'mse_scores_ridge_cebra': [np.mean(mse_dict['mse_scores_ridge_cebra'][col]) for col in columns]\n",
        "  }\n",
        "\n",
        "  # Plot the bar chart\n",
        "  fig, ax = plt.subplots(figsize=(34, 6))\n",
        "  for i, key in enumerate(averages.keys()):\n",
        "      ax.bar(x + i * width, averages[key], width, label=key) #, yerr=std_devs[key])\n",
        "\n",
        "      if add_heights:\n",
        "        # Add height values to each bar\n",
        "        for j, value in enumerate(averages[key]):\n",
        "            ax.text(x[j] + i * width, value, str(value), ha='center', va='bottom', fontsize=18)\n",
        "\n",
        "  # Customize the plot\n",
        "  ax.set_xticks(x + width)\n",
        "  ax.set_xticklabels(columns, rotation=45, ha='right', fontsize=15)\n",
        "  ax.set_xlabel('Self-Reported Metric', fontsize=18)\n",
        "  ax.set_ylabel('Average MSE', fontsize=18)\n",
        "  #ax.set_yticklabels(ax.get_yticks(), fontsize=15)\n",
        "  ax.set_yticklabels(['{:.2f}'.format(label) for label in ax.get_yticks()], fontsize=15)\n",
        "  ax.set_title(f'Linear Regression MSE, Time Window = {time_radius // 30} Hours', fontsize=18)\n",
        "  ax.legend(['Untransformed Input', 'PCA', 'LLE', 'Ridge (L2 Regularizer)', 'Ridge PCA', 'Ridge LLE', 'Ridge CEBRA'], fontsize=15)\n",
        "\n",
        "  # Save the plot\n",
        "  plt.savefig(savepath, bbox_inches='tight')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bK1-I6SZWPEF"
      },
      "outputs": [],
      "source": [
        "for i in openface_model_mse_transforms_best_dict.keys():\n",
        "  mse_dict_now = openface_model_mse_transforms_best_dict[i][1]\n",
        "  plot_linReg_results(mse_dict_now, int(i), RESULTS_PATH_BASE + f'LinReg_cebra_norm_{i}.png', add_heights=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yEuBNSueb4Yd"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o2kMXeMlaatZ"
      },
      "source": [
        "## Scatterplots & P Value"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.stats import pearsonr\n",
        "\n",
        "\n",
        "def plot_predictions(y, y_pred, ax=None):\n",
        "\n",
        "    # Compute Pearson's R\n",
        "    pearson_corr, p_val = pearsonr(y, y_pred)\n",
        "\n",
        "    # Create the scatter plot on the specified axes\n",
        "    if ax is None:\n",
        "        fig, ax = plt.subplots()\n",
        "    ax.scatter(y, y_pred, label='Predicted vs. True')\n",
        "\n",
        "    # Add the correlation coefficient on the plot\n",
        "    ax.text(0.05, 0.95, f'Pearson\\'s R: {pearson_corr:.2f}', transform=ax.transAxes, fontsize=15)\n",
        "    ax.text(0.05, 0.85, f'P Value: {p_val:.2f}', transform=ax.transAxes, fontsize=15)\n",
        "\n",
        "    # Set labels and title\n",
        "    ax.set_xlabel('True Labels', fontsize=15)\n",
        "    ax.set_ylabel('Predicted Labels', fontsize=15)\n",
        "    ax.set_title('Predicted vs. True Labels', fontsize=15)\n",
        "\n",
        "    # Set the same range for x and y axes\n",
        "    min_value = min(np.min(y), np.min(y_pred))\n",
        "    max_value = max(np.max(y), np.max(y_pred))\n",
        "    buffer = (max_value - min_value) * 0.05  # 5% buffer\n",
        "    ax.set_xlim(min_value - buffer, max_value + buffer)\n",
        "    ax.set_ylim(min_value - buffer, max_value + buffer)\n",
        "\n",
        "    # Add the line of best fit\n",
        "    ax.plot([min_value - buffer, max_value + buffer], [min_value - buffer, max_value + buffer], \\\n",
        "            color='red', linestyle='--', label='Line of Best Fit')\n",
        "\n",
        "    # Adjust the font size of the tick labels on the axes\n",
        "    ax.tick_params(axis='both', labelsize=14)\n",
        "\n",
        "    # Add legend\n",
        "    #ax.legend()\n",
        "\n",
        "    if ax is None:\n",
        "        return fig\n",
        "\n",
        "def get_longest_keys(best_models):\n",
        "  # initialize a variable to store the longest list of keys\n",
        "  longest_key_list = []\n",
        "\n",
        "  # loop through the dictionaries in best_models\n",
        "  for sub_dict in best_models.values():\n",
        "    # get the list of keys for this dictionary\n",
        "    key_list = list(sub_dict.keys())\n",
        "    # check if this list is longer than the current longest list\n",
        "    if len(key_list) > len(longest_key_list):\n",
        "        longest_key_list = key_list\n",
        "\n",
        "  return longest_key_list\n",
        "\n",
        "def extract_preds(best_models, best_X, best_y):\n",
        "  # each are dictionaries with datetimes as keys\n",
        "  # values are dictionaries with emotions as keys\n",
        "  # models then has models, X has a (1, n) vector, and y has one value (ground truth)\n",
        "\n",
        "  # returns y_dict, y_pred_dict\n",
        "\n",
        "  # initialize a variable to store the longest list of keys\n",
        "  longest_key_list = get_longest_keys(best_models)\n",
        "\n",
        "  # initialize empty dictionaries to store results\n",
        "  y_pred_dict = {}\n",
        "  y_dict = {}\n",
        "\n",
        "  # loop through emotions\n",
        "  for emotion in longest_key_list:\n",
        "\n",
        "    # initialize empty lists to store relevant models, X, and y\n",
        "    models = []\n",
        "    X_list = []\n",
        "    y_list = []\n",
        "\n",
        "    # loop through datetimes to find the relevant models for this emotion\n",
        "    for dt in best_models.keys():\n",
        "        if emotion in best_models[dt]:\n",
        "            # append the relevant model, X, and y to their respective lists\n",
        "            models.append(best_models[dt][emotion])\n",
        "            X_list.append(best_X[dt][emotion])\n",
        "            y_list.append(best_y[dt][emotion])\n",
        "\n",
        "    # initialize an empty list to store the predictions for this emotion\n",
        "    y_pred_list = []\n",
        "\n",
        "    # loop through the relevant models and make predictions\n",
        "    for enum, model in enumerate(models):\n",
        "        y_pred_list.append(model.predict(X_list[enum]))\n",
        "\n",
        "    # stack the predictions into a single array\n",
        "    y_pred = np.vstack(y_pred_list)\n",
        "\n",
        "    # add the predictions and ground truth arrays to the dictionaries\n",
        "    y_pred_dict[emotion] = y_pred\n",
        "    y_dict[emotion] = y_list\n",
        "\n",
        "  return y_dict, y_pred_dict\n",
        "\n",
        "\n",
        "\n",
        "def plot_subplots(best_models, best_X, best_y, overall_title):\n",
        "    num_plots = len(get_longest_keys(best_models))\n",
        "    num_cols = 4\n",
        "    num_rows = (num_plots + num_cols - 1) // num_cols\n",
        "\n",
        "    y_dict, y_pred_dict = extract_preds(best_models, best_X, best_y)\n",
        "\n",
        "    # Calculate the desired figure size for larger plot\n",
        "    figsize = (28, 12)\n",
        "\n",
        "    # Create subplots with equal aspect ratio\n",
        "    fig, axes = plt.subplots(num_rows, num_cols, figsize=figsize, subplot_kw={'aspect': 'auto'})\n",
        "\n",
        "    # Flatten the axes array if necessary\n",
        "    if num_plots == 1:\n",
        "        axes = np.array([axes])\n",
        "\n",
        "    # Loop through the dictionaries\n",
        "    for i, (key, y_list) in enumerate(y_dict.items()):\n",
        "        y_list = np.array(y_list).astype(float)\n",
        "        y_pred = np.array(y_pred_dict[key]).astype(float)\n",
        "        y_pred = np.array([i[0] for i in y_pred])\n",
        "\n",
        "        # Get the subplot coordinates\n",
        "        row = i // num_cols\n",
        "        col = i % num_cols\n",
        "\n",
        "        # Plot predictions on the subplot\n",
        "        plot_predictions(y_list, y_pred, ax=axes[row, col])\n",
        "        axes[row, col].set_title(key, fontsize=15)\n",
        "        axes[row, col].set_aspect('equal')\n",
        "\n",
        "    # Add overall title\n",
        "    fig.suptitle(overall_title, fontsize=17)\n",
        "\n",
        "    # Adjust spacing and layout\n",
        "    fig.tight_layout()\n",
        "\n",
        "    # Increase the font size of the legend\n",
        "    for ax in axes.flat:\n",
        "        legend = ax.legend()\n",
        "        if legend is not None:\n",
        "            for text in legend.get_texts():\n",
        "                text.set_fontsize(15)\n",
        "\n",
        "    return fig\n",
        "\n",
        "\n",
        "\n",
        "def scatterplotsLinReg(tuple_to_unpack, savepath, overall_title):\n",
        "\n",
        "    models_dict, mse_dict, transforms_dict, best_dict = tuple_to_unpack\n",
        "\n",
        "    best_models = best_dict['best_models']\n",
        "    best_X = best_dict['best_X']\n",
        "    best_y = best_dict['best_y']\n",
        "\n",
        "    plot_subplots(best_models, best_X, best_y, overall_title)\n",
        "\n",
        "    plt.savefig(savepath)\n",
        "    return plot_subplots(best_models, best_X, best_y, overall_title)\n"
      ],
      "metadata": {
        "id": "820xOOGPcaHR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ct8TLdK96lPA"
      },
      "outputs": [],
      "source": [
        "for i in openface_model_mse_transforms_best_dict.keys():\n",
        "  scatterplotsLinReg(openface_model_mse_transforms_best_dict[i], RESULTS_PATH_BASE + f'scatter_norm_{i}.png', f'Best Model Scatterplots, Time Window = {int(i) // 30} Hours')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "79m53uKwG_xY"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Explainability\n",
        "Which inputs does each model use for each prediction?"
      ],
      "metadata": {
        "id": "JXDWQ1dy0gxY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ONLY RUN IF SHELL COMMANDS AREN'T WORKING\n",
        "import locale\n",
        "def getpreferredencoding(do_setlocale = True):\n",
        "    return \"UTF-8\"\n",
        "locale.getpreferredencoding = getpreferredencoding"
      ],
      "metadata": {
        "id": "330LPe4C3RvJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install shap -qq"
      ],
      "metadata": {
        "id": "hKKLHkDNeu1k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import shap\n",
        "\n",
        "def compute_shapley_importance(model, X):\n",
        "    # Apply the transform to the input data\n",
        "    #X_transformed = transform.transform(X)\n",
        "\n",
        "    # Initialize the SHAP explainer with the model and transformed data\n",
        "    explainer = shap.Explainer(model.predict, X, algorithm='permutation')\n",
        "\n",
        "    # Compute the SHAP values for the transformed data\n",
        "    shap_values = explainer(X)\n",
        "\n",
        "    # Get the feature importance based on SHAP values\n",
        "    feature_importance = shap_values.abs.mean(axis=0)\n",
        "\n",
        "    shap.summary_plot(feature_importance, X)\n",
        "\n",
        "    return feature_importance\n",
        "\n",
        "class CustomModelWrapper:\n",
        "    def __init__(self, custom_function):\n",
        "        self.custom_function = custom_function\n",
        "        self.classes_ = None  # Dummy attribute to satisfy pdp.pdp_isolate()\n",
        "\n",
        "    def predict(self, X):\n",
        "        return np.array([self.custom_function(np.array(X))])\n",
        "\n",
        "    def __call__(self, X):\n",
        "        return self.predict(X)\n",
        "\n",
        "\n",
        "def calculate_perturbed_preds(model, x):\n",
        "    # returns a vector of same size as x AND the baseline pred\n",
        "    # but with predictions with the relevant feature set to 0\n",
        "\n",
        "    # Baseline pred\n",
        "    baseline_pred = model.predict(x)\n",
        "\n",
        "    # Initialize an array to store feature importance scores\n",
        "    perturbed_preds = np.zeros(x.shape[1])\n",
        "\n",
        "    # Iterate over each feature\n",
        "    for feature_index in range(x.shape[1]):\n",
        "        # Create a copy of the input array\n",
        "        perturbed_x = np.copy(x)\n",
        "\n",
        "        # Set the feature values to zero\n",
        "        perturbed_x[0, feature_index] = 0\n",
        "\n",
        "        # Get prediction with perturbed feature\n",
        "        perturbed_pred = model.predict(perturbed_x)\n",
        "\n",
        "        # Calculate the feature importance score\n",
        "        perturbed_preds[feature_index] = perturbed_pred\n",
        "\n",
        "    return perturbed_preds, baseline_pred\n"
      ],
      "metadata": {
        "id": "Ghblki3L0ieV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_longest_keys(best_models):\n",
        "  # initialize a variable to store the longest list of keys\n",
        "  longest_key_list = []\n",
        "\n",
        "  # loop through the dictionaries in best_models\n",
        "  for sub_dict in best_models.values():\n",
        "    # get the list of keys for this dictionary\n",
        "    key_list = list(sub_dict.keys())\n",
        "    # check if this list is longer than the current longest list\n",
        "    if len(key_list) > len(longest_key_list):\n",
        "        longest_key_list = key_list\n",
        "\n",
        "  return longest_key_list\n",
        "\n",
        "def extract_importance_params(best_models, best_transforms, untransformed_X, best_y):\n",
        "  # each are dictionaries with datetimes as keys\n",
        "  # values are dictionaries with emotions as keys\n",
        "  # models then has models, transform has a transform (or None), and X has a (1, n) vector\n",
        "\n",
        "  # returns importance_dict\n",
        "\n",
        "  perturbed_dict = {}\n",
        "  baseline_results = {}\n",
        "  pearson_R_baseline = {}\n",
        "  p_value_baseline = {}\n",
        "  p_value_perturbed = {}\n",
        "  pearson_R_perturbed = {}\n",
        "  importance_scores_dict = {}\n",
        "\n",
        "  # initialize a variable to store the longest list of keys\n",
        "  longest_key_list = get_longest_keys(best_models)\n",
        "\n",
        "  # length of feature vector\n",
        "  X_size = untransformed_X[list(best_models.keys())[0]]\n",
        "  X_size = X_size[list(X_size.keys())[0]].shape[1]\n",
        "\n",
        "\n",
        "  # loop through emotions\n",
        "  for emotion in longest_key_list:\n",
        "\n",
        "    # initialize empty dict\n",
        "    perturbed_dict_within = {}\n",
        "    baseline_within = {}\n",
        "    best_y_within = {}\n",
        "\n",
        "    # loop through datetimes to find the relevant models for this emotion\n",
        "    for dt in best_models.keys():\n",
        "        if emotion in best_models[dt]:\n",
        "            # append the relevant model, X, and y to their respective lists\n",
        "            model_now = best_models[dt][emotion]\n",
        "            transform_now = best_transforms[dt][emotion]\n",
        "            X_now = untransformed_X[dt][emotion]\n",
        "            if transform_now == None:\n",
        "              combined_model = lambda x: model_now.predict(x)[0]\n",
        "            else:\n",
        "              combined_model = lambda x: model_now.predict(transform_now.transform(x))[0]\n",
        "\n",
        "            combined_model = CustomModelWrapper(combined_model)\n",
        "\n",
        "            # perturbed result\n",
        "            perturbed_result, baseline_pred = calculate_perturbed_preds(combined_model, X_now)\n",
        "\n",
        "            # add a key to dictionary\n",
        "            perturbed_dict_within[dt] = perturbed_result\n",
        "            baseline_within[dt] = baseline_pred[0]\n",
        "            best_y_within[dt] = best_y[dt][emotion]\n",
        "\n",
        "    perturbed_dict[emotion] = perturbed_dict_within\n",
        "    baseline_results[emotion] = baseline_within\n",
        "\n",
        "    p_r_temp, p_temp = pearsonr(list(best_y_within.values()), list(baseline_within.values()))\n",
        "\n",
        "    pearson_R_baseline[emotion] = p_r_temp\n",
        "    p_value_baseline[emotion] = p_temp\n",
        "\n",
        "    pearson_R_perturbed[emotion] = []\n",
        "    p_value_perturbed[emotion] = []\n",
        "    for i in range(X_size):\n",
        "      perturbed_preds = []\n",
        "      for j in perturbed_dict_within.keys():\n",
        "        perturbed_preds.append(perturbed_dict_within[j][i])\n",
        "      pr_temp, p_val_temp = pearsonr(list(best_y_within.values()), perturbed_preds)\n",
        "      pearson_R_perturbed[emotion] = pearson_R_perturbed[emotion] + [pr_temp]\n",
        "      p_value_perturbed[emotion] = p_value_perturbed[emotion] + [p_val_temp]\n",
        "\n",
        "    importance_scores_dict[emotion] = pearson_R_baseline[emotion] - pearson_R_perturbed[emotion]\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  return importance_scores_dict\n",
        "\n",
        "def tuple_unpack_helper_explainer(tuple_here):\n",
        "  best_models = tuple_here[3]['best_models']\n",
        "  best_transforms = tuple_here[3]['best_transforms']\n",
        "  untransformed_X = tuple_here[3]['untransformed_X']\n",
        "  best_y = tuple_here[3]['best_y']\n",
        "  return extract_importance_params(best_models, best_transforms, untransformed_X, best_y)"
      ],
      "metadata": {
        "id": "tcYuxS7u0mt1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "explainer_dict = apply_function_to_dict(openface_model_mse_transforms_best_dict, tuple_unpack_helper_explainer)"
      ],
      "metadata": {
        "id": "WCVZDn82R4Jf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# SAVE VARIABLE\n",
        "save_var(explainer_dict)"
      ],
      "metadata": {
        "id": "6-b7WP9OZhwM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# LOAD VARIABLE\n",
        "explainer_dict = load_var('explainer_dict')"
      ],
      "metadata": {
        "id": "mkmdzWDMZjsJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# example\n",
        "example_explanation = explainer_dict['60']['Mood']\n",
        "np.argsort(-example_explanation)[:10]"
      ],
      "metadata": {
        "id": "4zNOo9wuazHr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qOpsxB8_bxcq"
      },
      "source": [
        "# Experiments"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mkqfWHhmPTIH"
      },
      "source": [
        "## CEBRA\n",
        "https://cebra.ai/\n",
        "\n",
        "https://www.nature.com/articles/s41586-023-06031-6"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bKdd29OfPeWB"
      },
      "outputs": [],
      "source": [
        "!pip install cebra -qq"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import cebra\n",
        "\n",
        "cebra.models.get_options()\n",
        "\n",
        "N_COMPONENTS = 15\n",
        "\n",
        "single_cebra_model = cebra.CEBRA(batch_size=5,\n",
        "                                 output_dimension=N_COMPONENTS,\n",
        "                                 max_iterations=10,\n",
        "                                 max_adapt_iterations=10)\n",
        "\n"
      ],
      "metadata": {
        "id": "_ov_FdwsH7-Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V593ki6yxnNL"
      },
      "source": [
        "# ML Methods"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LFr33nDUxIhp"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import cross_val_predict\n",
        "from sklearn.svm import SVR\n",
        "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
        "from sklearn.neural_network import MLPRegressor\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "import numpy as np\n",
        "import random\n",
        "\n",
        "def set_seed(x=5):\n",
        "  np.random.seed(x)\n",
        "  random.seed(x)\n",
        "\n",
        "\n",
        "set_seed()\n",
        "\n",
        "# ensure you have loaded df_moodTracking already!\n",
        "\n",
        "VECTORS_NOW = openface_vectors\n",
        "models_svm = {}\n",
        "models_rf = {}\n",
        "models_gb = {}\n",
        "models_nn = {}\n",
        "\n",
        "mse_scores_svm = {}\n",
        "mse_scores_rf = {}\n",
        "mse_scores_gb = {}\n",
        "mse_scores_nn = {}\n",
        "\n",
        "\n",
        "for col in df_moodTracking.columns:\n",
        "    if col != 'Datetime':\n",
        "        # Get the numpy vector for the current column\n",
        "        y = df_moodTracking[col].values\n",
        "\n",
        "        # Get the corresponding numpy vectors from the VECTORS_NOW dictionary\n",
        "        X = np.array([VECTORS_NOW[str_to_ts(dt)] for dt in df_moodTracking['Datetime']])\n",
        "\n",
        "        valid_indices = ~pd.isna(y)\n",
        "        y = y[valid_indices]\n",
        "        X = X[valid_indices]\n",
        "\n",
        "        mse_scores_svm[col] = []\n",
        "        mse_scores_rf[col] = []\n",
        "        mse_scores_gb[col] = []\n",
        "        mse_scores_nn[col] = []\n",
        "\n",
        "        # Perform one-left-out prediction\n",
        "        # SVM\n",
        "        svm = SVR()\n",
        "        svm_predictions = cross_val_predict(svm, X, y)\n",
        "\n",
        "        # Random Forests\n",
        "        rf = RandomForestRegressor()\n",
        "        rf_predictions = cross_val_predict(rf, X, y)\n",
        "\n",
        "        # Gradient Boosting\n",
        "        gb = GradientBoostingRegressor()\n",
        "        gb_predictions = cross_val_predict(gb, X, y)\n",
        "\n",
        "        # Neural Networks\n",
        "        nn = MLPRegressor()\n",
        "        nn_predictions = cross_val_predict(nn, X, y)\n",
        "\n",
        "\n",
        "\n",
        "        # Store the trained model in the dictionary with the datetime as the key\n",
        "        if df_moodTracking['Datetime'][i] not in models_svm:\n",
        "            models_svm[df_moodTracking['Datetime'][i]] = {}\n",
        "        models_svm[df_moodTracking['Datetime'][i]][col] = svm\n",
        "\n",
        "        if df_moodTracking['Datetime'][i] not in models_rf:\n",
        "            models_rf[df_moodTracking['Datetime'][i]] = {}\n",
        "        models_rf[df_moodTracking['Datetime'][i]][col] = rf\n",
        "\n",
        "        if df_moodTracking['Datetime'][i] not in models_gb:\n",
        "            models_gb[df_moodTracking['Datetime'][i]] = {}\n",
        "        models_gb[df_moodTracking['Datetime'][i]][col] = gb\n",
        "\n",
        "        if df_moodTracking['Datetime'][i] not in models_nn:\n",
        "            models_nn[df_moodTracking['Datetime'][i]] = {}\n",
        "        models_nn[df_moodTracking['Datetime'][i]][col] = nn\n",
        "\n",
        "\n",
        "        # Evaluate the predictions\n",
        "        mse_svm = mean_squared_error(y, svm_predictions)\n",
        "        mse_scores_svm[col] = mse_svm\n",
        "\n",
        "        mse_rf = mean_squared_error(y, rf_predictions)\n",
        "        mse_scores_rf[col] = mse_rf\n",
        "\n",
        "        mse_gb = mean_squared_error(y, gb_predictions)\n",
        "        mse_scores_gb[col] = mse_gb\n",
        "\n",
        "        mse_nn = mean_squared_error(y, nn_predictions)\n",
        "        mse_scores_nn[col] = mse_nn\n",
        "\n",
        "# Compute and print the average MSE for each column\n",
        "for col in mse_scores_svm.keys():\n",
        "    avg_mse_svm = np.mean(mse_scores_svm[col])\n",
        "    print(f\"Average MSE for SVM on {col}: {avg_mse_svm}\")\n",
        "\n",
        "    avg_mse_rf = np.mean(mse_scores_rf[col])\n",
        "    print(f\"Average MSE for RF on {col}: {avg_mse_rf}\")\n",
        "\n",
        "    avg_mse_gb = np.mean(mse_scores_gb[col])\n",
        "    print(f\"Average MSE for GB on {col}: {avg_mse_gb}\")\n",
        "\n",
        "    avg_mse_nn = np.mean(mse_scores_nn[col])\n",
        "    print(f\"Average MSE for NN on {col}: {avg_mse_nn}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dS9vouHOx7Ct"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Extract the column names from any of the dictionaries\n",
        "columns = list(mse_scores_svm.keys())\n",
        "\n",
        "# Set the position of the bars on the x-axis\n",
        "x = np.arange(len(columns))\n",
        "width = 0.15  # Width of each bar\n",
        "\n",
        "# Get the average values and standard deviations for each column\n",
        "averages = {\n",
        "    'mse_scores_svm': [np.mean(mse_scores_svm[col]) for col in columns],\n",
        "    'mse_scores_rf': [np.mean(mse_scores_rf[col]) for col in columns],\n",
        "    'mse_scores_gb': [np.mean(mse_scores_gb[col]) for col in columns],\n",
        "    #'mse_scores_nn': [np.mean(mse_scores_nn[col]) for col in columns],\n",
        "}\n",
        "\n",
        "std_devs = {\n",
        "    'mse_scores_svm': [np.std(mse_scores_svm[col]) for col in columns],\n",
        "    'mse_scores_rf': [np.std(mse_scores_rf[col]) for col in columns],\n",
        "    'mse_scores_gb': [np.mean(mse_scores_gb[col]) for col in columns],\n",
        "    #'mse_scores_ridge': [np.mean(mse_scores_ridge[col]) for col in columns],\n",
        "}\n",
        "\n",
        "# Plot the bar chart\n",
        "fig, ax = plt.subplots(figsize=(16, 6))\n",
        "for i, key in enumerate(averages.keys()):\n",
        "    ax.bar(x + i * width, averages[key], width, label=key) #, yerr=std_devs[key])\n",
        "\n",
        "# Customize the plot\n",
        "ax.set_xticks(x + width)\n",
        "ax.set_xticklabels(columns, rotation=45, ha='right', fontsize=15)\n",
        "ax.set_xlabel('Self-Reported Metric', fontsize=18)\n",
        "ax.set_ylabel('Average MSE', fontsize=18)\n",
        "ax.set_yticklabels(ax.get_yticks(), fontsize=15)\n",
        "ax.set_title('Machine Learning MSE', fontsize=18)\n",
        "ax.legend(['Support Vector Machines', 'Random Forests', 'Gradient Boosting'], fontsize=15)\n",
        "\n",
        "# Show the plot\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# OLD CODE"
      ],
      "metadata": {
        "id": "FvEElXFkij1S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_data_within_duration(dfs_dict, df_video_timestamps, datetime, duration):\n",
        "    # Takes in:\n",
        "    # dfs_dict -- a dictionary of dataframes containing csv data from one of the pipelines\n",
        "    # df_video_timestamps -- the VideoDateTimes_199 csv\n",
        "    # datetime -- a pd.datetime value to center our extraction\n",
        "    # duration -- a duration (in minutes) BEFORE the datetime to extract\n",
        "\n",
        "    # Outputs:\n",
        "    # One dataframe with all rows we want, with timestamps converted into correct datetimes\n",
        "\n",
        "    videos_processed = dfs_dict.keys()\n",
        "    df_processed_videos = df_video_timestamps[df_video_timestamps['Filename'].isin(videos_processed)]\n",
        "\n",
        "    #end_datetime = datetime + pd.Timedelta(minutes=duration)\n",
        "    end_datetime = datetime\n",
        "    start_datetime = datetime - pd.Timedelta(minutes=duration)\n",
        "    relevant_keys = df_processed_videos.loc[(pd.to_datetime(df_processed_videos['VideoEnd']) >= start_datetime) &\n",
        "                                            (pd.to_datetime(df_processed_videos['VideoStart']) <= end_datetime), 'Filename'].values\n",
        "\n",
        "    df_combined = pd.DataFrame()\n",
        "\n",
        "    for key in relevant_keys:\n",
        "        video_start = pd.to_datetime(df_processed_videos.loc[df_processed_videos['Filename'] == key, 'VideoStart'].values[0])\n",
        "        df = dfs_dict[key][(dfs_dict[key]['timestamp'] >= (start_datetime - video_start).total_seconds()) &\n",
        "                           (dfs_dict[key]['timestamp'] <= (end_datetime - video_start).total_seconds())]\n",
        "        df['timestamp'] = video_start + pd.to_timedelta(df['timestamp'], unit='s')\n",
        "        df_combined = pd.concat([df_combined, df], ignore_index=True, sort=False)\n",
        "\n",
        "    # drop frame number because it's now irrelevant / was specific to each video\n",
        "    if not(df_combined.empty):\n",
        "      df_combined = df_combined.drop(columns='frame')\n",
        "\n",
        "    return df_combined"
      ],
      "metadata": {
        "id": "o_4H1Nb8imRH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_sens_spec(logreg_sensitivity_dict, logreg_specificity_dict, rf_sensitivity_dict, rf_specificity_dict, title, save_path=RESULTS_PATH_BASE + 'SMILE/OFAU_metrics.png'):\n",
        "  # Create a list of colors for each metric\n",
        "  colors = ['red', 'blue', 'green', 'orange']\n",
        "\n",
        "  # Plot the graph\n",
        "  plt.figure(figsize=(8, 6))\n",
        "\n",
        "  # Plot sensitivity values\n",
        "  for i, (model_dict, metric_name) in enumerate([(logreg_sensitivity_dict, 'LogReg Sensitivity'),\n",
        "                                                (rf_sensitivity_dict, 'RF Sensitivity')]):\n",
        "      time_window, metric_values = zip(*model_dict.items())\n",
        "      plt.plot(time_window, metric_values, marker='o', linestyle='-', color=colors[i], label=metric_name)\n",
        "\n",
        "  # Plot specificity values\n",
        "  for i, (model_dict, metric_name) in enumerate([(logreg_specificity_dict, 'LogReg Specificity'),\n",
        "                                                (rf_specificity_dict, 'RF Specificity')]):\n",
        "      time_window, metric_values = zip(*model_dict.items())\n",
        "      plt.plot(time_window, metric_values, marker='o', linestyle='-', color=colors[i+2], label=metric_name)\n",
        "\n",
        "  # Set labels and title\n",
        "  plt.xlabel('Time Window (seconds)')\n",
        "  plt.ylabel('Sensitivity or Specificity')\n",
        "  plt.title(title)\n",
        "\n",
        "  # Add a legend\n",
        "  plt.legend()\n",
        "\n",
        "  # save figure\n",
        "  plt.savefig(save_path, bbox_inches='tight')"
      ],
      "metadata": {
        "id": "994npWfsimTd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "best_thresh_dict = {'AU06_c': 0.2,\n",
        "                    'AU07_c': 0.2,\n",
        "                    'AU10_c': 1,\n",
        "                    'AU12_c': 0.2,\n",
        "                    'AU14_c': 0.2,\n",
        "                    'AU25_c': 0.2}\n",
        "\n",
        "for one_au_now, best_threshold in best_thresh_dict.items():\n",
        "  if '10' in one_au_now:\n",
        "    # We want to AVOID AU10 for smile\n",
        "    leq = True\n",
        "  else:\n",
        "    leq = False\n",
        "  title_now = f\"ROC: {one_au_now} only, {best_threshold}\"\n",
        "  of_smile = rule_mean_add(openface_smile, [one_au_now], best_threshold, leq=leq)\n",
        "  auroc_of_smile, sens_of_smile, spec_of_smile = calculate_metrics(of_smile, Final_Smile_Labels, plot_roc=True, title=title_now)\n"
      ],
      "metadata": {
        "id": "I3OcQ_iGT7Jd"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "machine_shape": "hm",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}