{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "D57PMLHEVlOm"
   },
   "source": [
    "# Set Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "id": "frVOpCRsQFEX"
   },
   "outputs": [],
   "source": [
    "PAT_NOW = \"S21_160\"\n",
    "PAT_SHORT_NAME = \"S_160\"\n",
    "\n",
    "MOOD_TRACKING_SHEET_PATH = f'/home/klab/NAS/Analysis/AudioFacialEEG/Behavioral Labeling/Mood_Tracking.xlsx'\n",
    "\n",
    "BEHAVIORAL_LABELS_SHEET_PATH = f'/home/klab/NAS/Analysis/AudioFacialEEG/Behavioral Labeling/Behavior_Labeling.xlsx'\n",
    "\n",
    "VIDEO_TIMESTAMPS_SHEET_PATH = f'/home/klab/NAS/Analysis/AudioFacialEEG/Behavioral Labeling/videoDateTimes/VideoDatetimes{PAT_SHORT_NAME[1:]}.xlsx'\n",
    "\n",
    "OPENFACE_OUTPUT_DIRECTORY = f'/home/klab/NAS/Analysis/outputs_OpenFace/{PAT_NOW}/'\n",
    "COMBINED_OUTPUT_DIRECTORY = f'/home/klab/NAS/Analysis/outputs_Combined/{PAT_NOW}/'\n",
    "\n",
    "RUNTIME_VAR_PATH = '/home/klab/NAS/Analysis/AudioFacialEEG/Runtime_Vars/'\n",
    "RESULTS_PATH_BASE = f'/home/klab/NAS/Analysis/AudioFacialEEG/Results/{PAT_SHORT_NAME}/'\n",
    "FEATURE_VIS_PATH = f'/home/klab/NAS/Analysis/AudioFacialEEG/Feature_Visualization/{PAT_SHORT_NAME}/'\n",
    "FEATURE_LABEL_PATH = '/home/klab/NAS/Analysis/AudioFacialEEG/Feature_Labels/'\n",
    "QC_PATH = '/home/klab/NAS/Analysis/AudioFacialEEG/Quality_Control/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "id": "91MVRRaOj-FH"
   },
   "outputs": [],
   "source": [
    "EMO_FEATURE_SETTING = 2\n",
    "\n",
    "# 0 - Our Custom AU --> Emotions, with all emotions\n",
    "# 1 - Our Custom AU --> Emotions, with just OpenDBM's emotions\n",
    "# 2 - OpenDBM's AU--> Emotions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "id": "b_KxZhrQtcmv"
   },
   "outputs": [],
   "source": [
    "STATS_FEATURE_SETTING = 3\n",
    "\n",
    "# 0 - Our new features (including autocorrelation, kurtosis, etc.)\n",
    "# 1 - Our new features, excluding extras like autocorrelation and kurtosis\n",
    "# 2 - Just pres_pct\n",
    "# 3 - Our new features, excluding extras. Do NOT threshold AUs before computing metrics. HSE gets 5 event features. OGAU gets num events and presence percent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "id": "VIc4rrMwD8N9"
   },
   "outputs": [],
   "source": [
    "NORMALIZE_DATA = 0\n",
    "\n",
    "# 0 - No time series normalization\n",
    "# 1 - Yes time series normalization (for each time window)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SU72QcAcVyLy"
   },
   "source": [
    "# Installs & Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "id": "t7QHCYhjQTQ0"
   },
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "id": "LRX3feHKIR1z"
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "import pandas as pd\n",
    "\n",
    "# Ignore all warnings\n",
    "pd.options.mode.chained_assignment = None\n",
    "pd.set_option('mode.chained_assignment', None)\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_kKGUjhTqo-3"
   },
   "source": [
    "# Runtime Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "id": "d6_t0DlpTFmi"
   },
   "outputs": [],
   "source": [
    "# SAVE VARIABLES\n",
    "import pickle\n",
    "\n",
    "\n",
    "def get_var_name(our_variable):\n",
    "    namespace = globals()\n",
    "    for name, obj in namespace.items():\n",
    "        if obj is our_variable:\n",
    "            return name\n",
    "    return None\n",
    "\n",
    "# Save the dictionary to a file using pickle\n",
    "def save_var(our_variable, RUNTIME_VAR_PATH=RUNTIME_VAR_PATH, forced_name=None):\n",
    "  if forced_name is None:\n",
    "    name_now = get_var_name(our_variable)\n",
    "  else:\n",
    "    name_now = forced_name\n",
    "\n",
    "  with open(RUNTIME_VAR_PATH + f'{name_now}.pkl', 'wb') as file:\n",
    "      pickle.dump(our_variable, file)\n",
    "\n",
    "def load_var(variable_name, RUNTIME_VAR_PATH=RUNTIME_VAR_PATH):\n",
    "  # Load from the file\n",
    "  with open(RUNTIME_VAR_PATH + f'{variable_name}.pkl', 'rb') as file:\n",
    "      return pickle.load(file)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-N5cJiTpuyVr"
   },
   "source": [
    "# Video Timestamps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "id": "QoONs-gXu0NZ"
   },
   "outputs": [],
   "source": [
    "df_videoTimestamps = pd.read_excel(VIDEO_TIMESTAMPS_SHEET_PATH, sheet_name=f'VideoDatetimes_{PAT_SHORT_NAME.split(\"_\")[-1]}')\n",
    "df_videoTimestamps['Filename'] = df_videoTimestamps['Filename'].str.replace('.m2t', '')\n",
    "\n",
    "if PAT_SHORT_NAME == 'S_199':\n",
    "  # There's no H01 video, so let's drop that filename\n",
    "  df_videoTimestamps = df_videoTimestamps.drop(211)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "id": "M7WfI-u-PR2h"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18926Y00\n",
      "18926Z00\n"
     ]
    }
   ],
   "source": [
    "# Check for any missing videos!\n",
    "\n",
    "def print_difference(list1, list2):\n",
    "    for item in list1:\n",
    "        if item not in list2:\n",
    "            print(item)\n",
    "\n",
    "filenames_master_list = list(df_videoTimestamps['Filename'].values)\n",
    "filenames_we_have = [i[:-4] for i in os.listdir(COMBINED_OUTPUT_DIRECTORY)]\n",
    "\n",
    "print_difference(filenames_master_list, filenames_we_have)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "id": "cqMfPe79vFRv"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Filename</th>\n",
       "      <th>VideoStart</th>\n",
       "      <th>VideoEnd</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>229</th>\n",
       "      <td>1892DB00</td>\n",
       "      <td>2021-03-01 05:53:51</td>\n",
       "      <td>2021-03-01 06:53:47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>230</th>\n",
       "      <td>1892DC00</td>\n",
       "      <td>2021-03-01 06:53:51</td>\n",
       "      <td>2021-03-01 07:53:47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>231</th>\n",
       "      <td>1892DD00</td>\n",
       "      <td>2021-03-01 07:53:51</td>\n",
       "      <td>2021-03-01 08:53:47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>232</th>\n",
       "      <td>1892DE00</td>\n",
       "      <td>2021-03-01 08:53:51</td>\n",
       "      <td>2021-03-01 09:53:46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>233</th>\n",
       "      <td>1892DJ00</td>\n",
       "      <td>2021-03-01 13:53:51</td>\n",
       "      <td>2021-03-01 14:36:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Filename          VideoStart            VideoEnd\n",
       "229  1892DB00 2021-03-01 05:53:51 2021-03-01 06:53:47\n",
       "230  1892DC00 2021-03-01 06:53:51 2021-03-01 07:53:47\n",
       "231  1892DD00 2021-03-01 07:53:51 2021-03-01 08:53:47\n",
       "232  1892DE00 2021-03-01 08:53:51 2021-03-01 09:53:46\n",
       "233  1892DJ00 2021-03-01 13:53:51 2021-03-01 14:36:00"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_videoTimestamps[-5:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Fbw5bePEHjOu"
   },
   "source": [
    "# Danny's Labels (Smile, Laugh, etc.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "id": "TTuEt1ryHoU0"
   },
   "outputs": [],
   "source": [
    "df = pd.read_excel(BEHAVIORAL_LABELS_SHEET_PATH, sheet_name=PAT_NOW, dtype={'Filename': str})\n",
    "\n",
    "columns_to_keep = ['Filename', 'Time Start', 'Time End', 'Behavior']  # List of columns to keep\n",
    "\n",
    "df = df[columns_to_keep]\n",
    "\n",
    "df['Behavior'] = df['Behavior'].str.lower()\n",
    "df.dropna(how='any', inplace=True)\n",
    "\n",
    "\n",
    "# Function to correct the time format\n",
    "def correct_time_format(time_str):\n",
    "    time_str = str(time_str).strip()\n",
    "    \n",
    "    # Try parsing the time as \"HH:MM:SS\" first\n",
    "    time_val = pd.to_datetime(time_str, format='%H:%M:%S', errors='coerce')\n",
    "    if pd.isna(time_val):\n",
    "        # If parsing failed, try \"M:SS\" or \"MM:SS\" next\n",
    "        time_val = pd.to_datetime(time_str, format='%M:%S', errors='coerce')\n",
    "        if pd.isna(time_val):\n",
    "            # If still fails, handle or raise error\n",
    "            print(time_str)\n",
    "            raise ValueError(\"Invalid time format\")\n",
    "        else:\n",
    "            # Adjust for \"M:SS\" or \"MM:SS\" as \"00:M:SS\"\n",
    "            corrected_time = pd.to_datetime(f\"00:{time_str}\", format='%H:%M:%S').time()\n",
    "    else:\n",
    "        corrected_time = time_val.time()\n",
    "\n",
    "    return corrected_time\n",
    "\n",
    "\n",
    "# Apply the correction to 'Time Start' and 'Time End'\n",
    "df['Time Start'] = df['Time Start'].apply(correct_time_format)\n",
    "df['Time End'] = df['Time End'].apply(correct_time_format)\n",
    "\n",
    "\n",
    "Danny_Labels = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "Danny_Labels.dropna(how='any', inplace=True)\n",
    "Danny_Labels.loc[:, Danny_Labels.columns.str.contains('Time')] = Danny_Labels.loc[:, Danny_Labels.columns.str.contains('Time')].applymap(lambda x: x.replace(' ', '') if isinstance(x, str) else x)\n",
    "Danny_Labels.loc[:, Danny_Labels.columns.str.contains('Time')] = Danny_Labels.loc[:, Danny_Labels.columns.str.contains('Time')].applymap(lambda x: re.sub(r'(?<=:)(\\d)(?=:)', r'0\\1', x) if isinstance(x, str) else x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "id": "JYzTk6QFHoaV"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Filename</th>\n",
       "      <th>Time Start</th>\n",
       "      <th>Time End</th>\n",
       "      <th>Behavior</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>18927100</td>\n",
       "      <td>00:27:30</td>\n",
       "      <td>00:29:30</td>\n",
       "      <td>phlebotomy draw, discomfort</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>18927200</td>\n",
       "      <td>00:42:51</td>\n",
       "      <td>00:42:58</td>\n",
       "      <td>grimace, discomfort</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>18927200</td>\n",
       "      <td>00:43:15</td>\n",
       "      <td>00:43:46</td>\n",
       "      <td>grimace, discomfort</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>18927200</td>\n",
       "      <td>00:50:03</td>\n",
       "      <td>00:50:07</td>\n",
       "      <td>grimace, discomfort</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>18927R00</td>\n",
       "      <td>00:25:25</td>\n",
       "      <td>00:25:27</td>\n",
       "      <td>said ow, starting to hurt, discomfort</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>18927A00</td>\n",
       "      <td>00:05:16</td>\n",
       "      <td>00:05:53</td>\n",
       "      <td>phlebotomy draw, discomfort</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>18927Y00</td>\n",
       "      <td>00:14:13</td>\n",
       "      <td>00:14:55</td>\n",
       "      <td>phlebotomy draw, discomfort</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>18928N00</td>\n",
       "      <td>00:27:02</td>\n",
       "      <td>00:27:36</td>\n",
       "      <td>phlebotomy draw, discomfort</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>18928N00</td>\n",
       "      <td>00:27:37</td>\n",
       "      <td>00:27:42</td>\n",
       "      <td>smile with chuckle</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>18929B00</td>\n",
       "      <td>00:31:58</td>\n",
       "      <td>00:33:32</td>\n",
       "      <td>phlebotomy draw, discomfort</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>18929Y00</td>\n",
       "      <td>00:20:10</td>\n",
       "      <td>00:21:08</td>\n",
       "      <td>phlebotomy draw, discomfort</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1892AN00</td>\n",
       "      <td>00:21:33</td>\n",
       "      <td>00:22:05</td>\n",
       "      <td>phlebotomy draw, discomfort</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1892BA00</td>\n",
       "      <td>00:30:51</td>\n",
       "      <td>00:31:38</td>\n",
       "      <td>phlebotomy draw, little discomfort</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1892BM00</td>\n",
       "      <td>00:00:20</td>\n",
       "      <td>00:00:23</td>\n",
       "      <td>smile</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1892BM00</td>\n",
       "      <td>00:00:40</td>\n",
       "      <td>00:00:46</td>\n",
       "      <td>smile</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1892BM00</td>\n",
       "      <td>00:01:07</td>\n",
       "      <td>00:01:17</td>\n",
       "      <td>smile with chuckle</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1892BM00</td>\n",
       "      <td>00:01:30</td>\n",
       "      <td>00:01:40</td>\n",
       "      <td>neutral expression</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1892BM00</td>\n",
       "      <td>00:01:42</td>\n",
       "      <td>00:01:53</td>\n",
       "      <td>big laughter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1892BM00</td>\n",
       "      <td>00:01:57</td>\n",
       "      <td>00:02:00</td>\n",
       "      <td>neutral expression</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1892BM00</td>\n",
       "      <td>00:02:01</td>\n",
       "      <td>00:02:07</td>\n",
       "      <td>yawn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1892BM00</td>\n",
       "      <td>00:02:08</td>\n",
       "      <td>00:02:50</td>\n",
       "      <td>neutral expression, resting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>1892BM00</td>\n",
       "      <td>00:02:55</td>\n",
       "      <td>00:02:58</td>\n",
       "      <td>small yawn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>1892BM00</td>\n",
       "      <td>00:03:27</td>\n",
       "      <td>00:03:33</td>\n",
       "      <td>yawn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>1892BM00</td>\n",
       "      <td>00:03:56</td>\n",
       "      <td>00:04:21</td>\n",
       "      <td>neutral, using phone</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>1892BM00</td>\n",
       "      <td>00:04:23</td>\n",
       "      <td>00:04:29</td>\n",
       "      <td>yawn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>1892BM00</td>\n",
       "      <td>00:05:01</td>\n",
       "      <td>00:10:48</td>\n",
       "      <td>neutral, using phone</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>1892BM00</td>\n",
       "      <td>00:12:04</td>\n",
       "      <td>00:15:48</td>\n",
       "      <td>neutral, using phone</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>1892BM00</td>\n",
       "      <td>00:23:41</td>\n",
       "      <td>00:23:48</td>\n",
       "      <td>smile with chuckle</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>1892BM00</td>\n",
       "      <td>00:24:08</td>\n",
       "      <td>00:24:27</td>\n",
       "      <td>smile with chuckle</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>1892BM00</td>\n",
       "      <td>00:35:04</td>\n",
       "      <td>00:35:08</td>\n",
       "      <td>smile with chuckle</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>1892BM00</td>\n",
       "      <td>00:38:26</td>\n",
       "      <td>00:38:30</td>\n",
       "      <td>smile with chuckle</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>1892BM00</td>\n",
       "      <td>00:38:47</td>\n",
       "      <td>00:39:04</td>\n",
       "      <td>iv insertion, facial grimace, body jumped, dis...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>1892BM00</td>\n",
       "      <td>00:48:18</td>\n",
       "      <td>00:51:06</td>\n",
       "      <td>watching tv, neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>1892BM00</td>\n",
       "      <td>00:51:18</td>\n",
       "      <td>00:52:52</td>\n",
       "      <td>neutral, using phone</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>1892BM00</td>\n",
       "      <td>00:52:54</td>\n",
       "      <td>00:59:59</td>\n",
       "      <td>watching tv, neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>1892C000</td>\n",
       "      <td>00:21:35</td>\n",
       "      <td>00:22:30</td>\n",
       "      <td>phlebotomy draw, little discomfort</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>1892CN00</td>\n",
       "      <td>00:00:04</td>\n",
       "      <td>00:01:43</td>\n",
       "      <td>phlebotomy draw, facial grimace, discomfort</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>1892CN00</td>\n",
       "      <td>00:03:38</td>\n",
       "      <td>00:03:53</td>\n",
       "      <td>neutral expression</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>1892CN00</td>\n",
       "      <td>00:04:35</td>\n",
       "      <td>00:05:32</td>\n",
       "      <td>phlebotomy draw, little discomfort</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>1892CN00</td>\n",
       "      <td>00:56:26</td>\n",
       "      <td>00:56:45</td>\n",
       "      <td>facial grimace from headache, discomfort</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>1892CN00</td>\n",
       "      <td>00:57:07</td>\n",
       "      <td>00:57:10</td>\n",
       "      <td>facial grimace from headache, discomfort</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>1892CN00</td>\n",
       "      <td>00:57:18</td>\n",
       "      <td>00:57:45</td>\n",
       "      <td>facial grimace from headache, discomfort</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>1892CN00</td>\n",
       "      <td>00:58:11</td>\n",
       "      <td>00:58:40</td>\n",
       "      <td>facial grimace and tears from pain, discomfort</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>1892CN00</td>\n",
       "      <td>00:59:10</td>\n",
       "      <td>00:59:15</td>\n",
       "      <td>facial grimace from headache,discomfort</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>1892CN00</td>\n",
       "      <td>00:59:16</td>\n",
       "      <td>00:59:18</td>\n",
       "      <td>yawn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>1892CN00</td>\n",
       "      <td>00:59:37</td>\n",
       "      <td>00:59:55</td>\n",
       "      <td>neutral, using phone</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>1892DA00</td>\n",
       "      <td>00:08:42</td>\n",
       "      <td>00:08:52</td>\n",
       "      <td>laughter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>1892DA00</td>\n",
       "      <td>00:09:11</td>\n",
       "      <td>00:09:21</td>\n",
       "      <td>yawn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>1892DA00</td>\n",
       "      <td>00:09:38</td>\n",
       "      <td>00:09:48</td>\n",
       "      <td>laughter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>1892DA00</td>\n",
       "      <td>00:09:59</td>\n",
       "      <td>00:10:08</td>\n",
       "      <td>smile with chuckle</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>1892DA00</td>\n",
       "      <td>00:10:08</td>\n",
       "      <td>00:10:10</td>\n",
       "      <td>yawn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>1892DA00</td>\n",
       "      <td>00:10:53</td>\n",
       "      <td>00:11:11</td>\n",
       "      <td>laughter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>1892DA00</td>\n",
       "      <td>00:11:14</td>\n",
       "      <td>00:11:34</td>\n",
       "      <td>big laughter episode</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>1892DA00</td>\n",
       "      <td>00:11:38</td>\n",
       "      <td>00:12:24</td>\n",
       "      <td>phlebotomy draw, little discomfort, was smilin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>1892DA00</td>\n",
       "      <td>00:13:11</td>\n",
       "      <td>00:13:39</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>1892DA00</td>\n",
       "      <td>00:13:46</td>\n",
       "      <td>00:13:51</td>\n",
       "      <td>smile</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>1892DA00</td>\n",
       "      <td>00:13:58</td>\n",
       "      <td>00:14:07</td>\n",
       "      <td>yawn</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Filename Time Start  Time End  \\\n",
       "0   18927100   00:27:30  00:29:30   \n",
       "1   18927200   00:42:51  00:42:58   \n",
       "2   18927200   00:43:15  00:43:46   \n",
       "3   18927200   00:50:03  00:50:07   \n",
       "4   18927R00   00:25:25  00:25:27   \n",
       "5   18927A00   00:05:16  00:05:53   \n",
       "6   18927Y00   00:14:13  00:14:55   \n",
       "7   18928N00   00:27:02  00:27:36   \n",
       "8   18928N00   00:27:37  00:27:42   \n",
       "9   18929B00   00:31:58  00:33:32   \n",
       "10  18929Y00   00:20:10  00:21:08   \n",
       "11  1892AN00   00:21:33  00:22:05   \n",
       "12  1892BA00   00:30:51  00:31:38   \n",
       "13  1892BM00   00:00:20  00:00:23   \n",
       "14  1892BM00   00:00:40  00:00:46   \n",
       "15  1892BM00   00:01:07  00:01:17   \n",
       "16  1892BM00   00:01:30  00:01:40   \n",
       "17  1892BM00   00:01:42  00:01:53   \n",
       "18  1892BM00   00:01:57  00:02:00   \n",
       "19  1892BM00   00:02:01  00:02:07   \n",
       "20  1892BM00   00:02:08  00:02:50   \n",
       "21  1892BM00   00:02:55  00:02:58   \n",
       "22  1892BM00   00:03:27  00:03:33   \n",
       "23  1892BM00   00:03:56  00:04:21   \n",
       "24  1892BM00   00:04:23  00:04:29   \n",
       "25  1892BM00   00:05:01  00:10:48   \n",
       "26  1892BM00   00:12:04  00:15:48   \n",
       "27  1892BM00   00:23:41  00:23:48   \n",
       "28  1892BM00   00:24:08  00:24:27   \n",
       "29  1892BM00   00:35:04  00:35:08   \n",
       "30  1892BM00   00:38:26  00:38:30   \n",
       "31  1892BM00   00:38:47  00:39:04   \n",
       "32  1892BM00   00:48:18  00:51:06   \n",
       "33  1892BM00   00:51:18  00:52:52   \n",
       "34  1892BM00   00:52:54  00:59:59   \n",
       "35  1892C000   00:21:35  00:22:30   \n",
       "36  1892CN00   00:00:04  00:01:43   \n",
       "37  1892CN00   00:03:38  00:03:53   \n",
       "38  1892CN00   00:04:35  00:05:32   \n",
       "39  1892CN00   00:56:26  00:56:45   \n",
       "40  1892CN00   00:57:07  00:57:10   \n",
       "41  1892CN00   00:57:18  00:57:45   \n",
       "42  1892CN00   00:58:11  00:58:40   \n",
       "43  1892CN00   00:59:10  00:59:15   \n",
       "44  1892CN00   00:59:16  00:59:18   \n",
       "45  1892CN00   00:59:37  00:59:55   \n",
       "46  1892DA00   00:08:42  00:08:52   \n",
       "47  1892DA00   00:09:11  00:09:21   \n",
       "48  1892DA00   00:09:38  00:09:48   \n",
       "49  1892DA00   00:09:59  00:10:08   \n",
       "50  1892DA00   00:10:08  00:10:10   \n",
       "51  1892DA00   00:10:53  00:11:11   \n",
       "52  1892DA00   00:11:14  00:11:34   \n",
       "53  1892DA00   00:11:38  00:12:24   \n",
       "54  1892DA00   00:13:11  00:13:39   \n",
       "55  1892DA00   00:13:46  00:13:51   \n",
       "56  1892DA00   00:13:58  00:14:07   \n",
       "\n",
       "                                             Behavior  \n",
       "0                         phlebotomy draw, discomfort  \n",
       "1                                 grimace, discomfort  \n",
       "2                                 grimace, discomfort  \n",
       "3                                 grimace, discomfort  \n",
       "4               said ow, starting to hurt, discomfort  \n",
       "5                         phlebotomy draw, discomfort  \n",
       "6                         phlebotomy draw, discomfort  \n",
       "7                         phlebotomy draw, discomfort  \n",
       "8                                  smile with chuckle  \n",
       "9                         phlebotomy draw, discomfort  \n",
       "10                        phlebotomy draw, discomfort  \n",
       "11                        phlebotomy draw, discomfort  \n",
       "12                 phlebotomy draw, little discomfort  \n",
       "13                                              smile  \n",
       "14                                              smile  \n",
       "15                                 smile with chuckle  \n",
       "16                                 neutral expression  \n",
       "17                                       big laughter  \n",
       "18                                 neutral expression  \n",
       "19                                               yawn  \n",
       "20                        neutral expression, resting  \n",
       "21                                         small yawn  \n",
       "22                                               yawn  \n",
       "23                               neutral, using phone  \n",
       "24                                               yawn  \n",
       "25                               neutral, using phone  \n",
       "26                               neutral, using phone  \n",
       "27                                 smile with chuckle  \n",
       "28                                 smile with chuckle  \n",
       "29                                 smile with chuckle  \n",
       "30                                 smile with chuckle  \n",
       "31  iv insertion, facial grimace, body jumped, dis...  \n",
       "32                              watching tv, neutral   \n",
       "33                               neutral, using phone  \n",
       "34                              watching tv, neutral   \n",
       "35                 phlebotomy draw, little discomfort  \n",
       "36        phlebotomy draw, facial grimace, discomfort  \n",
       "37                                 neutral expression  \n",
       "38                 phlebotomy draw, little discomfort  \n",
       "39           facial grimace from headache, discomfort  \n",
       "40           facial grimace from headache, discomfort  \n",
       "41           facial grimace from headache, discomfort  \n",
       "42     facial grimace and tears from pain, discomfort  \n",
       "43            facial grimace from headache,discomfort  \n",
       "44                                               yawn  \n",
       "45                               neutral, using phone  \n",
       "46                                           laughter  \n",
       "47                                               yawn  \n",
       "48                                           laughter  \n",
       "49                                 smile with chuckle  \n",
       "50                                               yawn  \n",
       "51                                           laughter  \n",
       "52                               big laughter episode  \n",
       "53  phlebotomy draw, little discomfort, was smilin...  \n",
       "54                                            neutral  \n",
       "55                                              smile  \n",
       "56                                               yawn  "
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Danny_Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "id": "Klnlxpllu2D2"
   },
   "outputs": [],
   "source": [
    "def filter_df_by_behavior(df, desired_string):\n",
    "    # Create a copy of the DataFrame\n",
    "    filtered_df = df.copy()\n",
    "\n",
    "    # Filter the DataFrame based on the desired string within 'Behavior' column\n",
    "    filtered_df = filtered_df[filtered_df['Behavior'].str.contains(desired_string)]\n",
    "\n",
    "    # Reset the index of the filtered DataFrame\n",
    "    filtered_df = filtered_df.reset_index(drop=True)\n",
    "\n",
    "    # Return the filtered DataFrame\n",
    "    return filtered_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "\n",
    "\n",
    "def add_time_strings(t1, t2):\n",
    "    total_seconds = sum(x.total_seconds() for x in [pd.to_timedelta(t) for t in [t1, t2]])\n",
    "    return str(pd.to_timedelta(total_seconds, unit='s'))\n",
    "\n",
    "\n",
    "def convert_time(df1, df2):\n",
    "    if df1.empty:\n",
    "        return df1\n",
    "\n",
    "    modified_df = df1.copy()\n",
    "\n",
    "    filename_to_videostart = dict(zip(df2['Filename'], df2['VideoStart']))\n",
    "\n",
    "    def handle_time_conversion(row, time_field):\n",
    "        video_start = filename_to_videostart.get(str(row['Filename']), None)\n",
    "        if video_start is None:\n",
    "            return None\n",
    "\n",
    "        try:\n",
    "            # Get the base date from the video start datetime.\n",
    "            base_date = video_start.date() if isinstance(video_start, datetime.datetime) else pd.to_datetime(video_start).date()\n",
    "        except Exception:\n",
    "            return None\n",
    "\n",
    "        time_value = row[time_field]\n",
    "        if time_value is None:\n",
    "            return None\n",
    "\n",
    "        try:\n",
    "            # Convert the time value to a string and then to a timedelta.\n",
    "            time_str = time_value.strftime('%H:%M:%S') if isinstance(time_value, datetime.time) else time_value\n",
    "            final_timedelta = pd.to_timedelta(time_str)\n",
    "            # Create a complete datetime object using the base date and the time from the timedelta.\n",
    "            final_time = pd.Timestamp(base_date) + final_timedelta\n",
    "            return final_time\n",
    "        except Exception:\n",
    "            return None\n",
    "\n",
    "    \n",
    "    # Apply time conversion and maintain the output as Timestamps.\n",
    "    modified_df['Time Start'] = modified_df.apply(lambda row: handle_time_conversion(row, 'Time Start'), axis=1)\n",
    "    modified_df['Time End'] = modified_df.apply(lambda row: handle_time_conversion(row, 'Time End'), axis=1)\n",
    "\n",
    "    return modified_df\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "id": "-7BX6qD1hgA3"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def buffer_neither(smiles_df, sleep_df):\n",
    "    # Convert time columns to datetime if not already\n",
    "    smiles_df['Time Start'] = pd.to_datetime(smiles_df['Time Start'], errors='coerce')\n",
    "    smiles_df['Time End'] = pd.to_datetime(smiles_df['Time End'], errors='coerce')\n",
    "\n",
    "    if not sleep_df.empty:\n",
    "        sleep_df['Time Start'] = pd.to_datetime(sleep_df['Time Start'], errors='coerce')\n",
    "        sleep_df['Time End'] = pd.to_datetime(sleep_df['Time End'], errors='coerce')\n",
    "\n",
    "    # Drop rows with NaT values in smiles dataframe\n",
    "    smiles_df = smiles_df.dropna(subset=['Time Start', 'Time End'])\n",
    "\n",
    "    # Check if sleep dataframe is not empty and drop rows with NaT values\n",
    "    if not sleep_df.empty:\n",
    "        sleep_df = sleep_df.dropna(subset=['Time Start', 'Time End'])\n",
    "\n",
    "    # If both dataframes are empty\n",
    "    if smiles_df.empty and (sleep_df.empty or sleep_df is None):\n",
    "        return pd.DataFrame(columns=['Time'])  # Return empty dataframe if no data available\n",
    "\n",
    "    # Define ranges using non-empty dataframe(s)\n",
    "    start_times = pd.Series(smiles_df['Time Start'].tolist() + (sleep_df['Time Start'].tolist() if not sleep_df.empty else [])).dropna()\n",
    "    end_times = pd.Series(smiles_df['Time End'].tolist() + (sleep_df['Time End'].tolist() if not sleep_df.empty else [])).dropna()\n",
    "\n",
    "    if start_times.empty or end_times.empty:\n",
    "        return pd.DataFrame(columns=['Time'])  # Return empty dataframe if no valid times are available\n",
    "\n",
    "    # Find the earliest and latest times\n",
    "    start_time = start_times.min()\n",
    "    end_time = end_times.max()\n",
    "\n",
    "    # Create a DataFrame with fixed frequency for the time range\n",
    "    time_range = pd.date_range(start=start_time, end=end_time, freq='10S')\n",
    "    tracking_df = pd.DataFrame({'Time': time_range, 'BufferSafe': True})\n",
    "\n",
    "    # Set BufferSafe status based on proximity to smile and sleep events\n",
    "    for i in range(len(tracking_df)):\n",
    "        time = tracking_df.loc[i, 'Time']\n",
    "        buffer_before = time - pd.Timedelta(minutes=1)\n",
    "        buffer_after = time + pd.Timedelta(minutes=1)\n",
    "\n",
    "        has_smile_within_buffer = smiles_df[((smiles_df['Time Start'] <= buffer_after) & (smiles_df['Time End'] >= buffer_before))].shape[0] > 0\n",
    "        has_sleep_within_buffer = False if sleep_df.empty else (sleep_df[((sleep_df['Time Start'] <= buffer_after) & (sleep_df['Time End'] >= buffer_before))].shape[0] > 0)\n",
    "        tracking_df.loc[i, 'BufferSafe'] = not (has_smile_within_buffer or has_sleep_within_buffer)\n",
    "\n",
    "    return tracking_df[tracking_df['BufferSafe']]['Time'].reset_index(drop=True)\n",
    "\n",
    "\n",
    "def create_event_detection_df(smiles_df, safe_series):\n",
    "    # Create a new DataFrame for event detection\n",
    "    event_detection_df = pd.DataFrame(columns=['Datetime', 'EventDetected'])\n",
    "    # Iterate over each row in the smiles_df\n",
    "    for index, row in smiles_df.iterrows():\n",
    "        start_time = row['Time Start']\n",
    "        end_time = row['Time End']\n",
    "\n",
    "        # Generate a range of timestamps at a frequency of 1 second\n",
    "        timestamps = pd.date_range(start=start_time, end=end_time, freq='S', inclusive='right')\n",
    "\n",
    "        # Add each timestamp as a separate row to the event_detection_df\n",
    "        for timestamp in timestamps:\n",
    "            event_detection_df = pd.concat([event_detection_df, pd.DataFrame.from_records([{'Datetime': timestamp, 'EventDetected': 1}])], ignore_index=True)\n",
    "\n",
    "    # Get the length of the smile event DataFrame\n",
    "    num_smiles = len(event_detection_df)\n",
    "\n",
    "    num_of_each_class = min(len(safe_series), num_smiles)\n",
    "    \n",
    "    # Randomly sample from the buffer safe Series\n",
    "    sampled_safe_series = safe_series.sample(n=num_of_each_class, replace=False)\n",
    "\n",
    "    # Randomly sample from the event detection df\n",
    "    event_detection_df = event_detection_df.sample(n=num_of_each_class, replace=False).reset_index(drop=True)\n",
    "    \n",
    "    # Add nonsmile nonsleep events to the DataFrame\n",
    "    nonsmile_nonsleep_times = sampled_safe_series.reset_index(drop=True)\n",
    "    nonsmile_nonsleep_df = pd.DataFrame({'Datetime': nonsmile_nonsleep_times, 'EventDetected': 0})\n",
    "    event_detection_df = pd.concat([event_detection_df, nonsmile_nonsleep_df], ignore_index=True)\n",
    "\n",
    "    # Sort the DataFrame by DateTime in ascending order\n",
    "    event_detection_df = event_detection_df.sort_values(by='Datetime').reset_index(drop=True)\n",
    "\n",
    "    return event_detection_df\n",
    "\n",
    "def get_labels(smile_string, sleep_string):\n",
    "  # gets us our labels df (DateTime and EventDetected columns)\n",
    "  # note: doesn't need to be smiles. Replace 'smile' with any other event as first arg.\n",
    "\n",
    "  # smile string is what we want to detect\n",
    "  # sleep string is what we label as neither smile nor non-smile\n",
    "  # i.e. if a time period is labeled as sleep, exclude from dataset\n",
    "\n",
    "  # Make sure Danny_Labels and df_videoTimestamps have been loaded in already!\n",
    "\n",
    "  Smile_Labels = filter_df_by_behavior(Danny_Labels, smile_string)\n",
    "  Sleep_Labels = filter_df_by_behavior(Danny_Labels, sleep_string)\n",
    "  \n",
    "    \n",
    "  smiles_df = convert_time(Smile_Labels, df_videoTimestamps)\n",
    "  sleep_df = convert_time(Sleep_Labels, df_videoTimestamps)\n",
    "  \n",
    "\n",
    "  non_smile_non_sleep_times = buffer_neither(smiles_df, sleep_df)\n",
    "\n",
    "  # We need at least 5 events (probably even more) to be able to train a model\n",
    "  if len(smiles_df) < 5:\n",
    "      return pd.DataFrame()\n",
    "\n",
    "  return create_event_detection_df(smiles_df, non_smile_non_sleep_times)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "id": "pZ0z-xCgwP6Q"
   },
   "outputs": [],
   "source": [
    "# NOTE: The events are defined such that we label the END time and time window looks at 1 s preceding\n",
    "\n",
    "# Eventually, we should run this 500 times to get range of AUROC\n",
    "\n",
    "Final_Smile_Labels = get_labels('smile', 'sleep')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "id": "7tTEJO0CwTKq"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Datetime</th>\n",
       "      <th>EventDetected</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021-02-22 00:27:38</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021-02-22 00:27:39</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021-02-22 00:27:40</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2021-02-22 00:27:41</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2021-02-22 00:27:42</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>2021-03-01 00:13:47</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>2021-03-01 00:13:48</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>2021-03-01 00:13:49</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>2021-03-01 00:13:50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>2021-03-01 00:13:51</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>144 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               Datetime EventDetected\n",
       "0   2021-02-22 00:27:38             1\n",
       "1   2021-02-22 00:27:39             1\n",
       "2   2021-02-22 00:27:40             1\n",
       "3   2021-02-22 00:27:41             1\n",
       "4   2021-02-22 00:27:42             1\n",
       "..                  ...           ...\n",
       "139 2021-03-01 00:13:47             1\n",
       "140 2021-03-01 00:13:48             1\n",
       "141 2021-03-01 00:13:49             1\n",
       "142 2021-03-01 00:13:50             1\n",
       "143 2021-03-01 00:13:51             1\n",
       "\n",
       "[144 rows x 2 columns]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Final_Smile_Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "id": "yWzUpbdBYd2C"
   },
   "outputs": [],
   "source": [
    "Final_Yawn_Labels = get_labels('yawn', 'sleep')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "id": "qDMfrm6WYfS1"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Datetime</th>\n",
       "      <th>EventDetected</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021-02-26 00:02:02</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021-02-26 00:02:03</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021-02-26 00:02:04</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2021-02-26 00:02:05</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2021-02-26 00:02:06</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>2021-03-01 00:14:03</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>2021-03-01 00:14:04</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>2021-03-01 00:14:05</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>2021-03-01 00:14:06</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>2021-03-01 00:14:07</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>88 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              Datetime EventDetected\n",
       "0  2021-02-26 00:02:02             1\n",
       "1  2021-02-26 00:02:03             1\n",
       "2  2021-02-26 00:02:04             1\n",
       "3  2021-02-26 00:02:05             1\n",
       "4  2021-02-26 00:02:06             1\n",
       "..                 ...           ...\n",
       "83 2021-03-01 00:14:03             1\n",
       "84 2021-03-01 00:14:04             1\n",
       "85 2021-03-01 00:14:05             1\n",
       "86 2021-03-01 00:14:06             1\n",
       "87 2021-03-01 00:14:07             1\n",
       "\n",
       "[88 rows x 2 columns]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Final_Yawn_Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "id": "fSYsDNu08rQq"
   },
   "outputs": [],
   "source": [
    "Final_Discomfort_Labels = get_labels('discomfort', 'sleep')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "id": "IGStcnbt8128"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Datetime</th>\n",
       "      <th>EventDetected</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021-02-19 00:27:31</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021-02-19 00:27:32</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021-02-19 00:27:33</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2021-02-19 00:27:34</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2021-02-19 00:27:35</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1725</th>\n",
       "      <td>2021-03-01 00:12:20</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1726</th>\n",
       "      <td>2021-03-01 00:12:21</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1727</th>\n",
       "      <td>2021-03-01 00:12:22</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1728</th>\n",
       "      <td>2021-03-01 00:12:23</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1729</th>\n",
       "      <td>2021-03-01 00:12:24</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1730 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                Datetime EventDetected\n",
       "0    2021-02-19 00:27:31             1\n",
       "1    2021-02-19 00:27:32             1\n",
       "2    2021-02-19 00:27:33             1\n",
       "3    2021-02-19 00:27:34             1\n",
       "4    2021-02-19 00:27:35             1\n",
       "...                  ...           ...\n",
       "1725 2021-03-01 00:12:20             1\n",
       "1726 2021-03-01 00:12:21             1\n",
       "1727 2021-03-01 00:12:22             1\n",
       "1728 2021-03-01 00:12:23             1\n",
       "1729 2021-03-01 00:12:24             1\n",
       "\n",
       "[1730 rows x 2 columns]"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Final_Discomfort_Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "id": "h_G9TSa3Nm_h"
   },
   "outputs": [],
   "source": [
    "Final_Sad_Labels = get_labels('sad', 'sleep')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "id": "QgOC-mWINnPf"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: []"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Final_Sad_Labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dOrT1X_9WU5X"
   },
   "source": [
    "# OpenFace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "id": "YV8_wmALY-hV"
   },
   "outputs": [],
   "source": [
    "# DICTIONARY OF SEPARATE DFS\n",
    "\n",
    "def get_dict_openface(output_dir):\n",
    "    # Create an empty dictionary to hold the DataFrames\n",
    "    dfs_openface = {}\n",
    "\n",
    "    # Get a list of all the CSV files in the directory\n",
    "    csv_files = sorted([f for f in os.listdir(output_dir) if f.endswith('.csv')])\n",
    "\n",
    "    # list of columns to keep, assuming they may have variable spaces\n",
    "    columns_to_keep = ['frame', 'timestamp', 'success', 'AU01_r', 'AU02_r', 'AU04_r', 'AU05_r', 'AU06_r', 'AU07_r', \n",
    "                       'AU09_r', 'AU10_r', 'AU12_r', 'AU14_r', 'AU15_r', 'AU17_r', 'AU20_r', 'AU23_r', 'AU25_r', 'AU26_r', \n",
    "                       'AU45_r', 'AU01_c', 'AU02_c', 'AU04_c', 'AU05_c', 'AU06_c', 'AU07_c', 'AU09_c', 'AU10_c', 'AU12_c', \n",
    "                       'AU14_c', 'AU15_c', 'AU17_c', 'AU20_c', 'AU23_c', 'AU25_c', 'AU26_c', 'AU45_c']\n",
    "\n",
    "    # Loop through the CSV files\n",
    "    for csv_file in csv_files:\n",
    "        # Load data into a pandas DataFrame\n",
    "        csv_file_path = os.path.join(output_dir, csv_file)\n",
    "        df_temp = pd.read_csv(csv_file_path)\n",
    "\n",
    "        # Fix column names to not have leading or trailing spaces\n",
    "        df_temp.columns = df_temp.columns.str.strip()\n",
    "\n",
    "        # Keep every 6th row such that it's 5 fps!\n",
    "        X = 6\n",
    "        df_temp = df_temp[df_temp.index % X == 0]\n",
    "\n",
    "        # Filter DataFrame to keep only columns in list, now that names are stripped\n",
    "        df_temp = df_temp.loc[:, [col for col in columns_to_keep if col in df_temp.columns]]\n",
    "\n",
    "        # Store the DataFrame in the dictionary with the csv file name as the key\n",
    "        # remove the '.csv' by doing csv_file[:-4]\n",
    "        dfs_openface[csv_file[:-4]] = df_temp\n",
    "        del df_temp\n",
    "\n",
    "    return dfs_openface\n",
    "\n",
    "\n",
    "def only_successful_frames(df):\n",
    "    # get frames where AU/emotion detection was successful!\n",
    "    return df[df['success'] == 1]\n",
    "\n",
    "def apply_function_to_dict(dictionary, func, **kwargs):\n",
    "    \"\"\"\n",
    "    Apply a function to each DataFrame in a dictionary and return a modified copy of the dictionary.\n",
    "\n",
    "    Args:\n",
    "        dictionary (dict): The dictionary containing DataFrames.\n",
    "        func (function): The function to apply to each DataFrame.\n",
    "        **kwargs: Additional keyword arguments to pass to the function.\n",
    "\n",
    "    Returns:\n",
    "        dict: A modified copy of the dictionary with the function applied to each DataFrame.\n",
    "    \"\"\"\n",
    "    return {key: func(df, **kwargs) for key, df in dictionary.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eTOXk7be8YSH"
   },
   "outputs": [],
   "source": [
    "dfs_openface = get_dict_openface(OPENFACE_OUTPUT_DIRECTORY)\n",
    "dfs_openface = apply_function_to_dict(dfs_openface, only_successful_frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wkiuU4NVeACU"
   },
   "outputs": [],
   "source": [
    "# SAVE THE OPENFACE DICTIONARY\n",
    "\n",
    "save_var(dfs_openface, forced_name=f'dfs_openface_{PAT_SHORT_NAME}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Py2RgmTAekZS"
   },
   "outputs": [],
   "source": [
    "# # LOAD THE OPENFACE DICTIONARY\n",
    "\n",
    "# dfs_openface = load_var(f'dfs_openface_{PAT_SHORT_NAME}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "t52_30WQzYeh"
   },
   "source": [
    "# HSEmotion & OpenGraphAU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aUg5iqkRtIJX"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "def get_dict(output_dir, file_now='outputs_hse.csv', filterOutLR=True):\n",
    "\n",
    "  # Initialize an empty dictionary to store the dataframes\n",
    "  df_dict = {}\n",
    "\n",
    "  # Loop through the subfolders in alphabetical order\n",
    "  for subfolder_name in sorted(os.listdir(output_dir)):\n",
    "\n",
    "    # Check if the subfolder contains CSV files\n",
    "    subfolder_path = os.path.join(output_dir, subfolder_name)\n",
    "    if not os.path.isdir(subfolder_path):\n",
    "      continue\n",
    "\n",
    "    # Load the first CSV file in the subfolder into a dataframe\n",
    "    csv_file_path = os.path.join(subfolder_path, file_now)\n",
    "    if not os.path.isfile(csv_file_path):\n",
    "      continue\n",
    "\n",
    "    try:\n",
    "      df_temp = pd.read_csv(csv_file_path)\n",
    "    except:\n",
    "      df_temp = pd.DataFrame(columns=['frame', 'timestamp', 'success', 'AU1', 'AU2', 'AU4', 'AU5', 'AU6', 'AU7', 'AU9',\n",
    "       'AU10', 'AU11', 'AU12', 'AU13', 'AU14', 'AU15', 'AU16', 'AU17', 'AU18',\n",
    "       'AU19', 'AU20', 'AU22', 'AU23', 'AU24', 'AU25', 'AU26', 'AU27', 'AU32',\n",
    "       'AU38', 'AU39'])\n",
    "\n",
    "\n",
    "    # OpenGraphAU - we are filtering out L and R!\n",
    "    if filterOutLR:\n",
    "      df_temp = df_temp.filter(regex='^(?!AUL|AUR)')\n",
    "\n",
    "    # Add the dataframe to the dictionary with the subfolder name as the key\n",
    "    # We do [:-4] to remove '.mp4' from the end of the string\n",
    "    df_dict[subfolder_name[:-4]] = df_temp\n",
    "\n",
    "  return df_dict\n",
    "\n",
    "def create_binary_columns(df, threshold):\n",
    "    df_copy = df.copy()\n",
    "    # adds classification columns to opengraphAU\n",
    "    for col in df_copy.columns:\n",
    "        if col.startswith('AU'):\n",
    "            # Add _c to the column name for the new column\n",
    "            new_col_name = col + '_c'\n",
    "            # Apply the binary classification to the new column\n",
    "            df_copy[new_col_name] = df_copy[col].apply(lambda x: 1 if x >= threshold else 0)\n",
    "            # Add _r to the original column name\n",
    "            df_copy = df_copy.rename(columns={col: col + '_r'}, inplace=False)\n",
    "    return df_copy\n",
    "\n",
    "def remove_columns_ending_with_r(df):\n",
    "    columns_to_drop = [col for col in df.columns if col.endswith('_r')]\n",
    "    df = df.drop(columns=columns_to_drop, inplace=False)\n",
    "    return df\n",
    "\n",
    "\n",
    "def only_successful_frames(df):\n",
    "    # get frames where AU/emotion detection was successful!\n",
    "    return df[df['success'] == 1]\n",
    "\n",
    "\n",
    "def apply_function_to_dict(dictionary, func, **kwargs):\n",
    "    \"\"\"\n",
    "    Apply a function to each DataFrame in a dictionary and return a modified copy of the dictionary.\n",
    "\n",
    "    Args:\n",
    "        dictionary (dict): The dictionary containing DataFrames.\n",
    "        func (function): The function to apply to each DataFrame.\n",
    "        **kwargs: Additional keyword arguments to pass to the function.\n",
    "\n",
    "    Returns:\n",
    "        dict: A modified copy of the dictionary with the function applied to each DataFrame.\n",
    "    \"\"\"\n",
    "    return {key: func(df, **kwargs) for key, df in dictionary.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mEea0RmkACqS"
   },
   "outputs": [],
   "source": [
    "dfs_hsemotion = get_dict(COMBINED_OUTPUT_DIRECTORY, file_now='outputs_hse.csv')\n",
    "dfs_hsemotion = apply_function_to_dict(dfs_hsemotion, only_successful_frames)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "atk8wPgaEnPs"
   },
   "source": [
    "## Smile, Yawn, Etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vMHW6u8fEpCj"
   },
   "outputs": [],
   "source": [
    "dfs_opengraphau = get_dict(COMBINED_OUTPUT_DIRECTORY, file_now='outputs_ogau.csv')\n",
    "dfs_opengraphau = apply_function_to_dict(dfs_opengraphau, only_successful_frames)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YttjHCDnevzg"
   },
   "outputs": [],
   "source": [
    "# SAVE DF HSEMOTION\n",
    "save_var(dfs_hsemotion, forced_name=f'dfs_hsemotion_{PAT_SHORT_NAME}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CnW9mKJ8FLsE"
   },
   "outputs": [],
   "source": [
    "# SAVE DF OPENGRAPHAU WITHOUT ANY THRESHOLDING\n",
    "save_var(dfs_opengraphau, forced_name=f'dfs_opengraphau_smile_{PAT_SHORT_NAME}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qleLVP1hGXur"
   },
   "outputs": [],
   "source": [
    "# # LOAD VARS FOR BEHAVIOR PREDICTION\n",
    "# # NO THRESHOLDING FOR DF OPENGRAPHAU\n",
    "\n",
    "# dfs_hsemotion = load_var(f'dfs_hsemotion_{PAT_SHORT_NAME}')\n",
    "\n",
    "# dfs_opengraphau = load_var(f'dfs_opengraphau_smile_{PAT_SHORT_NAME}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pjDp31PcyrBD"
   },
   "source": [
    "# Select Specific Times"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7rrCWvN5Kmjr"
   },
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rgRoAaIsyuFY"
   },
   "outputs": [],
   "source": [
    "def get_data_within_duration(dfs_dict, df_video_timestamps, datetime, duration):\n",
    "    # Takes in:\n",
    "    # dfs_dict -- a dictionary of dataframes containing csv data from one of the pipelines\n",
    "    # df_video_timestamps -- the VideoDateTimes_199 csv\n",
    "    # datetime -- a pd.datetime value to center our extraction\n",
    "    # duration -- a duration (in minutes) BEFORE the datetime to extract\n",
    "\n",
    "    # Outputs:\n",
    "    # One dataframe with all rows we want, with timestamps converted into correct datetimes\n",
    "    start_datetime = datetime - pd.Timedelta(minutes=duration)\n",
    "    end_datetime = datetime\n",
    "\n",
    "    relevant_keys = df_video_timestamps.loc[(pd.to_datetime(df_video_timestamps['VideoEnd']) >= start_datetime) &\n",
    "                                            (pd.to_datetime(df_video_timestamps['VideoStart']) <= end_datetime), 'Filename'].values\n",
    "\n",
    "    relevant_dfs = []\n",
    "    for key in relevant_keys:\n",
    "        if key in dfs_dict:\n",
    "            video_start = pd.to_datetime(df_video_timestamps.loc[df_video_timestamps['Filename'] == key, 'VideoStart'].values[0])\n",
    "            video_end = pd.to_datetime(df_video_timestamps.loc[df_video_timestamps['Filename'] == key, 'VideoEnd'].values[0])\n",
    "            time_mask = ((dfs_dict[key]['timestamp'] >= (start_datetime - video_start).total_seconds()) &\n",
    "                         (dfs_dict[key]['timestamp'] <= (end_datetime - video_start).total_seconds()))\n",
    "            df = dfs_dict[key].loc[time_mask].copy()\n",
    "            df['timestamp'] = video_start + pd.to_timedelta(df['timestamp'], unit='s')\n",
    "            relevant_dfs.append(df)\n",
    "\n",
    "    if relevant_dfs:\n",
    "        df_combined = pd.concat(relevant_dfs, ignore_index=True, sort=False)\n",
    "        df_combined = df_combined.drop(columns='frame')\n",
    "\n",
    "        return df_combined\n",
    "\n",
    "    print(f\"MAJOR ERROR! ZERO RELEVANT DFS!! DATETIME: {datetime}\")\n",
    "    return pd.DataFrame()\n",
    "\n",
    "def get_radius_dict(TIME_RADIUS_IN_MINUTES, INPUT_DF, df_videoTimestamps, df_moodTracking, takeAll=True):\n",
    "  # takes in the:\n",
    "  # --time radius,\n",
    "  # --input dataframe dict (e.g. is it from OpenFace? HSEmotion?)\n",
    "  # --df with video timestamps\n",
    "  # --df with mood tracking patient reports\n",
    "  # --takeAll - are we taking all reports, or filtering out values w/o mood (e.g. anxiety)? True = no filtering\n",
    "\n",
    "  # returns dictionary of timestamp : df with relevant frames\n",
    "\n",
    "  # We'll make a dictionary, with the relevant df for each datetime we have a report\n",
    "  radius_df_dict = {}\n",
    "  for oneIndex in range(len(df_moodTracking)):\n",
    "    # Let's make sure there's a value collected (or takeAll = True)!\n",
    "    if takeAll:\n",
    "      dt_now = get_moodTracking_datetime(oneIndex, df_moodTracking=df_moodTracking)\n",
    "      filtered_df = get_data_within_duration(INPUT_DF, df_videoTimestamps, dt_now, TIME_RADIUS_IN_MINUTES)\n",
    "      radius_df_dict[dt_now] = filtered_df\n",
    "    else:\n",
    "      val_now = df_moodTracking[oneIndex:oneIndex+1]['Anxiety'][oneIndex]\n",
    "      if isinstance(val_now, str):\n",
    "        # Value was collected\n",
    "        dt_now = get_moodTracking_datetime(oneIndex, df_moodTracking=df_moodTracking)\n",
    "        filtered_df = get_data_within_duration(INPUT_DF, df_videoTimestamps, dt_now, TIME_RADIUS_IN_MINUTES)\n",
    "        radius_df_dict[dt_now] = filtered_df\n",
    "      else:\n",
    "        # No value collected!\n",
    "        print('No value for Anxiety for index ', oneIndex, f'corresponding to {get_moodTracking_datetime(oneIndex, df_moodTracking=df_moodTracking)}')\n",
    "  return radius_df_dict\n",
    "\n",
    "def generate_number_list(start, interval, count):\n",
    "    number_list = [start + i * interval for i in range(count)]\n",
    "    return number_list\n",
    "\n",
    "def get_moodTracking_datetime(index, df_moodTracking):\n",
    "  temp_var = pd.to_datetime(pd.to_datetime(df_moodTracking[index:index+1]['Datetime']).dt.strftime('%d-%b-%Y %H:%M:%S'))\n",
    "  return pd.Timestamp(temp_var[index])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9DIJGifEdj0g"
   },
   "source": [
    "# LogReg Mapping (Smile, Yawn, etc.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1cLXNBE-dm6y"
   },
   "source": [
    "## Prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "u2kPJFEadoy2"
   },
   "outputs": [],
   "source": [
    "def only_successful_frames(df):\n",
    "    # get frames where AU/emotion detection was successful!\n",
    "    return df[df['success'] == 1]\n",
    "\n",
    "\n",
    "def clean_data(pipeline_emotion, labels):\n",
    "    # Convert the Datetime column to datetime objects for comparison\n",
    "    labels['Datetime'] = pd.to_datetime(labels['Datetime'])\n",
    "\n",
    "    # Create a list to store keys to be removed\n",
    "    keys_to_remove = []\n",
    "\n",
    "    # Iterate through the pipeline_emotion dictionary\n",
    "    for key, df in pipeline_emotion.items():\n",
    "        # Check if the dataframe is empty\n",
    "        if df.empty:\n",
    "            # Add the key to keys_to_remove list\n",
    "            keys_to_remove.append(key)\n",
    "\n",
    "    # Remove empty dataframes from pipeline_emotion\n",
    "    for key in keys_to_remove:\n",
    "        del pipeline_emotion[key]\n",
    "\n",
    "    # Remove the relevant rows from labels\n",
    "    labels = labels[~labels['Datetime'].isin(keys_to_remove)]\n",
    "\n",
    "    return pipeline_emotion, labels\n",
    "\n",
    "def preprocess_df_radius_dict(df_radius_dict, labels_now, columns_to_keep):\n",
    "  # Takes only successful frames\n",
    "  # Chooses specific columns from each df to keep\n",
    "\n",
    "  df_radius_dict_clean, labels_now_clean = clean_data(df_radius_dict, labels_now)\n",
    "\n",
    "  new_radius_dict = {}\n",
    "  for key1, one_time_df in df_radius_dict_clean.items():\n",
    "    success_df = only_successful_frames(one_time_df)\n",
    "    new_radius_dict[key1] = success_df.loc[:, columns_to_keep]\n",
    "\n",
    "  return new_radius_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DshcJyDzeOyh"
   },
   "outputs": [],
   "source": [
    "def shuffle_labels(df):\n",
    "    \"\"\"\n",
    "    Takes in a DataFrame, makes a copy of it, and randomly shuffles the 'EventDetected' labels.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): DataFrame containing 'EventDetected' column.\n",
    "\n",
    "    Returns:\n",
    "        shuffled_df (pd.DataFrame): A copy of the original DataFrame with shuffled 'EventDetected' column.\n",
    "    \"\"\"\n",
    "    if df.empty:\n",
    "        return df\n",
    "    shuffled_df = df.copy()\n",
    "    shuffled_df['EventDetected'] = df['EventDetected'].sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "    return shuffled_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "n21wY8yleV0c"
   },
   "outputs": [],
   "source": [
    "Shuffled_Smile_Labels = shuffle_labels(Final_Smile_Labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rrFnSQyzK-I8"
   },
   "outputs": [],
   "source": [
    "Shuffled_Yawn_Labels = shuffle_labels(Final_Yawn_Labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tOCDiE9Yfdi4"
   },
   "outputs": [],
   "source": [
    "Shuffled_Discomfort_Labels = shuffle_labels(Final_Discomfort_Labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9xskTc2qOR7z"
   },
   "outputs": [],
   "source": [
    "Shuffled_Sad_Labels = shuffle_labels(Final_Sad_Labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Behaviors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SHORT EVENT DETECTION (SMILE, ETC.)\n",
    "takeAll = True # we are taking all patient reports\n",
    "\n",
    "# start and interval are in minutes\n",
    "# example: 0.01666 is 1 second\n",
    "TIME_RADIUS_LIST = [0.01666] # JUST one second\n",
    "\n",
    "openface_radius_dict = {}\n",
    "hsemotion_radius_dict = {}\n",
    "opengraphau_radius_dict = {}\n",
    "\n",
    "DANNY_LABELS_NOW = Final_Smile_Labels\n",
    "\n",
    "if not(DANNY_LABELS_NOW.empty):\n",
    "    \n",
    "    for i in TIME_RADIUS_LIST:\n",
    "      openface_radius_now = get_radius_dict(i, dfs_openface, df_videoTimestamps, DANNY_LABELS_NOW, takeAll=takeAll)\n",
    "      hsemotion_radius_now = get_radius_dict(i, dfs_hsemotion, df_videoTimestamps, DANNY_LABELS_NOW, takeAll=takeAll)\n",
    "      opengraphau_radius_now = get_radius_dict(i, dfs_opengraphau, df_videoTimestamps, DANNY_LABELS_NOW, takeAll=takeAll)\n",
    "    \n",
    "      openface_radius_dict[f'{i}'] = openface_radius_now\n",
    "      hsemotion_radius_dict[f'{i}'] = hsemotion_radius_now\n",
    "      opengraphau_radius_dict[f'{i}'] = opengraphau_radius_now\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SAVE VARIABLES - Smile\n",
    "if not(DANNY_LABELS_NOW.empty):\n",
    "    save_var(openface_radius_dict, forced_name=f'openface_radius_dict_smile_1_{PAT_SHORT_NAME}')\n",
    "    \n",
    "    save_var(hsemotion_radius_dict, forced_name=f'hsemotion_radius_dict_smile_1_{PAT_SHORT_NAME}')\n",
    "    \n",
    "    save_var(opengraphau_radius_dict, forced_name=f'opengraphau_radius_dict_smile_1_{PAT_SHORT_NAME}')\n",
    "    \n",
    "    save_var(Final_Smile_Labels, forced_name=f'Final_Smile_Labels_{PAT_SHORT_NAME}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "989qK4Oqdo1h"
   },
   "outputs": [],
   "source": [
    "if not(DANNY_LABELS_NOW.empty):\n",
    "    openface_radius_dict = openface_radius_dict['0.01666']\n",
    "    hsemotion_radius_dict = hsemotion_radius_dict['0.01666']\n",
    "    opengraphau_radius_dict = opengraphau_radius_dict['0.01666']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dVjZKc7udrhi"
   },
   "outputs": [],
   "source": [
    "if not(DANNY_LABELS_NOW.empty):\n",
    "        \n",
    "    # SMILE\n",
    "    openface_smile = preprocess_df_radius_dict(openface_radius_dict, Final_Smile_Labels,\n",
    "                                                    ['AU01_r', 'AU02_r', 'AU04_r', 'AU05_r',\n",
    "           'AU06_r', 'AU07_r', 'AU09_r', 'AU10_r', 'AU12_r', 'AU14_r', 'AU15_r',\n",
    "           'AU17_r', 'AU20_r', 'AU23_r', 'AU25_r', 'AU26_r', 'AU45_r', 'AU01_c',\n",
    "           'AU02_c', 'AU04_c', 'AU05_c', 'AU06_c', 'AU07_c', 'AU09_c', 'AU10_c',\n",
    "           'AU12_c', 'AU14_c', 'AU15_c', 'AU17_c', 'AU20_c', 'AU23_c', 'AU25_c',\n",
    "           'AU26_c', 'AU45_c'])\n",
    "    \n",
    "    opengraphau_smile = preprocess_df_radius_dict(opengraphau_radius_dict, Final_Smile_Labels,\n",
    "                                                       ['AU1', 'AU2', 'AU4', 'AU5', 'AU6', 'AU7', 'AU9',\n",
    "           'AU10', 'AU11', 'AU12', 'AU13', 'AU14', 'AU15', 'AU16', 'AU17', 'AU18',\n",
    "           'AU19', 'AU20', 'AU22', 'AU23', 'AU24', 'AU25', 'AU26', 'AU27', 'AU32',\n",
    "           'AU38', 'AU39'])\n",
    "    \n",
    "    hsemotion_smile = preprocess_df_radius_dict(hsemotion_radius_dict, Final_Smile_Labels,\n",
    "                                                     ['Happiness'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SHORT EVENT DETECTION (SMILE, ETC.)\n",
    "takeAll = True # we are taking all patient reports\n",
    "\n",
    "# start and interval are in minutes\n",
    "# example: 0.01666 is 1 second\n",
    "TIME_RADIUS_LIST = [0.01666] # JUST one second\n",
    "\n",
    "openface_radius_dict = {}\n",
    "hsemotion_radius_dict = {}\n",
    "opengraphau_radius_dict = {}\n",
    "\n",
    "DANNY_LABELS_NOW = Final_Yawn_Labels\n",
    "\n",
    "if not(DANNY_LABELS_NOW.empty):\n",
    "    for i in TIME_RADIUS_LIST:\n",
    "      openface_radius_now = get_radius_dict(i, dfs_openface, df_videoTimestamps, DANNY_LABELS_NOW, takeAll=takeAll)\n",
    "      hsemotion_radius_now = get_radius_dict(i, dfs_hsemotion, df_videoTimestamps, DANNY_LABELS_NOW, takeAll=takeAll)\n",
    "      opengraphau_radius_now = get_radius_dict(i, dfs_opengraphau, df_videoTimestamps, DANNY_LABELS_NOW, takeAll=takeAll)\n",
    "    \n",
    "      openface_radius_dict[f'{i}'] = openface_radius_now\n",
    "      hsemotion_radius_dict[f'{i}'] = hsemotion_radius_now\n",
    "      opengraphau_radius_dict[f'{i}'] = opengraphau_radius_now\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not(DANNY_LABELS_NOW.empty):\n",
    "        \n",
    "    # SAVE VARIABLES - Yawn\n",
    "    \n",
    "    save_var(openface_radius_dict, forced_name=f'openface_radius_dict_yawn_1_{PAT_SHORT_NAME}')\n",
    "    \n",
    "    save_var(hsemotion_radius_dict, forced_name=f'hsemotion_radius_dict_yawn_1_{PAT_SHORT_NAME}')\n",
    "    \n",
    "    save_var(opengraphau_radius_dict, forced_name=f'opengraphau_radius_dict_yawn_1_{PAT_SHORT_NAME}')\n",
    "    \n",
    "    save_var(Final_Yawn_Labels, forced_name=f'Final_Yawn_Labels_{PAT_SHORT_NAME}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not(DANNY_LABELS_NOW.empty):\n",
    "    \n",
    "    openface_radius_dict = openface_radius_dict['0.01666']\n",
    "    hsemotion_radius_dict = hsemotion_radius_dict['0.01666']\n",
    "    opengraphau_radius_dict = opengraphau_radius_dict['0.01666']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-nwYcRh4K1Kq"
   },
   "outputs": [],
   "source": [
    "if not(DANNY_LABELS_NOW.empty):\n",
    "        \n",
    "    # YAWN\n",
    "    openface_yawn = preprocess_df_radius_dict(openface_radius_dict, Final_Yawn_Labels,\n",
    "                                                    ['AU01_r', 'AU02_r', 'AU04_r', 'AU05_r',\n",
    "           'AU06_r', 'AU07_r', 'AU09_r', 'AU10_r', 'AU12_r', 'AU14_r', 'AU15_r',\n",
    "           'AU17_r', 'AU20_r', 'AU23_r', 'AU25_r', 'AU26_r', 'AU45_r', 'AU01_c',\n",
    "           'AU02_c', 'AU04_c', 'AU05_c', 'AU06_c', 'AU07_c', 'AU09_c', 'AU10_c',\n",
    "           'AU12_c', 'AU14_c', 'AU15_c', 'AU17_c', 'AU20_c', 'AU23_c', 'AU25_c',\n",
    "           'AU26_c', 'AU45_c'])\n",
    "    \n",
    "    opengraphau_yawn = preprocess_df_radius_dict(opengraphau_radius_dict, Final_Yawn_Labels,\n",
    "                                                       ['AU1', 'AU2', 'AU4', 'AU5', 'AU6', 'AU7', 'AU9',\n",
    "           'AU10', 'AU11', 'AU12', 'AU13', 'AU14', 'AU15', 'AU16', 'AU17', 'AU18',\n",
    "           'AU19', 'AU20', 'AU22', 'AU23', 'AU24', 'AU25', 'AU26', 'AU27', 'AU32',\n",
    "           'AU38', 'AU39'])\n",
    "    \n",
    "    hsemotion_yawn = preprocess_df_radius_dict(hsemotion_radius_dict, Final_Yawn_Labels,\n",
    "                                                     ['Anger', 'Disgust', 'Fear', 'Happiness',\n",
    "           'Neutral', 'Sadness', 'Surprise'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SHORT EVENT DETECTION (SMILE, ETC.)\n",
    "takeAll = True # we are taking all patient reports\n",
    "\n",
    "# start and interval are in minutes\n",
    "# example: 0.01666 is 1 second\n",
    "TIME_RADIUS_LIST = [0.01666] # JUST one second\n",
    "\n",
    "openface_radius_dict = {}\n",
    "hsemotion_radius_dict = {}\n",
    "opengraphau_radius_dict = {}\n",
    "\n",
    "DANNY_LABELS_NOW = Final_Discomfort_Labels\n",
    "\n",
    "if not(DANNY_LABELS_NOW.empty):\n",
    "    for i in TIME_RADIUS_LIST:\n",
    "      openface_radius_now = get_radius_dict(i, dfs_openface, df_videoTimestamps, DANNY_LABELS_NOW, takeAll=takeAll)\n",
    "      hsemotion_radius_now = get_radius_dict(i, dfs_hsemotion, df_videoTimestamps, DANNY_LABELS_NOW, takeAll=takeAll)\n",
    "      opengraphau_radius_now = get_radius_dict(i, dfs_opengraphau, df_videoTimestamps, DANNY_LABELS_NOW, takeAll=takeAll)\n",
    "    \n",
    "      openface_radius_dict[f'{i}'] = openface_radius_now\n",
    "      hsemotion_radius_dict[f'{i}'] = hsemotion_radius_now\n",
    "      opengraphau_radius_dict[f'{i}'] = opengraphau_radius_now\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not(DANNY_LABELS_NOW.empty):\n",
    "        \n",
    "    # SAVE VARIABLES - Discomfort\n",
    "    \n",
    "    save_var(openface_radius_dict, forced_name=f'openface_radius_dict_discomfort_1_{PAT_SHORT_NAME}')\n",
    "    \n",
    "    save_var(hsemotion_radius_dict, forced_name=f'hsemotion_radius_dict_discomfort_1_{PAT_SHORT_NAME}')\n",
    "    \n",
    "    save_var(opengraphau_radius_dict, forced_name=f'opengraphau_radius_dict_discomfort_1_{PAT_SHORT_NAME}')\n",
    "    \n",
    "    save_var(Final_Discomfort_Labels, forced_name=f'Final_Discomfort_Labels_{PAT_SHORT_NAME}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not(DANNY_LABELS_NOW.empty):\n",
    "    \n",
    "    openface_radius_dict = openface_radius_dict['0.01666']\n",
    "    hsemotion_radius_dict = hsemotion_radius_dict['0.01666']\n",
    "    opengraphau_radius_dict = opengraphau_radius_dict['0.01666']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oei3peGcBJII"
   },
   "outputs": [],
   "source": [
    "if not(DANNY_LABELS_NOW.empty):\n",
    "        \n",
    "    # DISCOMFORT\n",
    "    openface_discomfort = preprocess_df_radius_dict(openface_radius_dict, Final_Discomfort_Labels,\n",
    "                                                    ['AU01_r', 'AU02_r', 'AU04_r', 'AU05_r',\n",
    "           'AU06_r', 'AU07_r', 'AU09_r', 'AU10_r', 'AU12_r', 'AU14_r', 'AU15_r',\n",
    "           'AU17_r', 'AU20_r', 'AU23_r', 'AU25_r', 'AU26_r', 'AU45_r', 'AU01_c',\n",
    "           'AU02_c', 'AU04_c', 'AU05_c', 'AU06_c', 'AU07_c', 'AU09_c', 'AU10_c',\n",
    "           'AU12_c', 'AU14_c', 'AU15_c', 'AU17_c', 'AU20_c', 'AU23_c', 'AU25_c',\n",
    "           'AU26_c', 'AU45_c'])\n",
    "    opengraphau_discomfort = preprocess_df_radius_dict(opengraphau_radius_dict, Final_Discomfort_Labels,\n",
    "                                                       ['AU1', 'AU2', 'AU4', 'AU5', 'AU6', 'AU7', 'AU9',\n",
    "           'AU10', 'AU11', 'AU12', 'AU13', 'AU14', 'AU15', 'AU16', 'AU17', 'AU18',\n",
    "           'AU19', 'AU20', 'AU22', 'AU23', 'AU24', 'AU25', 'AU26', 'AU27', 'AU32',\n",
    "           'AU38', 'AU39'])\n",
    "    hsemotion_discomfort = preprocess_df_radius_dict(hsemotion_radius_dict, Final_Discomfort_Labels,\n",
    "                                                     ['Anger', 'Disgust', 'Fear', 'Happiness',\n",
    "           'Neutral', 'Sadness', 'Surprise'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SHORT EVENT DETECTION (SMILE, ETC.)\n",
    "takeAll = True # we are taking all patient reports\n",
    "\n",
    "# start and interval are in minutes\n",
    "# example: 0.01666 is 1 second\n",
    "TIME_RADIUS_LIST = [0.01666] # JUST one second\n",
    "\n",
    "openface_radius_dict = {}\n",
    "hsemotion_radius_dict = {}\n",
    "opengraphau_radius_dict = {}\n",
    "\n",
    "DANNY_LABELS_NOW = Final_Sad_Labels\n",
    "\n",
    "if not(DANNY_LABELS_NOW.empty):\n",
    "    \n",
    "    for i in TIME_RADIUS_LIST:\n",
    "      openface_radius_now = get_radius_dict(i, dfs_openface, df_videoTimestamps, DANNY_LABELS_NOW, takeAll=takeAll)\n",
    "      hsemotion_radius_now = get_radius_dict(i, dfs_hsemotion, df_videoTimestamps, DANNY_LABELS_NOW, takeAll=takeAll)\n",
    "      opengraphau_radius_now = get_radius_dict(i, dfs_opengraphau, df_videoTimestamps, DANNY_LABELS_NOW, takeAll=takeAll)\n",
    "    \n",
    "      openface_radius_dict[f'{i}'] = openface_radius_now\n",
    "      hsemotion_radius_dict[f'{i}'] = hsemotion_radius_now\n",
    "      opengraphau_radius_dict[f'{i}'] = opengraphau_radius_now\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not(DANNY_LABELS_NOW.empty):\n",
    "    \n",
    "    # SAVE VARIABLES - Sad\n",
    "    \n",
    "    save_var(openface_radius_dict, forced_name=f'openface_radius_dict_sad_1_{PAT_SHORT_NAME}')\n",
    "    \n",
    "    save_var(hsemotion_radius_dict, forced_name=f'hsemotion_radius_dict_sad_1_{PAT_SHORT_NAME}')\n",
    "    \n",
    "    save_var(opengraphau_radius_dict, forced_name=f'opengraphau_radius_dict_sad_1_{PAT_SHORT_NAME}')\n",
    "    \n",
    "    save_var(Final_Sad_Labels, forced_name=f'Final_Sad_Labels_{PAT_SHORT_NAME}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not(DANNY_LABELS_NOW.empty):\n",
    "    openface_radius_dict = openface_radius_dict['0.01666']\n",
    "    hsemotion_radius_dict = hsemotion_radius_dict['0.01666']\n",
    "    opengraphau_radius_dict = opengraphau_radius_dict['0.01666']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EpILl3dlOH7h"
   },
   "outputs": [],
   "source": [
    "if not(DANNY_LABELS_NOW.empty):\n",
    "    # SAD\n",
    "    openface_sad = preprocess_df_radius_dict(openface_radius_dict, Final_Sad_Labels,\n",
    "                                                    ['AU01_r', 'AU02_r', 'AU04_r', 'AU05_r',\n",
    "           'AU06_r', 'AU07_r', 'AU09_r', 'AU10_r', 'AU12_r', 'AU14_r', 'AU15_r',\n",
    "           'AU17_r', 'AU20_r', 'AU23_r', 'AU25_r', 'AU26_r', 'AU45_r', 'AU01_c',\n",
    "           'AU02_c', 'AU04_c', 'AU05_c', 'AU06_c', 'AU07_c', 'AU09_c', 'AU10_c',\n",
    "           'AU12_c', 'AU14_c', 'AU15_c', 'AU17_c', 'AU20_c', 'AU23_c', 'AU25_c',\n",
    "           'AU26_c', 'AU45_c'])\n",
    "    opengraphau_sad = preprocess_df_radius_dict(opengraphau_radius_dict, Final_Sad_Labels,\n",
    "                                                       ['AU1', 'AU2', 'AU4', 'AU5', 'AU6', 'AU7', 'AU9',\n",
    "           'AU10', 'AU11', 'AU12', 'AU13', 'AU14', 'AU15', 'AU16', 'AU17', 'AU18',\n",
    "           'AU19', 'AU20', 'AU22', 'AU23', 'AU24', 'AU25', 'AU26', 'AU27', 'AU32',\n",
    "           'AU38', 'AU39'])\n",
    "    hsemotion_sad = preprocess_df_radius_dict(hsemotion_radius_dict, Final_Sad_Labels,\n",
    "                                                     ['Sadness'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deal with missing variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(Final_Smile_Labels) == 0:\n",
    "    openface_smile = 0\n",
    "    opengraphau_smile = 0\n",
    "    hsemotion_smile = 0\n",
    "\n",
    "if len(Final_Discomfort_Labels) == 0:\n",
    "    openface_discomfort = 0\n",
    "    opengraphau_discomfort = 0\n",
    "    hsemotion_discomfort = 0\n",
    "\n",
    "if len(Final_Yawn_Labels) == 0:\n",
    "    openface_yawn = 0\n",
    "    opengraphau_yawn = 0\n",
    "    hsemotion_yawn = 0\n",
    "\n",
    "if len(Final_Sad_Labels) == 0:\n",
    "    openface_sad = 0\n",
    "    opengraphau_sad = 0\n",
    "    hsemotion_sad = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ApAP7JQ3kCxi"
   },
   "source": [
    "## Func: Train + Eval (5-Fold CV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XEV1aNXXkC-G"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score, roc_curve, accuracy_score, f1_score, average_precision_score\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import display\n",
    "from scipy import interp\n",
    "\n",
    "\n",
    "def train_and_evaluate(smile_dict, Final_Smile_Labels, pipeline_name='OpenFace', results_path=RESULTS_PATH_BASE + 'Smile/'):\n",
    "    # If we don't have any events, can't train and eval a model!\n",
    "    if Final_Smile_Labels.empty:\n",
    "        return pd.DataFrame(), 0, 0\n",
    "    \n",
    "    # Averaging values across rows for each DataFrame in smile_dict\n",
    "    averaged_values = {timestamp: df.mean() for timestamp, df in smile_dict.items()}\n",
    "\n",
    "    # Convert the dictionary to a DataFrame\n",
    "    averaged_df = pd.DataFrame.from_dict(averaged_values, orient='index', columns=smile_dict[next(iter(smile_dict))].columns)\n",
    "\n",
    "    # Merge with Final_Smile_Labels\n",
    "    merged_df = pd.merge(Final_Smile_Labels, averaged_df, left_on='Datetime', right_index=True)\n",
    "\n",
    "    merged_df.fillna(0, inplace=True)\n",
    "\n",
    "    # Split features and labels\n",
    "    X = merged_df.drop(['Datetime', 'EventDetected'], axis=1)\n",
    "    y = merged_df['EventDetected']\n",
    "    y = y.astype('int')\n",
    "\n",
    "    if len(np.unique(y)) < 2:\n",
    "        return pd.DataFrame(), 0, 0 \n",
    "\n",
    "    # Initialize StratifiedKFold and LogisticRegression\n",
    "    NUMBER_OF_FOLDS = 5\n",
    "    skf = StratifiedKFold(n_splits=NUMBER_OF_FOLDS, shuffle=True, random_state=42)\n",
    "    log_reg = LogisticRegression()\n",
    "\n",
    "    # Lists to hold metrics and ROC curve values across folds\n",
    "    auroc_list, accuracy_list, f1_list, auprc_list = [], [], [], []\n",
    "    mean_fpr = np.linspace(0, 1, 100)  # Common grid of FPR values for averaging the ROC curves\n",
    "    tprs = []  # List to hold the TPR values for each fold\n",
    "\n",
    "    for train_index, test_index in skf.split(X, y):\n",
    "        X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "        y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "\n",
    "        log_reg.fit(X_train, y_train)\n",
    "        y_pred = log_reg.predict(X_test)\n",
    "        y_proba = log_reg.predict_proba(X_test)[:, 1]\n",
    "\n",
    "        # Metrics computation\n",
    "        auroc_list.append(roc_auc_score(y_test, y_proba))\n",
    "        accuracy_list.append(accuracy_score(y_test, y_pred))\n",
    "        f1_list.append(f1_score(y_test, y_pred))\n",
    "        auprc_list.append(average_precision_score(y_test, y_proba))\n",
    "\n",
    "        # ROC Curve values for the current fold\n",
    "        fpr, tpr, _ = roc_curve(y_test, y_proba)\n",
    "        tprs.append(interp(mean_fpr, fpr, tpr))  # Interpolate the TPR values to the common grid of FPR values\n",
    "\n",
    "\n",
    "    # Compute the mean TPR values at each FPR to get the \"averaged\" ROC curve\n",
    "    mean_tpr = np.mean(tprs, axis=0)\n",
    "\n",
    "    # Plotting the curves\n",
    "    for tpr in tprs:\n",
    "      plt.plot(mean_fpr, tpr, color='b', alpha=0.1)  # Plot each fold's ROC curve with a light color\n",
    "    plt.plot(mean_fpr, mean_tpr, color='b', linewidth=2)  # Plot the \"averaged\" ROC curve in bold\n",
    "    plt.title(f'{pipeline_name} 5-Fold CV LogReg')\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "\n",
    "    # Save the figure to a file\n",
    "    os.makedirs(results_path, exist_ok=True)\n",
    "    output_file_path = os.path.join(results_path, f'{pipeline_name} roc_curve.png')\n",
    "    plt.savefig(output_file_path)\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "    # Reporting metrics\n",
    "    metrics_df = pd.DataFrame({\n",
    "        'Fold': list(range(1, NUMBER_OF_FOLDS + 1)) + ['Average'],\n",
    "        'Accuracy': accuracy_list + [np.mean(accuracy_list)],\n",
    "        'F1 Score': f1_list + [np.mean(f1_list)],\n",
    "        'AUPRC': auprc_list + [np.mean(auprc_list)],\n",
    "        'AUROC': auroc_list + [np.mean(auroc_list)]\n",
    "    })\n",
    "\n",
    "    # Specify the path for the CSV file\n",
    "    csv_file_path = os.path.join(results_path, f'{pipeline_name} metrics.csv')\n",
    "\n",
    "    # Save the DataFrame to a CSV file\n",
    "    metrics_df.to_csv(csv_file_path, index=False)\n",
    "\n",
    "\n",
    "    return metrics_df, mean_fpr, mean_tpr\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zmVhXeUbneQd"
   },
   "source": [
    "## Smile Results: Train + Eval (5-Fold CV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vNO88rbBkGTW"
   },
   "outputs": [],
   "source": [
    "of_metrics_df, of_mean_fpr, of_mean_tpr = train_and_evaluate(openface_smile, Final_Smile_Labels, pipeline_name='OpenFace', results_path=RESULTS_PATH_BASE + 'Smile/')\n",
    "print('OPENFACE: ')\n",
    "display(of_metrics_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JuiVMXa4kItE"
   },
   "outputs": [],
   "source": [
    "ogau_metrics_df, ogau_mean_fpr, ogau_mean_tpr = train_and_evaluate(opengraphau_smile, Final_Smile_Labels, pipeline_name='OpenGraphAU', results_path=RESULTS_PATH_BASE + 'Smile/')\n",
    "print('OPENGRAPHAU: ')\n",
    "display(ogau_metrics_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EE2ULS8NmhY_"
   },
   "outputs": [],
   "source": [
    "hse_metrics_df, hse_mean_fpr, hse_mean_tpr = train_and_evaluate(hsemotion_smile, Final_Smile_Labels, pipeline_name='HSEmotion', results_path=RESULTS_PATH_BASE + 'Smile/')\n",
    "print('HSEMOTION: ')\n",
    "display(hse_metrics_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fxrnpeIEvAcL"
   },
   "source": [
    "## Smile Checking shuffled labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zCoJoNXrvESx"
   },
   "outputs": [],
   "source": [
    "s_of_metrics_df, s_of_mean_fpr, s_of_mean_tpr = train_and_evaluate(openface_smile, Shuffled_Smile_Labels, pipeline_name='Shuffled OpenFace', results_path=RESULTS_PATH_BASE + 'Smile/')\n",
    "print('OPENFACE SHUFFLED: ')\n",
    "display(s_of_metrics_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zgvBDcjQvEYE"
   },
   "outputs": [],
   "source": [
    "s_ogau_metrics_df, s_ogau_mean_fpr, s_ogau_mean_tpr = train_and_evaluate(opengraphau_smile, Shuffled_Smile_Labels, pipeline_name='Shuffled OpenGraphAU', results_path=RESULTS_PATH_BASE + 'Smile/')\n",
    "print('OPENGRAPHAU SHUFFLED: ')\n",
    "display(s_ogau_metrics_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6LvfNe14vEaN"
   },
   "outputs": [],
   "source": [
    "s_hse_metrics_df, s_hse_mean_fpr, s_hse_mean_tpr = train_and_evaluate(hsemotion_smile, Shuffled_Smile_Labels, pipeline_name='Shuffled HSEmotion', results_path=RESULTS_PATH_BASE + 'Smile/')\n",
    "print('HSEMOTION SHUFFLED: ')\n",
    "display(s_hse_metrics_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tmyYDNpMLFQ7"
   },
   "source": [
    "## Yawn Results: Train + Eval (5-Fold CV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NXU-RwXyLFRE"
   },
   "outputs": [],
   "source": [
    "of_metrics_df, of_mean_fpr, of_mean_tpr = train_and_evaluate(openface_yawn, Final_Yawn_Labels, pipeline_name='OpenFace', results_path=RESULTS_PATH_BASE + 'Yawn/')\n",
    "print('OPENFACE: ')\n",
    "display(of_metrics_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9EE_6JcBLFRE"
   },
   "outputs": [],
   "source": [
    "ogau_metrics_df, ogau_mean_fpr, ogau_mean_tpr = train_and_evaluate(opengraphau_yawn, Final_Yawn_Labels, pipeline_name='OpenGraphAU', results_path=RESULTS_PATH_BASE + 'Yawn/')\n",
    "print('OPENGRAPHAU: ')\n",
    "display(ogau_metrics_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fWMiTFsJLFRE"
   },
   "outputs": [],
   "source": [
    "hse_metrics_df, hse_mean_fpr, hse_mean_tpr = train_and_evaluate(hsemotion_yawn, Final_Yawn_Labels, pipeline_name='HSEmotion', results_path=RESULTS_PATH_BASE + 'Yawn/')\n",
    "print('HSEMOTION: ')\n",
    "display(hse_metrics_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ppJdd12YLFRE"
   },
   "source": [
    "## Yawn Checking shuffled labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3CIZI4TiLFRF"
   },
   "outputs": [],
   "source": [
    "s_of_metrics_df, s_of_mean_fpr, s_of_mean_tpr = train_and_evaluate(openface_yawn, Shuffled_Yawn_Labels, pipeline_name='Shuffled OpenFace', results_path=RESULTS_PATH_BASE + 'Yawn/')\n",
    "print('OPENFACE SHUFFLED: ')\n",
    "display(s_of_metrics_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CA41WG3OLFRF"
   },
   "outputs": [],
   "source": [
    "s_ogau_metrics_df, s_ogau_mean_fpr, s_ogau_mean_tpr = train_and_evaluate(opengraphau_yawn, Shuffled_Yawn_Labels, pipeline_name='Shuffled OpenGraphAU', results_path=RESULTS_PATH_BASE + 'Yawn/')\n",
    "print('OPENGRAPHAU SHUFFLED: ')\n",
    "display(s_ogau_metrics_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EVtTnFFcLFRF"
   },
   "outputs": [],
   "source": [
    "s_hse_metrics_df, s_hse_mean_fpr, s_hse_mean_tpr = train_and_evaluate(hsemotion_yawn, Shuffled_Yawn_Labels, pipeline_name='Shuffled HSEmotion', results_path=RESULTS_PATH_BASE + 'Yawn/')\n",
    "print('HSEMOTION SHUFFLED: ')\n",
    "display(s_hse_metrics_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "H6iAlq7kDllA"
   },
   "source": [
    "## Discomfort Results: Train + Eval (5-Fold CV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "e9hXxu7PDllI"
   },
   "outputs": [],
   "source": [
    "of_metrics_df, of_mean_fpr, of_mean_tpr = train_and_evaluate(openface_discomfort, Final_Discomfort_Labels, pipeline_name='OpenFace', results_path=RESULTS_PATH_BASE + 'Discomfort/')\n",
    "print('OPENFACE: ')\n",
    "display(of_metrics_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HdiSirIfDllI"
   },
   "outputs": [],
   "source": [
    "ogau_metrics_df, ogau_mean_fpr, ogau_mean_tpr = train_and_evaluate(opengraphau_discomfort, Final_Discomfort_Labels, pipeline_name='OpenGraphAU', results_path=RESULTS_PATH_BASE + 'Discomfort/')\n",
    "print('OPENGRAPHAU: ')\n",
    "display(ogau_metrics_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gDldawZ6DllJ"
   },
   "outputs": [],
   "source": [
    "hse_metrics_df, hse_mean_fpr, hse_mean_tpr = train_and_evaluate(hsemotion_discomfort, Final_Discomfort_Labels, pipeline_name='HSEmotion', results_path=RESULTS_PATH_BASE + 'Discomfort/')\n",
    "print('HSEMOTION: ')\n",
    "display(hse_metrics_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kATmbM88DllJ"
   },
   "source": [
    "## Discomfort Checking shuffled labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qtp25XrADllJ"
   },
   "outputs": [],
   "source": [
    "s_of_metrics_df, s_of_mean_fpr, s_of_mean_tpr = train_and_evaluate(openface_discomfort, Shuffled_Discomfort_Labels, pipeline_name='Shuffled OpenFace', results_path=RESULTS_PATH_BASE + 'Discomfort/')\n",
    "print('OPENFACE SHUFFLED: ')\n",
    "display(s_of_metrics_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5CuNgv_-DllJ"
   },
   "outputs": [],
   "source": [
    "s_ogau_metrics_df, s_ogau_mean_fpr, s_ogau_mean_tpr = train_and_evaluate(opengraphau_discomfort, Shuffled_Discomfort_Labels, pipeline_name='Shuffled OpenGraphAU', results_path=RESULTS_PATH_BASE + 'Discomfort/')\n",
    "print('OPENGRAPHAU SHUFFLED: ')\n",
    "display(s_ogau_metrics_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zyTcX6qrDllJ"
   },
   "outputs": [],
   "source": [
    "s_hse_metrics_df, s_hse_mean_fpr, s_hse_mean_tpr = train_and_evaluate(hsemotion_discomfort, Shuffled_Discomfort_Labels, pipeline_name='Shuffled HSEmotion', results_path=RESULTS_PATH_BASE + 'Discomfort/')\n",
    "print('HSEMOTION SHUFFLED: ')\n",
    "display(s_hse_metrics_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nXss5kzANd5b"
   },
   "source": [
    "## Sad Results: Train + Eval (5-Fold CV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HcrVOsk1Nd5n"
   },
   "outputs": [],
   "source": [
    "of_metrics_df, of_mean_fpr, of_mean_tpr = train_and_evaluate(openface_sad, Final_Sad_Labels, pipeline_name='OpenFace', results_path=RESULTS_PATH_BASE + 'Sad/')\n",
    "print('OPENFACE: ')\n",
    "display(of_metrics_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Xnp2LEpvNd5o"
   },
   "outputs": [],
   "source": [
    "ogau_metrics_df, ogau_mean_fpr, ogau_mean_tpr = train_and_evaluate(opengraphau_sad, Final_Sad_Labels, pipeline_name='OpenGraphAU', results_path=RESULTS_PATH_BASE + 'Sad/')\n",
    "print('OPENGRAPHAU: ')\n",
    "display(ogau_metrics_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "p6oM_AGWNd5o"
   },
   "outputs": [],
   "source": [
    "hse_metrics_df, hse_mean_fpr, hse_mean_tpr = train_and_evaluate(hsemotion_sad, Final_Sad_Labels, pipeline_name='HSEmotion', results_path=RESULTS_PATH_BASE + 'Sad/')\n",
    "print('HSEMOTION: ')\n",
    "display(hse_metrics_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TV6bRuHgNd5o"
   },
   "source": [
    "## Sad Checking shuffled labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-QdQwBuCNd5o"
   },
   "outputs": [],
   "source": [
    "s_of_metrics_df, s_of_mean_fpr, s_of_mean_tpr = train_and_evaluate(openface_sad, Shuffled_Sad_Labels, pipeline_name='Shuffled OpenFace', results_path=RESULTS_PATH_BASE + 'Sad/')\n",
    "print('OPENFACE SHUFFLED: ')\n",
    "display(s_of_metrics_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KHnhUMl7Nd5p"
   },
   "outputs": [],
   "source": [
    "s_ogau_metrics_df, s_ogau_mean_fpr, s_ogau_mean_tpr = train_and_evaluate(opengraphau_sad, Shuffled_Sad_Labels, pipeline_name='Shuffled OpenGraphAU', results_path=RESULTS_PATH_BASE + 'Sad/')\n",
    "print('OPENGRAPHAU SHUFFLED: ')\n",
    "display(s_ogau_metrics_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XNyShjKENd5p"
   },
   "outputs": [],
   "source": [
    "s_hse_metrics_df, s_hse_mean_fpr, s_hse_mean_tpr = train_and_evaluate(hsemotion_sad, Shuffled_Sad_Labels, pipeline_name='Shuffled HSEmotion', results_path=RESULTS_PATH_BASE + 'Sad/')\n",
    "print('HSEMOTION SHUFFLED: ')\n",
    "display(s_hse_metrics_df)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "machine_shape": "hm",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
